{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Section\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium.wrappers import AtariPreprocessing, FrameStackObservation, RecordVideo, TransformReward\n",
    "from agents.reinforce import ReinforcePolicyGradientsAgent\n",
    "from agents.dqn import DQNAgent\n",
    "from agents.dueling_dqn import DuelingDQNAgent\n",
    "from agents.rainbow_dqn import RainbowDQNAgent\n",
    "from models.cnns import CNNBackbone\n",
    "from wrappers.gym_wrappers import ProgressiveRewardWrapper, ChannelFirstWrapper, NormalizeWrapper, ChannelWiseFrameStack, StopOnRoundEndWrapper, RemoveNoopWrapper, SkipRedundantFramesWrapper\n",
    "\n",
    "# Enable autoreload for all modules\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Training Configuration\n",
    "CONFIG = {\n",
    "    # Environment Settings\n",
    "    \"env_name\": \"ALE/Surround-v5\",\n",
    "    \"game\": \"Surround\",\n",
    "    \"mode\": 0,\n",
    "    \"difficulty\": 3,\n",
    "    \"frameskip\": 1,\n",
    "    \n",
    "    # Directory Settings\n",
    "    \"base_dir\": \"./experiments\",\n",
    "    \"video_subdir\": \"videos\",\n",
    "    \"checkpoint_subdir\": \"checkpoints\",\n",
    "    \"log_subdir\": \"logs\",\n",
    "    \n",
    "    # Training Settings\n",
    "    \"num_episodes\": 1000000,\n",
    "    \"render_every_n\": 250,\n",
    "    \"save_every_n\": 1000,\n",
    "    \n",
    "    # Environment Preprocessing\n",
    "    \"screen_size\": 84,\n",
    "    \"grayscale\": True,\n",
    "    \"frame_stack\": 0,  # Set to 0 to disable\n",
    "    \"normalize\": False, # Don't use this, normalization built into AtariPreprocessing wrapper\n",
    "    \"base_survival_reward\": 0.01,  # Lower base reward since it will scale up\n",
    "    # \"survival_scaling_factor\": 1.05, # Exponential growth factor\n",
    "    \"reward_scaling_factor\": 1, # Scaling factor for rewards\n",
    "    \"stop_on_round_end\": True,\n",
    "\n",
    "    # Agent Selection\n",
    "    # \"agent_type\": \"reinforce\",  # Options: \"reinforce\" or \"dqn\"\n",
    "    \"agent_type\": \"rainbow_dqn\",\n",
    "    \n",
    "    # Shared Agent Settings\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"learning_rate\": 1e-4, \n",
    "    \"weight_decay\": 0,\n",
    "    \"gamma\": 0.99, # Discount factor\n",
    "    \"use_cnn\": True,\n",
    "    \n",
    "    # REINFORCE-specific settings\n",
    "    \"reinforce\": {\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"entropy_coef\": 1e-4,\n",
    "        # Network architecture\n",
    "        \"cnn_channels\": [32, 64, 64],\n",
    "        \"cnn_kernel_sizes\": [3, 3, 3],\n",
    "        \"cnn_strides\": [2, 2, 1],\n",
    "        \"hidden_dims\": [512]\n",
    "    },\n",
    "    \n",
    "    # DQN-specific settings\n",
    "    \"dqn\": {\n",
    "        # Network architecture\n",
    "        \"cnn_channels\": [32, 64, 64],\n",
    "        \"cnn_kernel_sizes\": [8, 4, 3],\n",
    "        \"cnn_strides\": [4, 2, 1],\n",
    "        \"hidden_dims\": [64, 32],\n",
    "        \n",
    "        # Buffer settings\n",
    "        \"buffer_size\": 100000,\n",
    "        \"batch_size\": 64,\n",
    "        \"target_update_freq\": 1, # Update target network every n steps, set to 1 (or something low) for soft update\n",
    "        \"tau\": 0.001, # Soft update parameter, if 1 then hard update\n",
    "        \"update_freq\": 1,\n",
    "        \"gradient_clip\": 1.0,\n",
    "        \n",
    "        \"eps_start\": 1.0,\n",
    "        \"eps_end\": 0.05,\n",
    "        \"eps_decay\": 0.99,\n",
    "        \"double_dqn\": True,\n",
    "        \n",
    "        \"per_alpha\": 0.6,\n",
    "        \"per_beta_start\": 0.4,\n",
    "        \"per_beta_end\": 1.0,\n",
    "        \"per_beta_steps\": 100000\n",
    "    },\n",
    "\n",
    "    # DQN-specific settings\n",
    "    \"dueling_dqn\": {\n",
    "        \"cnn_channels\": [6, 6, 6],\n",
    "        \"cnn_kernel_sizes\": [8, 4, 3],\n",
    "        \"cnn_strides\": [4, 2, 1],\n",
    "        \"hidden_dims\": [512],\n",
    "        \n",
    "        # Buffer settings\n",
    "        \"buffer_size\": 50000,\n",
    "        \"batch_size\": 2048,\n",
    "        \"target_update_freq\": 2, # Update target network every n steps, set to 1 (or something low) for soft update\n",
    "        \"tau\": 0.001, # Soft update parameter, if 1 then hard update\n",
    "        \"update_freq\": 1,\n",
    "        \"gradient_clip\": 1.0,\n",
    "        \n",
    "        \"eps_start\": 1.0,\n",
    "        \"eps_end\": 0.05,\n",
    "        \"eps_decay\": 0.9995,\n",
    "        \"double_dqn\": True,\n",
    "        \n",
    "        \"per_alpha\": 0.4,\n",
    "        \"per_beta_start\": 0.4,\n",
    "        \"per_beta_end\": 1.0,\n",
    "        \"per_beta_steps\": 200000 \n",
    "    },\n",
    "\n",
    "    \"rainbow_dqn\": {\n",
    "        \"cnn_channels\": [32, 64, 64],\n",
    "        \"cnn_kernel_sizes\": [8, 4, 3],\n",
    "        \"cnn_strides\": [4, 2, 1],\n",
    "        \"hidden_dims\": [512],\n",
    "        \"buffer_size\": 100000,\n",
    "        \"batch_size\": 32,\n",
    "        \"target_update_freq\": 4,\n",
    "        \"tau\": 0.002,\n",
    "        \"update_freq\": 4,\n",
    "        \"gradient_clip\": 1.0,\n",
    "        \"double_dqn\": True,\n",
    "        \"per_alpha\": 0.6,\n",
    "        \"per_beta_start\": 0.4,\n",
    "        \"per_beta_end\": 1.0,\n",
    "        \"per_beta_steps\": 100000,\n",
    "        \"n_steps\": 3,\n",
    "        \"v_min\": -10.0,\n",
    "        \"v_max\": 10.0,\n",
    "        \"n_atoms\": 51\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_env(config, experiment_dir):\n",
    "    \"\"\"Create and wrap the environment according to configuration.\"\"\"\n",
    "    env = gym.make(\n",
    "        config[\"env_name\"],\n",
    "        render_mode=\"rgb_array\",\n",
    "        mode=config[\"mode\"],\n",
    "        difficulty=config[\"difficulty\"],\n",
    "        frameskip=config[\"frameskip\"]\n",
    "    )\n",
    "\n",
    "    env = SkipRedundantFramesWrapper(env)\n",
    "    \n",
    "    # Naive Stop on round end wrapper to detect end via reward (1 or -1)\n",
    "    if config[\"stop_on_round_end\"]:\n",
    "        env = StopOnRoundEndWrapper(env, stop_reward=1)\n",
    "\n",
    "    # Progressive reward wrapper\n",
    "    # env = ProgressiveRewardWrapper(\n",
    "    #     env,\n",
    "    #     base_survival_reward=config[\"base_survival_reward\"]\n",
    "    # )\n",
    "    env = TransformReward(env, lambda r: r + config[\"base_survival_reward\"])\n",
    "        \n",
    "    if config[\"reward_scaling_factor\"] != 1:\n",
    "        env = TransformReward(env, lambda r: r * config[\"reward_scaling_factor\"])\n",
    "    \n",
    "    # Preprocessing wrappers\n",
    "    env = AtariPreprocessing(\n",
    "        env,\n",
    "        noop_max=4,\n",
    "        frame_skip=1,\n",
    "        screen_size=config[\"screen_size\"],\n",
    "        scale_obs=True,\n",
    "        grayscale_obs=config[\"grayscale\"],\n",
    "        grayscale_newaxis=config[\"grayscale\"] # add channel dim\n",
    "    )\n",
    "\n",
    "    # Video wrapper\n",
    "    env = RecordVideo(\n",
    "        env,\n",
    "        video_folder=str(experiment_dir / config[\"video_subdir\"]),\n",
    "        episode_trigger=lambda episode_id: episode_id % config[\"render_every_n\"] == 0,\n",
    "        fps=60\n",
    "    )\n",
    "    \n",
    "    env = ChannelFirstWrapper(env)\n",
    "    \n",
    "    if config[\"frame_stack\"] > 0:\n",
    "        env = FrameStackObservation(env, config[\"frame_stack\"])\n",
    "        env = ChannelWiseFrameStack(env)\n",
    "    \n",
    "    if config[\"normalize\"]:\n",
    "        env = NormalizeWrapper(env)\n",
    "    \n",
    "    env = RemoveNoopWrapper(env)\n",
    "\n",
    "    return env\n",
    "\n",
    "def create_agent_from_config(config: dict, env: gym.Env):\n",
    "    \"\"\"\n",
    "    Creates an agent instance from a configuration dictionary by automatically\n",
    "    mapping config parameters to constructor arguments.\n",
    "    \n",
    "    The function combines common parameters with agent-specific ones and uses\n",
    "    dictionary unpacking for clean initialization.\n",
    "    \"\"\"\n",
    "    # Common parameters shared across all agents\n",
    "    common_params = {\n",
    "        \"env\": env,\n",
    "        \"device\": config.get(\"device\", \"cpu\"),\n",
    "        \"use_cnn\": config.get(\"use_cnn\", False),\n",
    "        \"lr\": config.get(\"learning_rate\", 1e-3),\n",
    "        \"weight_decay\": config.get(\"weight_decay\", 0),\n",
    "        \"gamma\": config.get(\"gamma\", 0.99)\n",
    "    }\n",
    "    \n",
    "    agent_type = config[\"agent_type\"].lower()\n",
    "    \n",
    "    # Get the appropriate agent class\n",
    "    agent_classes = {\n",
    "        \"reinforce\": ReinforcePolicyGradientsAgent,\n",
    "        \"dqn\": DQNAgent,\n",
    "        \"dueling_dqn\": DuelingDQNAgent,\n",
    "        \"rainbow_dqn\": RainbowDQNAgent\n",
    "    }\n",
    "    \n",
    "    if agent_type not in agent_classes:\n",
    "        raise ValueError(f\"Unknown agent type: {agent_type}\")\n",
    "    \n",
    "    agent_class = agent_classes[agent_type]\n",
    "    \n",
    "    # Combine common parameters with agent-specific ones\n",
    "    agent_params = {**common_params}\n",
    "    if agent_type in config:\n",
    "        agent_params.update(config[agent_type])\n",
    "    \n",
    "    # Create and return the agent instance using dictionary unpacking\n",
    "    return agent_class(**agent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_dir):\n",
    "    \"\"\"Plot and save training metrics.\"\"\"\n",
    "    df = pd.DataFrame(history)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define metrics groupings\n",
    "    value_metrics = ['total_return', 'mean_q_value']  # DQN and REINFORCE\n",
    "    loss_metrics = ['q_loss', 'policy_loss', 'entropy_loss', 'total_loss']  # Combined\n",
    "    auxiliary_metrics = ['eps']  # DQN-specific\n",
    "    \n",
    "    # Filter to only metrics present in the data\n",
    "    value_metrics = [m for m in value_metrics if m in df.columns]\n",
    "    loss_metrics = [m for m in loss_metrics if m in df.columns]\n",
    "    auxiliary_metrics = [m for m in auxiliary_metrics if m in df.columns]\n",
    "    \n",
    "    # Determine number of subplot rows needed\n",
    "    n_rows = (bool(value_metrics) + bool(loss_metrics) + bool(auxiliary_metrics))\n",
    "    \n",
    "    # Create combined figure\n",
    "    fig, axes = plt.subplots(n_rows, 1, figsize=(12, 5*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    current_ax = 0\n",
    "    \n",
    "    # Plot value metrics\n",
    "    if value_metrics:\n",
    "        ax = axes[current_ax]\n",
    "        for metric in value_metrics:\n",
    "            ax.plot(df[metric], label=metric)\n",
    "        ax.set_title('Value Metrics')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.legend()\n",
    "        current_ax += 1\n",
    "    \n",
    "    # Plot loss metrics\n",
    "    if loss_metrics:\n",
    "        ax = axes[current_ax]\n",
    "        for metric in loss_metrics:\n",
    "            ax.plot(df[metric], label=metric)\n",
    "        ax.set_title('Loss Metrics')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.legend()\n",
    "        current_ax += 1\n",
    "    \n",
    "    # Plot auxiliary metrics\n",
    "    if auxiliary_metrics:\n",
    "        ax = axes[current_ax]\n",
    "        for metric in auxiliary_metrics:\n",
    "            ax.plot(df[metric], label=metric)\n",
    "        ax.set_title('Auxiliary Metrics')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Also save individual plots\n",
    "    all_metrics = df.columns.tolist()\n",
    "    excluded_metrics = {'total_steps', 'buffer_size'}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        if metric not in excluded_metrics:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(df[metric])\n",
    "            plt.title(metric)\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel(metric)\n",
    "            plt.savefig(save_dir / f\"{metric}_history.png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(agent, episode, history, save_dir, config):\n",
    "    \"\"\"Save agent checkpoint and training history.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save agent state\n",
    "    agent_path = save_dir / f\"agent_{config['agent_type']}_episode_{episode}_{timestamp}.pth\"\n",
    "    agent.save(agent_path)\n",
    "    \n",
    "    # Save training state\n",
    "    checkpoint = {\n",
    "        'episode': episode,\n",
    "        'history': history,\n",
    "        'config': config\n",
    "    }\n",
    "    checkpoint_path = save_dir / f\"training_state_episode_{episode}_{timestamp}.pt\"\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    return agent_path, checkpoint_path\n",
    "\n",
    "def load_checkpoint(agent_path, config_path):\n",
    "    \"\"\"\n",
    "    Load agent checkpoint and config.\n",
    "    \n",
    "    Args:\n",
    "        agent_path: Path to .pth agent checkpoint\n",
    "        config_path: Path to experiment config.json\n",
    "    \n",
    "    Returns:\n",
    "        agent: Loaded agent instance\n",
    "        config: Loaded config dict\n",
    "    \"\"\"\n",
    "    # Load config\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    # Create environment\n",
    "    env = create_env(config, Path(config['base_dir']))\n",
    "    \n",
    "    # Create agent using helper function\n",
    "    agent = create_agent_from_config(config, env)\n",
    "    \n",
    "    # Load agent state\n",
    "    agent.load(agent_path)\n",
    "    \n",
    "    return agent, config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(config):\n",
    "    # Create experiment directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_name = f\"{config['game']}_{config['agent_type']}_{timestamp}\"\n",
    "    experiment_dir = Path(config[\"base_dir\"]) / experiment_name\n",
    "    \n",
    "    # Create subdirectories\n",
    "    for subdir in [config[\"video_subdir\"], config[\"checkpoint_subdir\"], config[\"log_subdir\"]]:\n",
    "        (experiment_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(experiment_dir / \"config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create environment and agent\n",
    "    env = create_env(config, experiment_dir=experiment_dir)\n",
    "    agent = create_agent_from_config(config, env)\n",
    "    \n",
    "    print(f\"\\nAgent Type: {config['agent_type'].upper()}\")\n",
    "    print(\"Model Architecture:\")\n",
    "    print(agent.model if hasattr(agent, 'model') else agent.q_network)\n",
    "    print(\"\\nObservation Space:\", env.observation_space)\n",
    "    \n",
    "    # Reset the environment and get the initial observation\n",
    "    observation, _ = env.reset()\n",
    "\n",
    "    # Check if the observation is channel-first (C, H, W) and permute if necessary\n",
    "    if observation.shape[0] == 3 or observation.shape[0] == 1:\n",
    "        observation = np.transpose(observation, (1, 2, 0))  # Convert to (H, W, C)\n",
    "\n",
    "    # Plot and save the observation as an image to preview and view preprocessing\n",
    "    plt.imshow(observation)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    image_path = experiment_dir / \"model_obs_example.png\"\n",
    "    plt.savefig(image_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Training loop\n",
    "    history = []\n",
    "    \n",
    "    for episode in range(config[\"num_episodes\"]):\n",
    "        # Run episode\n",
    "        results = agent.run_episode(env)\n",
    "        history.append(results)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Episode {episode + 1}/{config['num_episodes']}: {results}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (episode + 1) % config[\"save_every_n\"] == 0:\n",
    "            agent_path, checkpoint_path = save_checkpoint(\n",
    "                agent,\n",
    "                episode + 1,\n",
    "                history,\n",
    "                experiment_dir / config[\"checkpoint_subdir\"],\n",
    "                config\n",
    "            )\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "        if (episode + 1) % config[\"render_every_n\"] == 0:\n",
    "            # Plot training history\n",
    "            plot_training_history(history, experiment_dir / config[\"log_subdir\"])\n",
    "    \n",
    "    # Final save\n",
    "    agent_path, checkpoint_path = save_checkpoint(\n",
    "        agent,\n",
    "        config[\"num_episodes\"],\n",
    "        history,\n",
    "        experiment_dir / config[\"checkpoint_subdir\"],\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history, experiment_dir / config[\"log_subdir\"])\n",
    "    \n",
    "    return agent, history, env, experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.1+unknown)\n",
      "[Powered by Stella]\n",
      "/home/bytemarish/miniconda3/envs/slitherl/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/bytemarish/ACM_AI/SlitheRL_Cleaned/experiments/Surround_rainbow_dqn_20250224_172432/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN feature output shape: torch.Size([1, 3136])\n",
      "\n",
      "Agent Type: RAINBOW_DQN\n",
      "Model Architecture:\n",
      "C51DuelingQNetwork(\n",
      "  (feature_extractor): CNNBackbone(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (value_network): NoisyMLPBackbone(\n",
      "    (model): Sequential(\n",
      "      (0): NoisyLinear()\n",
      "      (1): ReLU()\n",
      "      (2): NoisyLinear()\n",
      "    )\n",
      "  )\n",
      "  (advantage_network): NoisyMLPBackbone(\n",
      "    (model): Sequential(\n",
      "      (0): NoisyLinear()\n",
      "      (1): ReLU()\n",
      "      (2): NoisyLinear()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Observation Space: Box(0.0, 255.0, (1, 84, 84), float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0617,  0.0315, -0.0457, -0.0407]], device='cuda:0'), reward is -0.99\n",
      "Episode 1/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 68, 'eps': 0.0, 'buffer_size': 68, 'q_loss': 1.3153727054595947, 'mean_q_value': 0.08053163439035416, 'max_q_value': 0.2702583372592926, 'min_q_value': -0.03141486644744873, 'mean_td_error': 0.09434497, 'max_td_error': 0.19891155, 'mean_weight': 0.33604130148887634}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1619,  0.1017,  0.1787,  0.1428]], device='cuda:0'), reward is -0.99\n",
      "Episode 2/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 106, 'eps': 0.0, 'buffer_size': 106, 'q_loss': 2.388187885284424, 'mean_q_value': 0.15644407272338867, 'max_q_value': 0.31489402055740356, 'min_q_value': -0.12267939746379852, 'mean_td_error': 0.17968205, 'max_td_error': 0.8673199, 'mean_weight': 0.6219595670700073}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1187, -0.0928, -0.3330, -0.0677]], device='cuda:0'), reward is -0.99\n",
      "Episode 3/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 153, 'eps': 0.0, 'buffer_size': 153, 'q_loss': 1.6742815971374512, 'mean_q_value': 0.14200973510742188, 'max_q_value': 0.5114388465881348, 'min_q_value': -0.170480877161026, 'mean_td_error': 0.1668502, 'max_td_error': 0.41756326, 'mean_weight': 0.4267229437828064}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1867, 0.1361, 0.1261, 0.1772]], device='cuda:0'), reward is -0.99\n",
      "Episode 4/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 169, 'eps': 0.0, 'buffer_size': 169, 'q_loss': 2.355938196182251, 'mean_q_value': -0.04332356154918671, 'max_q_value': 0.21328553557395935, 'min_q_value': -0.4552035629749298, 'mean_td_error': 0.17029545, 'max_td_error': 0.53479564, 'mean_weight': 0.608230471611023}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2136, 0.0845, 0.2086, 0.0860]], device='cuda:0'), reward is -0.99\n",
      "Episode 5/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 195, 'eps': 0.0, 'buffer_size': 195, 'q_loss': 1.6074038743972778, 'mean_q_value': 0.05543139949440956, 'max_q_value': 0.2931459844112396, 'min_q_value': -0.5277535915374756, 'mean_td_error': 0.21231769, 'max_td_error': 1.2831452, 'mean_weight': 0.4115965664386749}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1393, 0.0916, 0.1140, 0.0859]], device='cuda:0'), reward is -0.99\n",
      "Episode 6/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 216, 'eps': 0.0, 'buffer_size': 216, 'q_loss': 2.088923454284668, 'mean_q_value': 0.06174420565366745, 'max_q_value': 0.3555207848548889, 'min_q_value': -0.5384095311164856, 'mean_td_error': 0.15908913, 'max_td_error': 1.0801573, 'mean_weight': 0.5337909460067749}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0189, 0.0584, 0.0619, 0.0326]], device='cuda:0'), reward is -0.99\n",
      "Episode 7/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 258, 'eps': 0.0, 'buffer_size': 258, 'q_loss': 1.8423858880996704, 'mean_q_value': 0.13484664261341095, 'max_q_value': 0.4472573399543762, 'min_q_value': -0.3838648796081543, 'mean_td_error': 0.11079965, 'max_td_error': 0.27330828, 'mean_weight': 0.4677616059780121}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0840,  0.0371,  0.0224,  0.0812]], device='cuda:0'), reward is -0.99\n",
      "Episode 8/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 283, 'eps': 0.0, 'buffer_size': 283, 'q_loss': 2.172966718673706, 'mean_q_value': 0.049335964024066925, 'max_q_value': 0.34874942898750305, 'min_q_value': -0.40430179238319397, 'mean_td_error': 0.17734727, 'max_td_error': 0.5380589, 'mean_weight': 0.5522363781929016}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0259, 0.1070, 0.0548, 0.0769]], device='cuda:0'), reward is -0.99\n",
      "Episode 9/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 303, 'eps': 0.0, 'buffer_size': 303, 'q_loss': 2.4488697052001953, 'mean_q_value': 0.032988693565130234, 'max_q_value': 0.44017159938812256, 'min_q_value': -0.3504748046398163, 'mean_td_error': 0.18890071, 'max_td_error': 0.96038944, 'mean_weight': 0.6319997310638428}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0781, -0.0997,  0.0534, -0.0505]], device='cuda:0'), reward is -0.99\n",
      "Episode 10/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 328, 'eps': 0.0, 'buffer_size': 328, 'q_loss': 2.7066030502319336, 'mean_q_value': 0.01566264219582081, 'max_q_value': 0.22292345762252808, 'min_q_value': -0.38731294870376587, 'mean_td_error': 0.18057293, 'max_td_error': 0.36097932, 'mean_weight': 0.6824749708175659}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1027,  0.0724, -0.0485,  0.0826]], device='cuda:0'), reward is -0.99\n",
      "Episode 11/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 384, 'eps': 0.0, 'buffer_size': 384, 'q_loss': 2.07296085357666, 'mean_q_value': 0.0011368412524461746, 'max_q_value': 0.43206948041915894, 'min_q_value': -0.402521014213562, 'mean_td_error': 0.14151847, 'max_td_error': 0.83605766, 'mean_weight': 0.5365411043167114}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0574,  0.1019, -0.0299,  0.0274]], device='cuda:0'), reward is -0.99\n",
      "Episode 12/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 441, 'eps': 0.0, 'buffer_size': 441, 'q_loss': 1.7509186267852783, 'mean_q_value': 0.053734682500362396, 'max_q_value': 0.48373907804489136, 'min_q_value': -0.47895053029060364, 'mean_td_error': 0.13027674, 'max_td_error': 0.5110487, 'mean_weight': 0.45149147510528564}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1005,  0.1363, -0.2049,  0.0804]], device='cuda:0'), reward is -0.99\n",
      "Episode 13/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 482, 'eps': 0.0, 'buffer_size': 482, 'q_loss': 2.0566418170928955, 'mean_q_value': 0.0215914249420166, 'max_q_value': 0.2893849015235901, 'min_q_value': -0.3076346814632416, 'mean_td_error': 0.16076659, 'max_td_error': 1.1496274, 'mean_weight': 0.5352264642715454}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1250, -0.1079, -0.1862, -0.0695]], device='cuda:0'), reward is -0.99\n",
      "Episode 14/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 538, 'eps': 0.0, 'buffer_size': 538, 'q_loss': 2.308835983276367, 'mean_q_value': 0.009844713844358921, 'max_q_value': 0.25587376952171326, 'min_q_value': -0.7805464863777161, 'mean_td_error': 0.16263591, 'max_td_error': 0.66694283, 'mean_weight': 0.6221023797988892}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0108,  0.1255,  0.0893,  0.0520]], device='cuda:0'), reward is -0.99\n",
      "Episode 15/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 572, 'eps': 0.0, 'buffer_size': 572, 'q_loss': 1.4903501272201538, 'mean_q_value': 0.01068289577960968, 'max_q_value': 0.2666373550891876, 'min_q_value': -0.4328460991382599, 'mean_td_error': 0.1770395, 'max_td_error': 1.1223155, 'mean_weight': 0.39152824878692627}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0107, 0.2900, 0.2326, 0.1487]], device='cuda:0'), reward is -0.99\n",
      "Episode 16/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 602, 'eps': 0.0, 'buffer_size': 602, 'q_loss': 2.3889577388763428, 'mean_q_value': -0.01496619451791048, 'max_q_value': 0.2757672071456909, 'min_q_value': -0.5367343425750732, 'mean_td_error': 0.10740402, 'max_td_error': 0.26857418, 'mean_weight': 0.6065729856491089}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1797, 0.1283, 0.1223, 0.1400]], device='cuda:0'), reward is -0.99\n",
      "Episode 17/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 622, 'eps': 0.0, 'buffer_size': 622, 'q_loss': 2.6127262115478516, 'mean_q_value': -0.015495739877223969, 'max_q_value': 0.30272138118743896, 'min_q_value': -0.6142078638076782, 'mean_td_error': 0.1855123, 'max_td_error': 0.8870978, 'mean_weight': 0.6767249703407288}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0317,  0.0241, -0.0165,  0.0403]], device='cuda:0'), reward is -0.99\n",
      "Episode 18/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 661, 'eps': 0.0, 'buffer_size': 661, 'q_loss': 2.4229063987731934, 'mean_q_value': -0.0370803065598011, 'max_q_value': 0.3175426721572876, 'min_q_value': -0.7333987951278687, 'mean_td_error': 0.14154641, 'max_td_error': 0.3964464, 'mean_weight': 0.6366183757781982}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0276,  0.0775, -0.0862, -0.0721]], device='cuda:0'), reward is -0.99\n",
      "Episode 19/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 699, 'eps': 0.0, 'buffer_size': 699, 'q_loss': 1.6945159435272217, 'mean_q_value': -0.05522928759455681, 'max_q_value': 0.2631049156188965, 'min_q_value': -0.828898549079895, 'mean_td_error': 0.13403046, 'max_td_error': 0.69786996, 'mean_weight': 0.449734091758728}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0570, 0.1470, 0.0619, 0.0570]], device='cuda:0'), reward is -0.99\n",
      "Episode 20/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 735, 'eps': 0.0, 'buffer_size': 735, 'q_loss': 2.184682846069336, 'mean_q_value': 0.007744237780570984, 'max_q_value': 0.29483547806739807, 'min_q_value': -0.8428308963775635, 'mean_td_error': 0.14280745, 'max_td_error': 1.0002222, 'mean_weight': 0.5847681760787964}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0993, 0.1553, 0.0744, 0.1134]], device='cuda:0'), reward is -0.99\n",
      "Episode 21/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 766, 'eps': 0.0, 'buffer_size': 766, 'q_loss': 1.804917335510254, 'mean_q_value': 0.07173149287700653, 'max_q_value': 0.28305643796920776, 'min_q_value': -0.4072869122028351, 'mean_td_error': 0.104926735, 'max_td_error': 0.25956848, 'mean_weight': 0.4584001302719116}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0445,  0.0071,  0.0850, -0.0610]], device='cuda:0'), reward is -0.99\n",
      "Episode 22/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 791, 'eps': 0.0, 'buffer_size': 791, 'q_loss': 1.737114667892456, 'mean_q_value': 0.017504137009382248, 'max_q_value': 0.2569859027862549, 'min_q_value': -0.9367320537567139, 'mean_td_error': 0.12261578, 'max_td_error': 0.60618514, 'mean_weight': 0.46503329277038574}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1152, -0.0500,  0.0748,  0.1208]], device='cuda:0'), reward is -0.99\n",
      "Episode 23/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 819, 'eps': 0.0, 'buffer_size': 819, 'q_loss': 1.9293569326400757, 'mean_q_value': 0.0218417476862669, 'max_q_value': 0.2662545144557953, 'min_q_value': -0.4025669991970062, 'mean_td_error': 0.15722793, 'max_td_error': 1.0222659, 'mean_weight': 0.49312859773635864}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0350, 0.1697, 0.1083, 0.0622]], device='cuda:0'), reward is -0.99\n",
      "Episode 24/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 886, 'eps': 0.0, 'buffer_size': 886, 'q_loss': 2.1090784072875977, 'mean_q_value': 0.026356521993875504, 'max_q_value': 0.4024447798728943, 'min_q_value': -0.8274383544921875, 'mean_td_error': 0.08292568, 'max_td_error': 0.23416185, 'mean_weight': 0.547356367111206}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1140, -0.0488, -0.0506,  0.0854]], device='cuda:0'), reward is -0.99\n",
      "Episode 25/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 908, 'eps': 0.0, 'buffer_size': 908, 'q_loss': 2.377558469772339, 'mean_q_value': 0.07202772796154022, 'max_q_value': 0.2872406244277954, 'min_q_value': -0.3143182396888733, 'mean_td_error': 0.15846351, 'max_td_error': 1.2490845, 'mean_weight': 0.6123733520507812}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1078, 0.1707, 0.0028, 0.1144]], device='cuda:0'), reward is -0.99\n",
      "Episode 26/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 937, 'eps': 0.0, 'buffer_size': 937, 'q_loss': 2.254915237426758, 'mean_q_value': 0.0523778460919857, 'max_q_value': 0.27310600876808167, 'min_q_value': -0.7272970080375671, 'mean_td_error': 0.10896908, 'max_td_error': 0.62380797, 'mean_weight': 0.5925583839416504}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0278,  0.2162,  0.2828,  0.0394]], device='cuda:0'), reward is -0.99\n",
      "Episode 27/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 968, 'eps': 0.0, 'buffer_size': 968, 'q_loss': 2.20857572555542, 'mean_q_value': 0.10537287592887878, 'max_q_value': 0.348024845123291, 'min_q_value': -0.3051351308822632, 'mean_td_error': 0.11025123, 'max_td_error': 0.6848641, 'mean_weight': 0.5695587396621704}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0241, 0.2072, 0.1599, 0.1771]], device='cuda:0'), reward is -0.99\n",
      "Episode 28/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 1029, 'eps': 0.0, 'buffer_size': 1029, 'q_loss': 1.9197006225585938, 'mean_q_value': 0.059549055993556976, 'max_q_value': 0.2798554301261902, 'min_q_value': -0.43398481607437134, 'mean_td_error': 0.15044719, 'max_td_error': 1.0142459, 'mean_weight': 0.5059849619865417}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1707, 0.1018, 0.1380, 0.1822]], device='cuda:0'), reward is -0.99\n",
      "Episode 29/1000000: {'total_return': -0.86, 'steps': 14, 'total_steps': 1043, 'eps': 0.0, 'buffer_size': 1043, 'q_loss': 1.3267427682876587, 'mean_q_value': 0.05916812643408775, 'max_q_value': 0.3000470995903015, 'min_q_value': -0.5130194425582886, 'mean_td_error': 0.18640834, 'max_td_error': 0.9354136, 'mean_weight': 0.3477715849876404}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1073, -0.0065, -0.0687, -0.0131]], device='cuda:0'), reward is -0.99\n",
      "Episode 30/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 1059, 'eps': 0.0, 'buffer_size': 1059, 'q_loss': 2.3754122257232666, 'mean_q_value': 0.02003476582467556, 'max_q_value': 0.3190850615501404, 'min_q_value': -0.40196168422698975, 'mean_td_error': 0.16492245, 'max_td_error': 0.8723845, 'mean_weight': 0.6203774213790894}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0537, 0.0797, 0.1357, 0.1919]], device='cuda:0'), reward is -0.99\n",
      "Episode 31/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 1081, 'eps': 0.0, 'buffer_size': 1081, 'q_loss': 2.6890082359313965, 'mean_q_value': 0.07306656986474991, 'max_q_value': 0.3970806896686554, 'min_q_value': -0.9188743233680725, 'mean_td_error': 0.1526044, 'max_td_error': 1.1720997, 'mean_weight': 0.7064348459243774}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0678, -0.0838, -0.0732, -0.2598]], device='cuda:0'), reward is -0.99\n",
      "Episode 32/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 1132, 'eps': 0.0, 'buffer_size': 1132, 'q_loss': 1.772148847579956, 'mean_q_value': 0.053762923926115036, 'max_q_value': 0.43494993448257446, 'min_q_value': -0.4702971577644348, 'mean_td_error': 0.208432, 'max_td_error': 1.1477871, 'mean_weight': 0.4855305552482605}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0339, -0.0656,  0.1429, -0.2269]], device='cuda:0'), reward is -0.99\n",
      "Episode 33/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 1166, 'eps': 0.0, 'buffer_size': 1166, 'q_loss': 2.1056437492370605, 'mean_q_value': -0.06257014721632004, 'max_q_value': 0.30787065625190735, 'min_q_value': -0.7889532446861267, 'mean_td_error': 0.15108985, 'max_td_error': 0.84345675, 'mean_weight': 0.5693598985671997}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1876, -0.1036, -0.1253, -0.1612]], device='cuda:0'), reward is -0.99\n",
      "Episode 34/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 1242, 'eps': 0.0, 'buffer_size': 1242, 'q_loss': 1.3017057180404663, 'mean_q_value': 0.06294295191764832, 'max_q_value': 0.25079500675201416, 'min_q_value': -0.3007358908653259, 'mean_td_error': 0.098110616, 'max_td_error': 0.8003744, 'mean_weight': 0.3331555724143982}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0370, 0.1053, 0.0218, 0.0221]], device='cuda:0'), reward is -0.99\n",
      "Episode 35/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 1275, 'eps': 0.0, 'buffer_size': 1275, 'q_loss': 2.003441333770752, 'mean_q_value': -0.013482999056577682, 'max_q_value': 0.30390116572380066, 'min_q_value': -0.9206265807151794, 'mean_td_error': 0.1163311, 'max_td_error': 0.8771833, 'mean_weight': 0.5506162047386169}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1366, 0.2055, 0.1875, 0.0966]], device='cuda:0'), reward is -0.99\n",
      "Episode 36/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 1308, 'eps': 0.0, 'buffer_size': 1308, 'q_loss': 1.63908052444458, 'mean_q_value': 0.08926960825920105, 'max_q_value': 0.33396127820014954, 'min_q_value': -0.43967097997665405, 'mean_td_error': 0.111203596, 'max_td_error': 0.6235712, 'mean_weight': 0.4289742112159729}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0990, -0.0102,  0.0549,  0.2167]], device='cuda:0'), reward is -0.99\n",
      "Episode 37/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 1328, 'eps': 0.0, 'buffer_size': 1328, 'q_loss': 2.320162773132324, 'mean_q_value': 0.07152388244867325, 'max_q_value': 0.337546169757843, 'min_q_value': -0.6176207661628723, 'mean_td_error': 0.10457326, 'max_td_error': 0.5770737, 'mean_weight': 0.5862936973571777}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3518, -0.1220,  0.0786, -0.1059]], device='cuda:0'), reward is -0.99\n",
      "Episode 38/1000000: {'total_return': -0.0799999999999994, 'steps': 92, 'total_steps': 1420, 'eps': 0.0, 'buffer_size': 1420, 'q_loss': 2.1597177982330322, 'mean_q_value': 0.04881089925765991, 'max_q_value': 0.38455501198768616, 'min_q_value': -0.980787456035614, 'mean_td_error': 0.111406565, 'max_td_error': 1.0162649, 'mean_weight': 0.5923399329185486}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8234, -0.5983, -0.9045, -0.7406]], device='cuda:0'), reward is -0.99\n",
      "Episode 39/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 1451, 'eps': 0.0, 'buffer_size': 1451, 'q_loss': 2.3107595443725586, 'mean_q_value': 0.023953260853886604, 'max_q_value': 0.2012692391872406, 'min_q_value': -0.6422905921936035, 'mean_td_error': 0.10747555, 'max_td_error': 0.35200655, 'mean_weight': 0.5954052805900574}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1360, 0.1199, 0.0985, 0.1364]], device='cuda:0'), reward is -0.99\n",
      "Episode 40/1000000: {'total_return': -0.88, 'steps': 12, 'total_steps': 1463, 'eps': 0.0, 'buffer_size': 1463, 'q_loss': 1.9286538362503052, 'mean_q_value': 0.1022506058216095, 'max_q_value': 0.30715152621269226, 'min_q_value': -0.06508302688598633, 'mean_td_error': 0.08614008, 'max_td_error': 0.24717873, 'mean_weight': 0.49181199073791504}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0317, -0.0757,  0.0639,  0.1176]], device='cuda:0'), reward is -0.99\n",
      "Episode 41/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 1496, 'eps': 0.0, 'buffer_size': 1496, 'q_loss': 2.2678375244140625, 'mean_q_value': 0.1309986412525177, 'max_q_value': 0.32885485887527466, 'min_q_value': -0.2657712996006012, 'mean_td_error': 0.11238736, 'max_td_error': 0.724228, 'mean_weight': 0.5830061435699463}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0232,  0.0506,  0.0526, -0.1092]], device='cuda:0'), reward is -0.99\n",
      "Episode 42/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 1518, 'eps': 0.0, 'buffer_size': 1518, 'q_loss': 1.5645511150360107, 'mean_q_value': 0.04465775191783905, 'max_q_value': 0.26821663975715637, 'min_q_value': -0.7086746692657471, 'mean_td_error': 0.10634949, 'max_td_error': 0.6802801, 'mean_weight': 0.4078993797302246}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1205, -0.1374, -0.1699, -0.1941]], device='cuda:0'), reward is -0.99\n",
      "Episode 43/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 1545, 'eps': 0.0, 'buffer_size': 1545, 'q_loss': 1.5747545957565308, 'mean_q_value': 0.007534809410572052, 'max_q_value': 0.24870675802230835, 'min_q_value': -0.7168686985969543, 'mean_td_error': 0.11092457, 'max_td_error': 0.5378984, 'mean_weight': 0.4116203486919403}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1112, 0.1190, 0.0569, 0.2419]], device='cuda:0'), reward is -0.99\n",
      "Episode 44/1000000: {'total_return': -0.94, 'steps': 6, 'total_steps': 1551, 'eps': 0.0, 'buffer_size': 1551, 'q_loss': 1.699082374572754, 'mean_q_value': -0.03184184059500694, 'max_q_value': 0.2344638854265213, 'min_q_value': -0.8322430849075317, 'mean_td_error': 0.12220313, 'max_td_error': 0.6701649, 'mean_weight': 0.4434747099876404}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0621, 0.0852, 0.0935, 0.0667]], device='cuda:0'), reward is -0.99\n",
      "Episode 45/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 1582, 'eps': 0.0, 'buffer_size': 1582, 'q_loss': 2.5051181316375732, 'mean_q_value': 0.03970770537853241, 'max_q_value': 0.3420799672603607, 'min_q_value': -0.7347974181175232, 'mean_td_error': 0.07919085, 'max_td_error': 0.35447294, 'mean_weight': 0.6496126651763916}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7477, -0.0552,  0.1638, -0.1897]], device='cuda:0'), reward is -0.99\n",
      "Episode 46/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 1639, 'eps': 0.0, 'buffer_size': 1639, 'q_loss': 1.5566314458847046, 'mean_q_value': 0.015410385094583035, 'max_q_value': 0.25769510865211487, 'min_q_value': -0.9614760875701904, 'mean_td_error': 0.06374443, 'max_td_error': 0.31761825, 'mean_weight': 0.4198185205459595}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1089, 0.1457, 0.0942, 0.1126]], device='cuda:0'), reward is -0.99\n",
      "Episode 47/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 1667, 'eps': 0.0, 'buffer_size': 1667, 'q_loss': 2.077849864959717, 'mean_q_value': -0.005724774673581123, 'max_q_value': 0.2789798676967621, 'min_q_value': -0.8529037237167358, 'mean_td_error': 0.14048618, 'max_td_error': 1.0721663, 'mean_weight': 0.5956668257713318}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3979, -0.1786, -0.2085, -0.2606]], device='cuda:0'), reward is -0.99\n",
      "Episode 48/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 1709, 'eps': 0.0, 'buffer_size': 1709, 'q_loss': 2.005099296569824, 'mean_q_value': 0.03870193660259247, 'max_q_value': 0.3844015300273895, 'min_q_value': -1.0032124519348145, 'mean_td_error': 0.08702095, 'max_td_error': 0.34988546, 'mean_weight': 0.5414645671844482}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5133, -0.2886, -0.1720, -0.4336]], device='cuda:0'), reward is -0.99\n",
      "Episode 49/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 1762, 'eps': 0.0, 'buffer_size': 1762, 'q_loss': 2.3221843242645264, 'mean_q_value': 0.038480713963508606, 'max_q_value': 0.3619592785835266, 'min_q_value': -0.7315037250518799, 'mean_td_error': 0.121952444, 'max_td_error': 0.69472355, 'mean_weight': 0.6048900485038757}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8338, -0.7662, -0.8413, -0.8368]], device='cuda:0'), reward is -0.99\n",
      "Episode 50/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 1796, 'eps': 0.0, 'buffer_size': 1796, 'q_loss': 1.8435609340667725, 'mean_q_value': 0.06297777593135834, 'max_q_value': 0.2565104365348816, 'min_q_value': -0.9318894743919373, 'mean_td_error': 0.09779267, 'max_td_error': 0.86174685, 'mean_weight': 0.48371708393096924}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1605,  0.0194, -0.0241, -0.1029]], device='cuda:0'), reward is -0.99\n",
      "Episode 51/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 1836, 'eps': 0.0, 'buffer_size': 1836, 'q_loss': 2.2776377201080322, 'mean_q_value': 0.05073346942663193, 'max_q_value': 0.2990702688694, 'min_q_value': -0.7926530241966248, 'mean_td_error': 0.09300157, 'max_td_error': 0.48318613, 'mean_weight': 0.5975175499916077}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0706, 0.0742, 0.0986, 0.0097]], device='cuda:0'), reward is -0.99\n",
      "Episode 52/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 1859, 'eps': 0.0, 'buffer_size': 1859, 'q_loss': 1.6298537254333496, 'mean_q_value': 0.054625868797302246, 'max_q_value': 0.311443567276001, 'min_q_value': -0.8331299424171448, 'mean_td_error': 0.120468855, 'max_td_error': 0.99549735, 'mean_weight': 0.4386686086654663}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2047,  0.0880,  0.2293,  0.0094]], device='cuda:0'), reward is -0.99\n",
      "Episode 53/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 1903, 'eps': 0.0, 'buffer_size': 1903, 'q_loss': 1.7327128648757935, 'mean_q_value': -0.014517602510750294, 'max_q_value': 0.23383602499961853, 'min_q_value': -0.9596326351165771, 'mean_td_error': 0.074897036, 'max_td_error': 0.23769629, 'mean_weight': 0.48205578327178955}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0668, 0.0558, 0.0284, 0.0617]], device='cuda:0'), reward is -0.99\n",
      "Episode 54/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 1932, 'eps': 0.0, 'buffer_size': 1932, 'q_loss': 1.7985737323760986, 'mean_q_value': 0.08959214389324188, 'max_q_value': 0.2739484906196594, 'min_q_value': -0.8532508015632629, 'mean_td_error': 0.059480585, 'max_td_error': 0.1556378, 'mean_weight': 0.46924474835395813}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0223,  0.0148,  0.0105, -0.0369]], device='cuda:0'), reward is -0.99\n",
      "Episode 55/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 1954, 'eps': 0.0, 'buffer_size': 1954, 'q_loss': 1.9866254329681396, 'mean_q_value': 0.007145518437027931, 'max_q_value': 0.2412756085395813, 'min_q_value': -0.9481653571128845, 'mean_td_error': 0.09692863, 'max_td_error': 0.598878, 'mean_weight': 0.5362464189529419}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1041, -0.0900, -0.0889, -0.0595]], device='cuda:0'), reward is -0.99\n",
      "Episode 56/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 1970, 'eps': 0.0, 'buffer_size': 1970, 'q_loss': 2.366161346435547, 'mean_q_value': 0.013688692823052406, 'max_q_value': 0.24651819467544556, 'min_q_value': -0.7103028297424316, 'mean_td_error': 0.12023078, 'max_td_error': 0.8637471, 'mean_weight': 0.6286184191703796}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1692, 0.1321, 0.1412, 0.1115]], device='cuda:0'), reward is -0.99\n",
      "Episode 57/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 1991, 'eps': 0.0, 'buffer_size': 1991, 'q_loss': 2.4748010635375977, 'mean_q_value': 0.06015459820628166, 'max_q_value': 0.37622472643852234, 'min_q_value': -0.904638409614563, 'mean_td_error': 0.06873217, 'max_td_error': 0.25524098, 'mean_weight': 0.6570170521736145}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0583, -0.1482, -0.1270, -0.1224]], device='cuda:0'), reward is -0.99\n",
      "Episode 58/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 2011, 'eps': 0.0, 'buffer_size': 2011, 'q_loss': 2.0066113471984863, 'mean_q_value': 0.04585094749927521, 'max_q_value': 0.26347818970680237, 'min_q_value': -0.5422758460044861, 'mean_td_error': 0.12239469, 'max_td_error': 1.1175647, 'mean_weight': 0.5218108892440796}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3503, -0.1745, -0.1927, -0.2171]], device='cuda:0'), reward is -0.99\n",
      "Episode 59/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 2038, 'eps': 0.0, 'buffer_size': 2038, 'q_loss': 1.8650068044662476, 'mean_q_value': -0.06417739391326904, 'max_q_value': 0.2723887264728546, 'min_q_value': -0.9612866640090942, 'mean_td_error': 0.12079919, 'max_td_error': 0.6392495, 'mean_weight': 0.5192455053329468}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0991,  0.1727, -0.0094,  0.0126]], device='cuda:0'), reward is -0.99\n",
      "Episode 60/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 2096, 'eps': 0.0, 'buffer_size': 2096, 'q_loss': 1.9747450351715088, 'mean_q_value': 0.07392750680446625, 'max_q_value': 0.31174764037132263, 'min_q_value': -0.44201070070266724, 'mean_td_error': 0.13122845, 'max_td_error': 1.1213919, 'mean_weight': 0.5164355635643005}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7340, -0.6140, -0.4207, -0.5568]], device='cuda:0'), reward is -0.99\n",
      "Episode 61/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 2133, 'eps': 0.0, 'buffer_size': 2133, 'q_loss': 2.297640323638916, 'mean_q_value': 0.01387583464384079, 'max_q_value': 0.20236250758171082, 'min_q_value': -0.6941935420036316, 'mean_td_error': 0.16239215, 'max_td_error': 0.8417947, 'mean_weight': 0.608811616897583}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5624, -0.5643, -0.3265, -0.4964]], device='cuda:0'), reward is -0.99\n",
      "Episode 62/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 2161, 'eps': 0.0, 'buffer_size': 2161, 'q_loss': 1.6723660230636597, 'mean_q_value': 0.0324997715651989, 'max_q_value': 0.30031681060791016, 'min_q_value': -0.8721267580986023, 'mean_td_error': 0.11449103, 'max_td_error': 0.9008883, 'mean_weight': 0.4459281861782074}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2822, -0.2240, -0.2155, -0.1497]], device='cuda:0'), reward is -0.99\n",
      "Episode 63/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 2214, 'eps': 0.0, 'buffer_size': 2214, 'q_loss': 1.9330651760101318, 'mean_q_value': 0.04900268092751503, 'max_q_value': 0.31010758876800537, 'min_q_value': -0.9107744097709656, 'mean_td_error': 0.07560539, 'max_td_error': 0.47680247, 'mean_weight': 0.5178401470184326}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6009, -0.7707, -0.2046, -0.6168]], device='cuda:0'), reward is -0.99\n",
      "Episode 64/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 2244, 'eps': 0.0, 'buffer_size': 2244, 'q_loss': 1.8555481433868408, 'mean_q_value': 0.13368481397628784, 'max_q_value': 0.35302650928497314, 'min_q_value': -0.2349691540002823, 'mean_td_error': 0.075021334, 'max_td_error': 0.75503004, 'mean_weight': 0.47687259316444397}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2918, -0.2989, -0.2262, -0.1899]], device='cuda:0'), reward is -0.99\n",
      "Episode 65/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 2294, 'eps': 0.0, 'buffer_size': 2294, 'q_loss': 2.211848258972168, 'mean_q_value': 0.014996718615293503, 'max_q_value': 0.24263358116149902, 'min_q_value': -0.7456963658332825, 'mean_td_error': 0.10706275, 'max_td_error': 0.5291642, 'mean_weight': 0.5892846584320068}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1136, 0.0648, 0.1465, 0.0366]], device='cuda:0'), reward is -0.99\n",
      "Episode 66/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 2331, 'eps': 0.0, 'buffer_size': 2331, 'q_loss': 2.1209611892700195, 'mean_q_value': 0.024621743708848953, 'max_q_value': 0.26335829496383667, 'min_q_value': -0.7692775726318359, 'mean_td_error': 0.09458183, 'max_td_error': 0.5197505, 'mean_weight': 0.5614941716194153}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0981,  0.0405,  0.0344, -0.0264]], device='cuda:0'), reward is -0.99\n",
      "Episode 67/1000000: {'total_return': -0.83, 'steps': 17, 'total_steps': 2348, 'eps': 0.0, 'buffer_size': 2348, 'q_loss': 1.7933720350265503, 'mean_q_value': -0.10244864225387573, 'max_q_value': 0.29324015974998474, 'min_q_value': -0.8657127618789673, 'mean_td_error': 0.14573517, 'max_td_error': 0.6258713, 'mean_weight': 0.5440163612365723}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0358, -0.0468,  0.0434, -0.2192]], device='cuda:0'), reward is -0.99\n",
      "Episode 68/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 2375, 'eps': 0.0, 'buffer_size': 2375, 'q_loss': 1.7327748537063599, 'mean_q_value': -0.04186178743839264, 'max_q_value': 0.2351369559764862, 'min_q_value': -0.9390897750854492, 'mean_td_error': 0.12485032, 'max_td_error': 0.8930485, 'mean_weight': 0.4731508493423462}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1379,  0.0592,  0.0338, -0.0669]], device='cuda:0'), reward is -0.99\n",
      "Episode 69/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 2402, 'eps': 0.0, 'buffer_size': 2402, 'q_loss': 1.534082055091858, 'mean_q_value': 0.03199918568134308, 'max_q_value': 0.4051796793937683, 'min_q_value': -0.9124089479446411, 'mean_td_error': 0.08721321, 'max_td_error': 0.41709197, 'mean_weight': 0.41533488035202026}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7528, -0.5913, -0.4359, -0.1294]], device='cuda:0'), reward is -0.99\n",
      "Episode 70/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 2449, 'eps': 0.0, 'buffer_size': 2449, 'q_loss': 1.500734567642212, 'mean_q_value': 0.0660199522972107, 'max_q_value': 0.29481393098831177, 'min_q_value': -0.9013258814811707, 'mean_td_error': 0.10141081, 'max_td_error': 1.0463581, 'mean_weight': 0.3948865532875061}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0617, -0.0395, -0.0226, -0.0357]], device='cuda:0'), reward is -0.99\n",
      "Episode 71/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 2491, 'eps': 0.0, 'buffer_size': 2491, 'q_loss': 2.032938003540039, 'mean_q_value': -0.06892278045415878, 'max_q_value': 0.2310257852077484, 'min_q_value': -0.8562537431716919, 'mean_td_error': 0.107862726, 'max_td_error': 0.44653037, 'mean_weight': 0.5580474138259888}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3288,  0.0774,  0.0013, -0.0615]], device='cuda:0'), reward is -0.99\n",
      "Episode 72/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 2527, 'eps': 0.0, 'buffer_size': 2527, 'q_loss': 2.373731851577759, 'mean_q_value': 0.04774436354637146, 'max_q_value': 0.2593322992324829, 'min_q_value': -0.727444052696228, 'mean_td_error': 0.09569133, 'max_td_error': 0.6285491, 'mean_weight': 0.634215235710144}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7386, -0.6521, -0.6432, -0.6177]], device='cuda:0'), reward is -0.99\n",
      "Episode 73/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 2560, 'eps': 0.0, 'buffer_size': 2560, 'q_loss': 1.560235619544983, 'mean_q_value': -0.06951898336410522, 'max_q_value': 0.3674146234989166, 'min_q_value': -0.9653098583221436, 'mean_td_error': 0.15936878, 'max_td_error': 1.0172846, 'mean_weight': 0.4649888873100281}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1196, -0.1144, -0.0054, -0.1615]], device='cuda:0'), reward is -0.99\n",
      "Episode 74/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 2617, 'eps': 0.0, 'buffer_size': 2617, 'q_loss': 2.116726875305176, 'mean_q_value': -0.022736985236406326, 'max_q_value': 0.24130335450172424, 'min_q_value': -0.6918013095855713, 'mean_td_error': 0.1174232, 'max_td_error': 0.5910557, 'mean_weight': 0.5668574571609497}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2161, -0.1405, -0.1864, -0.3028]], device='cuda:0'), reward is -0.99\n",
      "Episode 75/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 2647, 'eps': 0.0, 'buffer_size': 2647, 'q_loss': 1.3187153339385986, 'mean_q_value': 0.07175809144973755, 'max_q_value': 0.33938825130462646, 'min_q_value': -0.5275932550430298, 'mean_td_error': 0.07899082, 'max_td_error': 0.40075874, 'mean_weight': 0.3374130427837372}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2516, -0.3426, -0.2879, -0.5034]], device='cuda:0'), reward is -0.99\n",
      "Episode 76/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 2677, 'eps': 0.0, 'buffer_size': 2677, 'q_loss': 2.3507542610168457, 'mean_q_value': 0.11216562986373901, 'max_q_value': 0.30288010835647583, 'min_q_value': -0.4278669059276581, 'mean_td_error': 0.07658261, 'max_td_error': 0.33536035, 'mean_weight': 0.6013635396957397}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2658, -0.0896, -0.0108, -0.1520]], device='cuda:0'), reward is -0.99\n",
      "Episode 77/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 2709, 'eps': 0.0, 'buffer_size': 2709, 'q_loss': 1.5794157981872559, 'mean_q_value': 0.00614914670586586, 'max_q_value': 0.25298574566841125, 'min_q_value': -0.9682353138923645, 'mean_td_error': 0.0626002, 'max_td_error': 0.26566434, 'mean_weight': 0.43101590871810913}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4562, -0.4277, -0.3038, -0.5739]], device='cuda:0'), reward is -0.99\n",
      "Episode 78/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 2740, 'eps': 0.0, 'buffer_size': 2740, 'q_loss': 1.9382774829864502, 'mean_q_value': 0.07783444225788116, 'max_q_value': 0.2713572382926941, 'min_q_value': -0.7072412371635437, 'mean_td_error': 0.08476654, 'max_td_error': 0.53470516, 'mean_weight': 0.5090291500091553}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0274, -0.0424,  0.0040, -0.0695]], device='cuda:0'), reward is -0.99\n",
      "Episode 79/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 2772, 'eps': 0.0, 'buffer_size': 2772, 'q_loss': 1.8301560878753662, 'mean_q_value': 0.006262622773647308, 'max_q_value': 0.297324001789093, 'min_q_value': -0.6564428806304932, 'mean_td_error': 0.11709283, 'max_td_error': 0.5270537, 'mean_weight': 0.4810277223587036}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0397, -0.0245,  0.0623, -0.0066]], device='cuda:0'), reward is -0.99\n",
      "Episode 80/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 2839, 'eps': 0.0, 'buffer_size': 2839, 'q_loss': 2.175797700881958, 'mean_q_value': 0.07578035444021225, 'max_q_value': 0.35273855924606323, 'min_q_value': -0.253399133682251, 'mean_td_error': 0.104170844, 'max_td_error': 0.9971644, 'mean_weight': 0.5601342916488647}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1269,  0.2079,  0.0554,  0.0331]], device='cuda:0'), reward is -0.99\n",
      "Episode 81/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 2864, 'eps': 0.0, 'buffer_size': 2864, 'q_loss': 1.7361985445022583, 'mean_q_value': 0.05831101909279823, 'max_q_value': 0.23859861493110657, 'min_q_value': -0.8928518295288086, 'mean_td_error': 0.061615773, 'max_td_error': 0.22290161, 'mean_weight': 0.45161157846450806}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2735, -0.0674, -0.0304, -0.1959]], device='cuda:0'), reward is -0.99\n",
      "Episode 82/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 2895, 'eps': 0.0, 'buffer_size': 2895, 'q_loss': 1.778505802154541, 'mean_q_value': 0.0038996972143650055, 'max_q_value': 0.3616529703140259, 'min_q_value': -0.9001173377037048, 'mean_td_error': 0.1214982, 'max_td_error': 0.81376576, 'mean_weight': 0.4740821421146393}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0711,  0.0544,  0.1434,  0.1227]], device='cuda:0'), reward is -0.99\n",
      "Episode 83/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 2942, 'eps': 0.0, 'buffer_size': 2942, 'q_loss': 1.9702327251434326, 'mean_q_value': -0.03805084526538849, 'max_q_value': 0.26934123039245605, 'min_q_value': -0.9939500093460083, 'mean_td_error': 0.092097715, 'max_td_error': 0.81765467, 'mean_weight': 0.5537360906600952}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1008,  0.0311,  0.0625, -0.1139]], device='cuda:0'), reward is -0.99\n",
      "Episode 84/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 2977, 'eps': 0.0, 'buffer_size': 2977, 'q_loss': 2.0722384452819824, 'mean_q_value': 0.09618102014064789, 'max_q_value': 0.25728166103363037, 'min_q_value': -0.5431740880012512, 'mean_td_error': 0.09597666, 'max_td_error': 0.94930446, 'mean_weight': 0.5465747714042664}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0285, -0.0899,  0.1106, -0.1350]], device='cuda:0'), reward is -0.99\n",
      "Episode 85/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 3051, 'eps': 0.0, 'buffer_size': 3051, 'q_loss': 2.59555721282959, 'mean_q_value': -0.006161853671073914, 'max_q_value': 0.2348983883857727, 'min_q_value': -0.9339442849159241, 'mean_td_error': 0.08244374, 'max_td_error': 0.7090694, 'mean_weight': 0.7125208973884583}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5122, -0.4297, -0.0864, -0.4606]], device='cuda:0'), reward is -0.99\n",
      "Episode 86/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 3124, 'eps': 0.0, 'buffer_size': 3124, 'q_loss': 2.223458766937256, 'mean_q_value': -0.026208100840449333, 'max_q_value': 0.2474096119403839, 'min_q_value': -0.9248659610748291, 'mean_td_error': 0.11796427, 'max_td_error': 0.7457671, 'mean_weight': 0.63108229637146}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0448, 0.0316, 0.0580, 0.0681]], device='cuda:0'), reward is -0.99\n",
      "Episode 87/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 3153, 'eps': 0.0, 'buffer_size': 3153, 'q_loss': 1.190748691558838, 'mean_q_value': -0.027138547971844673, 'max_q_value': 0.23981711268424988, 'min_q_value': -0.8737544417381287, 'mean_td_error': 0.10307558, 'max_td_error': 0.8256022, 'mean_weight': 0.32009854912757874}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6750, -0.2124, -0.2581, -0.3609]], device='cuda:0'), reward is -0.99\n",
      "Episode 88/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 3225, 'eps': 0.0, 'buffer_size': 3225, 'q_loss': 1.4480915069580078, 'mean_q_value': -0.030443619936704636, 'max_q_value': 0.3175863027572632, 'min_q_value': -0.9319571852684021, 'mean_td_error': 0.15720648, 'max_td_error': 1.1430591, 'mean_weight': 0.3950072228908539}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2802, -0.2807, -0.2439, -0.2389]], device='cuda:0'), reward is -0.99\n",
      "Episode 89/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 3258, 'eps': 0.0, 'buffer_size': 3258, 'q_loss': 1.5022025108337402, 'mean_q_value': -0.017944373190402985, 'max_q_value': 0.3693337142467499, 'min_q_value': -1.1066906452178955, 'mean_td_error': 0.08574074, 'max_td_error': 0.3193011, 'mean_weight': 0.4076576828956604}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0564, 0.1544, 0.1291, 0.1285]], device='cuda:0'), reward is -0.99\n",
      "Episode 90/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 3303, 'eps': 0.0, 'buffer_size': 3303, 'q_loss': 1.6170334815979004, 'mean_q_value': 0.059471968561410904, 'max_q_value': 0.279716819524765, 'min_q_value': -0.4200053811073303, 'mean_td_error': 0.07547008, 'max_td_error': 0.2738863, 'mean_weight': 0.42059823870658875}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0755, 0.0382, 0.0702, 0.0049]], device='cuda:0'), reward is -0.99\n",
      "Episode 91/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 3333, 'eps': 0.0, 'buffer_size': 3333, 'q_loss': 2.264716625213623, 'mean_q_value': 0.0466422364115715, 'max_q_value': 0.23468807339668274, 'min_q_value': -0.6732606291770935, 'mean_td_error': 0.09019713, 'max_td_error': 0.31673855, 'mean_weight': 0.5951943397521973}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3364, -0.6959, -0.3550, -0.2220]], device='cuda:0'), reward is -0.99\n",
      "Episode 92/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 3389, 'eps': 0.0, 'buffer_size': 3389, 'q_loss': 1.6999812126159668, 'mean_q_value': -0.012616857886314392, 'max_q_value': 0.28098732233047485, 'min_q_value': -0.9810678362846375, 'mean_td_error': 0.10848042, 'max_td_error': 1.0199208, 'mean_weight': 0.47513705492019653}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1682, -0.0623, -0.1161, -0.1488]], device='cuda:0'), reward is -0.99\n",
      "Episode 93/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 3428, 'eps': 0.0, 'buffer_size': 3428, 'q_loss': 2.203892707824707, 'mean_q_value': -0.007672417908906937, 'max_q_value': 0.39881113171577454, 'min_q_value': -0.898643434047699, 'mean_td_error': 0.06990527, 'max_td_error': 0.25410545, 'mean_weight': 0.5989830493927002}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2593, -0.5106, -0.2553, -0.5210]], device='cuda:0'), reward is -0.99\n",
      "Episode 94/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 3462, 'eps': 0.0, 'buffer_size': 3462, 'q_loss': 2.258066177368164, 'mean_q_value': 0.03981262445449829, 'max_q_value': 0.3712187111377716, 'min_q_value': -0.884275496006012, 'mean_td_error': 0.08342652, 'max_td_error': 0.87359583, 'mean_weight': 0.6263015270233154}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2342, -0.0026, -0.0051, -0.0836]], device='cuda:0'), reward is -0.99\n",
      "Episode 95/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 3487, 'eps': 0.0, 'buffer_size': 3487, 'q_loss': 2.2256646156311035, 'mean_q_value': 0.05282164365053177, 'max_q_value': 0.3032324016094208, 'min_q_value': -1.0146148204803467, 'mean_td_error': 0.047411323, 'max_td_error': 0.26612514, 'mean_weight': 0.6009862422943115}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1863, -0.2454, -0.1224, -0.1774]], device='cuda:0'), reward is -0.99\n",
      "Episode 96/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 3534, 'eps': 0.0, 'buffer_size': 3534, 'q_loss': 1.2883472442626953, 'mean_q_value': 0.036913469433784485, 'max_q_value': 0.24124768376350403, 'min_q_value': -0.9463534355163574, 'mean_td_error': 0.12963986, 'max_td_error': 0.90855813, 'mean_weight': 0.3478817343711853}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1026, -0.0711, -0.0382, -0.2351]], device='cuda:0'), reward is -0.99\n",
      "Episode 97/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 3583, 'eps': 0.0, 'buffer_size': 3583, 'q_loss': 1.7822997570037842, 'mean_q_value': -0.022874556481838226, 'max_q_value': 0.26698946952819824, 'min_q_value': -0.8080999255180359, 'mean_td_error': 0.08533307, 'max_td_error': 0.4550953, 'mean_weight': 0.4998176097869873}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0113, -0.0106,  0.0175, -0.0081]], device='cuda:0'), reward is -0.99\n",
      "Episode 98/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 3609, 'eps': 0.0, 'buffer_size': 3609, 'q_loss': 1.9899977445602417, 'mean_q_value': 0.07724594324827194, 'max_q_value': 0.35511550307273865, 'min_q_value': -0.7843409180641174, 'mean_td_error': 0.07554634, 'max_td_error': 0.34461576, 'mean_weight': 0.5329170823097229}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6797, -0.6684, -0.6181, -0.7497]], device='cuda:0'), reward is -0.99\n",
      "Episode 99/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 3661, 'eps': 0.0, 'buffer_size': 3661, 'q_loss': 1.8347370624542236, 'mean_q_value': 0.006331855431199074, 'max_q_value': 0.32519054412841797, 'min_q_value': -0.6304901242256165, 'mean_td_error': 0.10175823, 'max_td_error': 0.605021, 'mean_weight': 0.47474992275238037}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7628, -0.9184, -0.5749, -0.7041]], device='cuda:0'), reward is -0.99\n",
      "Episode 100/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 3706, 'eps': 0.0, 'buffer_size': 3706, 'q_loss': 2.2533645629882812, 'mean_q_value': 0.0054297056049108505, 'max_q_value': 0.38091015815734863, 'min_q_value': -0.9514581561088562, 'mean_td_error': 0.06125185, 'max_td_error': 0.4412173, 'mean_weight': 0.6218044757843018}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9055, -0.8685, -0.8922, -0.9399]], device='cuda:0'), reward is -0.99\n",
      "Episode 101/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 3737, 'eps': 0.0, 'buffer_size': 3737, 'q_loss': 2.008563756942749, 'mean_q_value': -0.017972996458411217, 'max_q_value': 0.37873125076293945, 'min_q_value': -0.9563856720924377, 'mean_td_error': 0.10700092, 'max_td_error': 0.53674966, 'mean_weight': 0.5558269023895264}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1989, 0.1677, 0.1811, 0.1308]], device='cuda:0'), reward is -0.99\n",
      "Episode 102/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 3761, 'eps': 0.0, 'buffer_size': 3761, 'q_loss': 1.7895267009735107, 'mean_q_value': 0.04788536578416824, 'max_q_value': 0.24976491928100586, 'min_q_value': -0.8362694382667542, 'mean_td_error': 0.11072813, 'max_td_error': 0.99027073, 'mean_weight': 0.48547282814979553}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4469, -0.4884, -0.3326, -0.2003]], device='cuda:0'), reward is -0.99\n",
      "Episode 103/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 3825, 'eps': 0.0, 'buffer_size': 3825, 'q_loss': 2.196577548980713, 'mean_q_value': -0.0023106327280402184, 'max_q_value': 0.2521701157093048, 'min_q_value': -0.9226106405258179, 'mean_td_error': 0.07943495, 'max_td_error': 0.51644844, 'mean_weight': 0.5915180444717407}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2538, -0.1968, -0.2534, -0.0566]], device='cuda:0'), reward is -0.99\n",
      "Episode 104/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 3867, 'eps': 0.0, 'buffer_size': 3867, 'q_loss': 1.7734391689300537, 'mean_q_value': 0.032891154289245605, 'max_q_value': 0.2966810464859009, 'min_q_value': -0.887488842010498, 'mean_td_error': 0.08397512, 'max_td_error': 0.48204634, 'mean_weight': 0.46779897809028625}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9280, -0.9082, -0.9152, -0.9552]], device='cuda:0'), reward is -0.99\n",
      "Episode 105/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 3896, 'eps': 0.0, 'buffer_size': 3896, 'q_loss': 1.7006490230560303, 'mean_q_value': 0.07812583446502686, 'max_q_value': 0.44370412826538086, 'min_q_value': -0.305256724357605, 'mean_td_error': 0.09065766, 'max_td_error': 1.0396001, 'mean_weight': 0.4429756700992584}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1990, -0.0988, -0.1275, -0.2065]], device='cuda:0'), reward is -0.99\n",
      "Episode 106/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 3941, 'eps': 0.0, 'buffer_size': 3941, 'q_loss': 1.8905701637268066, 'mean_q_value': 0.05101137235760689, 'max_q_value': 0.3240607976913452, 'min_q_value': -0.6610082983970642, 'mean_td_error': 0.13392127, 'max_td_error': 0.76620364, 'mean_weight': 0.509848952293396}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0011, -0.0996,  0.0927, -0.0121]], device='cuda:0'), reward is -0.99\n",
      "Episode 107/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 4015, 'eps': 0.0, 'buffer_size': 4015, 'q_loss': 2.2396011352539062, 'mean_q_value': 0.0838371142745018, 'max_q_value': 0.2681121528148651, 'min_q_value': -0.4668288826942444, 'mean_td_error': 0.045734823, 'max_td_error': 0.22671568, 'mean_weight': 0.578336238861084}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1215, -0.2217, -0.1428, -0.2109]], device='cuda:0'), reward is -0.99\n",
      "Episode 108/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 4066, 'eps': 0.0, 'buffer_size': 4066, 'q_loss': 1.5549886226654053, 'mean_q_value': 0.07744450867176056, 'max_q_value': 0.3013452887535095, 'min_q_value': -0.6793080568313599, 'mean_td_error': 0.09567269, 'max_td_error': 0.50653327, 'mean_weight': 0.40794166922569275}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4694, -0.3620, -0.6474, -0.7582]], device='cuda:0'), reward is -0.99\n",
      "Episode 109/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 4114, 'eps': 0.0, 'buffer_size': 4114, 'q_loss': 1.648702621459961, 'mean_q_value': 0.05062562972307205, 'max_q_value': 0.30918195843696594, 'min_q_value': -0.811393141746521, 'mean_td_error': 0.0894921, 'max_td_error': 0.5392144, 'mean_weight': 0.43530064821243286}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5581, -0.1085, -0.1054, -0.2741]], device='cuda:0'), reward is -0.99\n",
      "Episode 110/1000000: {'total_return': -0.08999999999999941, 'steps': 91, 'total_steps': 4205, 'eps': 0.0, 'buffer_size': 4205, 'q_loss': 1.8927898406982422, 'mean_q_value': 0.024601390585303307, 'max_q_value': 0.31569695472717285, 'min_q_value': -0.7734436392784119, 'mean_td_error': 0.07704206, 'max_td_error': 0.25516176, 'mean_weight': 0.5101503133773804}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0092, -0.0674, -0.0154, -0.0565]], device='cuda:0'), reward is -0.99\n",
      "Episode 111/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 4271, 'eps': 0.0, 'buffer_size': 4271, 'q_loss': 1.5773131847381592, 'mean_q_value': -0.01845347136259079, 'max_q_value': 0.2298131138086319, 'min_q_value': -0.8759506940841675, 'mean_td_error': 0.08183913, 'max_td_error': 0.3832246, 'mean_weight': 0.42466360330581665}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6206, -0.7858, -0.6374, -0.6877]], device='cuda:0'), reward is -0.99\n",
      "Episode 112/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 4332, 'eps': 0.0, 'buffer_size': 4332, 'q_loss': 2.3213746547698975, 'mean_q_value': -0.03712072968482971, 'max_q_value': 0.21530427038669586, 'min_q_value': -0.8751775622367859, 'mean_td_error': 0.081667155, 'max_td_error': 0.5407977, 'mean_weight': 0.6264982223510742}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2984, -0.1990, -0.3181, -0.2899]], device='cuda:0'), reward is -0.99\n",
      "Episode 113/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 4378, 'eps': 0.0, 'buffer_size': 4378, 'q_loss': 1.8207106590270996, 'mean_q_value': -0.04839298129081726, 'max_q_value': 0.284261554479599, 'min_q_value': -0.9359606504440308, 'mean_td_error': 0.12824953, 'max_td_error': 0.6275701, 'mean_weight': 0.5092486143112183}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3520, -0.6572, -0.3332, -0.3888]], device='cuda:0'), reward is -0.99\n",
      "Episode 114/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 4437, 'eps': 0.0, 'buffer_size': 4437, 'q_loss': 1.5972800254821777, 'mean_q_value': -0.020703641697764397, 'max_q_value': 0.23756931722164154, 'min_q_value': -0.7588140964508057, 'mean_td_error': 0.12284805, 'max_td_error': 0.6953168, 'mean_weight': 0.4393031597137451}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0504, -0.0769, -0.0749, -0.0615]], device='cuda:0'), reward is -0.99\n",
      "Episode 115/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 4458, 'eps': 0.0, 'buffer_size': 4458, 'q_loss': 2.149190664291382, 'mean_q_value': -0.03252624720335007, 'max_q_value': 0.2393786907196045, 'min_q_value': -0.8937612175941467, 'mean_td_error': 0.068944365, 'max_td_error': 0.3752538, 'mean_weight': 0.5984970331192017}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5821, -0.5767, -0.4364, -0.6107]], device='cuda:0'), reward is -0.99\n",
      "Episode 116/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 4493, 'eps': 0.0, 'buffer_size': 4493, 'q_loss': 2.0148677825927734, 'mean_q_value': 0.022288436070084572, 'max_q_value': 0.22865009307861328, 'min_q_value': -0.953140377998352, 'mean_td_error': 0.08226603, 'max_td_error': 0.6111863, 'mean_weight': 0.5548397898674011}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2043,  0.0460,  0.2151,  0.1213]], device='cuda:0'), reward is -0.99\n",
      "Episode 117/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 4520, 'eps': 0.0, 'buffer_size': 4520, 'q_loss': 1.6063470840454102, 'mean_q_value': -0.0031983014196157455, 'max_q_value': 0.32671016454696655, 'min_q_value': -0.7295668125152588, 'mean_td_error': 0.1187396, 'max_td_error': 0.8687761, 'mean_weight': 0.45324933528900146}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0087,  0.0348, -0.0044,  0.0178]], device='cuda:0'), reward is -0.99\n",
      "Episode 118/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 4554, 'eps': 0.0, 'buffer_size': 4554, 'q_loss': 1.714402198791504, 'mean_q_value': -0.007066020742058754, 'max_q_value': 0.23186668753623962, 'min_q_value': -0.8130353689193726, 'mean_td_error': 0.083304, 'max_td_error': 0.6639082, 'mean_weight': 0.4657387435436249}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3688, -0.0973, -0.1005, -0.1015]], device='cuda:0'), reward is -0.99\n",
      "Episode 119/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 4581, 'eps': 0.0, 'buffer_size': 4581, 'q_loss': 2.279029369354248, 'mean_q_value': 0.033604562282562256, 'max_q_value': 0.2878875136375427, 'min_q_value': -0.9657284617424011, 'mean_td_error': 0.07011671, 'max_td_error': 0.57654536, 'mean_weight': 0.6247415542602539}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6596, -0.2705, -0.2019, -0.3991]], device='cuda:0'), reward is -0.99\n",
      "Episode 120/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 4617, 'eps': 0.0, 'buffer_size': 4617, 'q_loss': 1.373486042022705, 'mean_q_value': 0.02400718256831169, 'max_q_value': 0.3015579581260681, 'min_q_value': -0.6799221634864807, 'mean_td_error': 0.06844774, 'max_td_error': 0.3802625, 'mean_weight': 0.3625327944755554}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7848, -0.3538, -0.1927, -0.3004]], device='cuda:0'), reward is -0.99\n",
      "Episode 121/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 4653, 'eps': 0.0, 'buffer_size': 4653, 'q_loss': 0.9922434687614441, 'mean_q_value': 0.062427837401628494, 'max_q_value': 0.28001129627227783, 'min_q_value': -0.8404178619384766, 'mean_td_error': 0.09677146, 'max_td_error': 1.0786211, 'mean_weight': 0.26506853103637695}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1296, -0.1484, -0.1438, -0.1484]], device='cuda:0'), reward is -0.99\n",
      "Episode 122/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 4676, 'eps': 0.0, 'buffer_size': 4676, 'q_loss': 1.9860018491744995, 'mean_q_value': 0.03916779160499573, 'max_q_value': 0.36483386158943176, 'min_q_value': -0.8248415589332581, 'mean_td_error': 0.10298024, 'max_td_error': 0.88058144, 'mean_weight': 0.5149452686309814}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0226,  0.0085,  0.0367,  0.0625]], device='cuda:0'), reward is -0.99\n",
      "Episode 123/1000000: {'total_return': -0.2899999999999996, 'steps': 71, 'total_steps': 4747, 'eps': 0.0, 'buffer_size': 4747, 'q_loss': 1.7259831428527832, 'mean_q_value': -0.10530955344438553, 'max_q_value': 0.2660619020462036, 'min_q_value': -0.9636472463607788, 'mean_td_error': 0.11730948, 'max_td_error': 0.60840714, 'mean_weight': 0.5282527208328247}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1098, -0.0717,  0.0711,  0.0984]], device='cuda:0'), reward is -0.99\n",
      "Episode 124/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 4771, 'eps': 0.0, 'buffer_size': 4771, 'q_loss': 1.7627761363983154, 'mean_q_value': -0.03866853937506676, 'max_q_value': 0.2349461019039154, 'min_q_value': -0.6895503997802734, 'mean_td_error': 0.10491182, 'max_td_error': 0.5107813, 'mean_weight': 0.48903656005859375}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0656, -0.0603,  0.0464,  0.0862]], device='cuda:0'), reward is -0.99\n",
      "Episode 125/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 4819, 'eps': 0.0, 'buffer_size': 4819, 'q_loss': 2.0737369060516357, 'mean_q_value': 0.05038595199584961, 'max_q_value': 0.259246289730072, 'min_q_value': -0.9246858954429626, 'mean_td_error': 0.04200042, 'max_td_error': 0.15066306, 'mean_weight': 0.5503733158111572}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0135,  0.0129, -0.0030, -0.0002]], device='cuda:0'), reward is -0.99\n",
      "Episode 126/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 4843, 'eps': 0.0, 'buffer_size': 4843, 'q_loss': 1.5858427286148071, 'mean_q_value': 0.026279054582118988, 'max_q_value': 0.31598713994026184, 'min_q_value': -0.4746299982070923, 'mean_td_error': 0.09604005, 'max_td_error': 0.8583523, 'mean_weight': 0.4199743866920471}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6792, -0.5676, -0.5361, -0.6821]], device='cuda:0'), reward is -0.99\n",
      "Episode 127/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 4888, 'eps': 0.0, 'buffer_size': 4888, 'q_loss': 2.1217989921569824, 'mean_q_value': 0.01598137803375721, 'max_q_value': 0.21921837329864502, 'min_q_value': -0.6392077803611755, 'mean_td_error': 0.09350307, 'max_td_error': 0.39579785, 'mean_weight': 0.5590305328369141}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6923, -0.8494, -0.6823, -0.6498]], device='cuda:0'), reward is -0.99\n",
      "Episode 128/1000000: {'total_return': -0.2899999999999996, 'steps': 71, 'total_steps': 4959, 'eps': 0.0, 'buffer_size': 4959, 'q_loss': 2.170045852661133, 'mean_q_value': -0.0502447783946991, 'max_q_value': 0.16897445917129517, 'min_q_value': -0.9390696883201599, 'mean_td_error': 0.07998047, 'max_td_error': 0.27615827, 'mean_weight': 0.5905854105949402}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4227, -0.4706, -0.0732, -0.3385]], device='cuda:0'), reward is -0.99\n",
      "Episode 129/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 4995, 'eps': 0.0, 'buffer_size': 4995, 'q_loss': 1.3272430896759033, 'mean_q_value': -0.05667653679847717, 'max_q_value': 0.240698903799057, 'min_q_value': -0.9868545532226562, 'mean_td_error': 0.11933086, 'max_td_error': 0.90143347, 'mean_weight': 0.36689493060112}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2987, -0.2183, -0.1553, -0.1431]], device='cuda:0'), reward is -0.99\n",
      "Episode 130/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 5032, 'eps': 0.0, 'buffer_size': 5032, 'q_loss': 2.127861261367798, 'mean_q_value': 0.0027740560472011566, 'max_q_value': 0.27333709597587585, 'min_q_value': -0.7066063284873962, 'mean_td_error': 0.082582146, 'max_td_error': 0.39270073, 'mean_weight': 0.5773028135299683}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0324, 0.0595, 0.0774, 0.0358]], device='cuda:0'), reward is -0.99\n",
      "Episode 131/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 5053, 'eps': 0.0, 'buffer_size': 5053, 'q_loss': 1.4058810472488403, 'mean_q_value': 0.028345033526420593, 'max_q_value': 0.24611163139343262, 'min_q_value': -0.7562994956970215, 'mean_td_error': 0.0658208, 'max_td_error': 0.23369968, 'mean_weight': 0.37118735909461975}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6728, -0.8321, -0.3596, -0.7144]], device='cuda:0'), reward is -0.99\n",
      "Episode 132/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 5093, 'eps': 0.0, 'buffer_size': 5093, 'q_loss': 1.646589994430542, 'mean_q_value': -0.03751286119222641, 'max_q_value': 0.2412203699350357, 'min_q_value': -0.8346017003059387, 'mean_td_error': 0.123751506, 'max_td_error': 0.7086011, 'mean_weight': 0.4402034878730774}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1086,  0.0681,  0.1225,  0.0232]], device='cuda:0'), reward is -0.99\n",
      "Episode 133/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 5113, 'eps': 0.0, 'buffer_size': 5113, 'q_loss': 1.5450658798217773, 'mean_q_value': 0.04272889345884323, 'max_q_value': 0.2269432544708252, 'min_q_value': -0.9460604190826416, 'mean_td_error': 0.11409509, 'max_td_error': 0.7211858, 'mean_weight': 0.4168475270271301}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1171, 0.0866, 0.1100, 0.0888]], device='cuda:0'), reward is -0.99\n",
      "Episode 134/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 5135, 'eps': 0.0, 'buffer_size': 5135, 'q_loss': 1.8555970191955566, 'mean_q_value': 0.08293423056602478, 'max_q_value': 0.36228543519973755, 'min_q_value': -0.3823193311691284, 'mean_td_error': 0.072744265, 'max_td_error': 0.4685505, 'mean_weight': 0.47886741161346436}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1695, -0.1601, -0.3518, -0.2756]], device='cuda:0'), reward is -0.99\n",
      "Episode 135/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 5174, 'eps': 0.0, 'buffer_size': 5174, 'q_loss': 2.493016242980957, 'mean_q_value': -0.04497131332755089, 'max_q_value': 0.32425209879875183, 'min_q_value': -0.755414605140686, 'mean_td_error': 0.10974267, 'max_td_error': 0.6712465, 'mean_weight': 0.6496968865394592}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0282,  0.0943,  0.0907,  0.1321]], device='cuda:0'), reward is -0.99\n",
      "Episode 136/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 5202, 'eps': 0.0, 'buffer_size': 5202, 'q_loss': 2.0048835277557373, 'mean_q_value': 0.08020374178886414, 'max_q_value': 0.2718120515346527, 'min_q_value': -0.540493369102478, 'mean_td_error': 0.072797805, 'max_td_error': 0.4495058, 'mean_weight': 0.5272123217582703}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6468, -0.7144, -0.6211, -0.6214]], device='cuda:0'), reward is -0.99\n",
      "Episode 137/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 5263, 'eps': 0.0, 'buffer_size': 5263, 'q_loss': 1.981137990951538, 'mean_q_value': 0.025798019021749496, 'max_q_value': 0.21919628977775574, 'min_q_value': -0.4871375560760498, 'mean_td_error': 0.08892468, 'max_td_error': 0.37869152, 'mean_weight': 0.5149167776107788}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0439, 0.0766, 0.0981, 0.0963]], device='cuda:0'), reward is -0.99\n",
      "Episode 138/1000000: {'total_return': -0.83, 'steps': 17, 'total_steps': 5280, 'eps': 0.0, 'buffer_size': 5280, 'q_loss': 2.0943799018859863, 'mean_q_value': 0.048043154180049896, 'max_q_value': 0.3496449887752533, 'min_q_value': -0.7980372309684753, 'mean_td_error': 0.074936375, 'max_td_error': 0.29723132, 'mean_weight': 0.5579441785812378}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0587, 0.0886, 0.1054, 0.0858]], device='cuda:0'), reward is -0.99\n",
      "Episode 139/1000000: {'total_return': -0.10999999999999943, 'steps': 89, 'total_steps': 5369, 'eps': 0.0, 'buffer_size': 5369, 'q_loss': 1.6663260459899902, 'mean_q_value': -0.06846138089895248, 'max_q_value': 0.20970889925956726, 'min_q_value': -0.7967177033424377, 'mean_td_error': 0.08811596, 'max_td_error': 0.36957824, 'mean_weight': 0.4497741460800171}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0487,  0.0220,  0.0657, -0.0309]], device='cuda:0'), reward is -0.99\n",
      "Episode 140/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 5433, 'eps': 0.0, 'buffer_size': 5433, 'q_loss': 1.7530088424682617, 'mean_q_value': 0.03268538415431976, 'max_q_value': 0.265299528837204, 'min_q_value': -0.4523892402648926, 'mean_td_error': 0.0979668, 'max_td_error': 0.53760993, 'mean_weight': 0.4629289507865906}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6660, -0.9156, -0.6317, -0.7499]], device='cuda:0'), reward is -0.99\n",
      "Episode 141/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 5464, 'eps': 0.0, 'buffer_size': 5464, 'q_loss': 1.9573121070861816, 'mean_q_value': 0.044160954654216766, 'max_q_value': 0.2616027891635895, 'min_q_value': -0.8261216282844543, 'mean_td_error': 0.07965433, 'max_td_error': 0.49829948, 'mean_weight': 0.5296444892883301}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2269, -0.1905, -0.2998, -0.4279]], device='cuda:0'), reward is -0.99\n",
      "Episode 142/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 5504, 'eps': 0.0, 'buffer_size': 5504, 'q_loss': 1.5549863576889038, 'mean_q_value': 0.016381267458200455, 'max_q_value': 0.3320099115371704, 'min_q_value': -0.6949931383132935, 'mean_td_error': 0.10402239, 'max_td_error': 0.50458986, 'mean_weight': 0.414751261472702}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3855, -0.6822, -0.2363, -0.3815]], device='cuda:0'), reward is -0.99\n",
      "Episode 143/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 5552, 'eps': 0.0, 'buffer_size': 5552, 'q_loss': 1.95822274684906, 'mean_q_value': -0.06444282084703445, 'max_q_value': 0.2845459580421448, 'min_q_value': -0.9538413882255554, 'mean_td_error': 0.10255152, 'max_td_error': 0.6528597, 'mean_weight': 0.5332582592964172}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1518, -0.4431,  0.0711, -0.3075]], device='cuda:0'), reward is -0.99\n",
      "Episode 144/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 5585, 'eps': 0.0, 'buffer_size': 5585, 'q_loss': 1.896744966506958, 'mean_q_value': 0.058411650359630585, 'max_q_value': 0.34699493646621704, 'min_q_value': -0.7375940084457397, 'mean_td_error': 0.057522006, 'max_td_error': 0.26451117, 'mean_weight': 0.5019240975379944}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8401, -0.5474, -0.6245, -0.7332]], device='cuda:0'), reward is -0.99\n",
      "Episode 145/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 5646, 'eps': 0.0, 'buffer_size': 5646, 'q_loss': 1.866239070892334, 'mean_q_value': -0.04111725091934204, 'max_q_value': 0.3638361096382141, 'min_q_value': -0.8712282776832581, 'mean_td_error': 0.102051966, 'max_td_error': 0.6700397, 'mean_weight': 0.5230210423469543}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2494, -0.1459, -0.2268, -0.2568]], device='cuda:0'), reward is -0.99\n",
      "Episode 146/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 5703, 'eps': 0.0, 'buffer_size': 5703, 'q_loss': 2.0402092933654785, 'mean_q_value': -0.03027372807264328, 'max_q_value': 0.25012803077697754, 'min_q_value': -0.8170087933540344, 'mean_td_error': 0.087778, 'max_td_error': 0.48578578, 'mean_weight': 0.5682716369628906}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3842, -0.3841, -0.0880,  0.1621]], device='cuda:0'), reward is -0.99\n",
      "Episode 147/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 5739, 'eps': 0.0, 'buffer_size': 5739, 'q_loss': 2.3308119773864746, 'mean_q_value': 0.050119198858737946, 'max_q_value': 0.3397449254989624, 'min_q_value': -0.5505750179290771, 'mean_td_error': 0.08246669, 'max_td_error': 0.37008, 'mean_weight': 0.6209810376167297}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2874, -0.3904, -0.3050, -0.3492]], device='cuda:0'), reward is -0.99\n",
      "Episode 148/1000000: {'total_return': -0.1899999999999995, 'steps': 81, 'total_steps': 5820, 'eps': 0.0, 'buffer_size': 5820, 'q_loss': 1.6380290985107422, 'mean_q_value': 0.11636678874492645, 'max_q_value': 0.34350574016571045, 'min_q_value': -0.8337138295173645, 'mean_td_error': 0.12760061, 'max_td_error': 0.88568753, 'mean_weight': 0.4332697093486786}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6560, -0.6545, -0.5896, -0.6548]], device='cuda:0'), reward is -0.99\n",
      "Episode 149/1000000: {'total_return': -0.0699999999999994, 'steps': 93, 'total_steps': 5913, 'eps': 0.0, 'buffer_size': 5913, 'q_loss': 1.349215030670166, 'mean_q_value': 0.05053987354040146, 'max_q_value': 0.29847216606140137, 'min_q_value': -0.5765597224235535, 'mean_td_error': 0.065644175, 'max_td_error': 0.20588186, 'mean_weight': 0.3530278205871582}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6640, -0.4330, -0.5404, -0.4870]], device='cuda:0'), reward is -0.99\n",
      "Episode 150/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 5959, 'eps': 0.0, 'buffer_size': 5959, 'q_loss': 1.8909366130828857, 'mean_q_value': 0.008348224684596062, 'max_q_value': 0.2631320357322693, 'min_q_value': -0.869261622428894, 'mean_td_error': 0.085514285, 'max_td_error': 0.34875667, 'mean_weight': 0.5098987817764282}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5111, -0.2283,  0.0723, -0.2489]], device='cuda:0'), reward is -0.99\n",
      "Episode 151/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 5984, 'eps': 0.0, 'buffer_size': 5984, 'q_loss': 1.863991141319275, 'mean_q_value': 0.05055058002471924, 'max_q_value': 0.2287290394306183, 'min_q_value': -0.6907691955566406, 'mean_td_error': 0.116211906, 'max_td_error': 1.0068198, 'mean_weight': 0.5021400451660156}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0701, 0.0252, 0.0454, 0.0448]], device='cuda:0'), reward is -0.99\n",
      "Episode 152/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 6024, 'eps': 0.0, 'buffer_size': 6024, 'q_loss': 2.4425411224365234, 'mean_q_value': 0.03686527535319328, 'max_q_value': 0.2566996216773987, 'min_q_value': -0.4861237406730652, 'mean_td_error': 0.085344955, 'max_td_error': 0.3790716, 'mean_weight': 0.6364988088607788}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0760, -0.2514,  0.1590, -0.0203]], device='cuda:0'), reward is -0.99\n",
      "Episode 153/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 6048, 'eps': 0.0, 'buffer_size': 6048, 'q_loss': 2.100989580154419, 'mean_q_value': -0.012606271542608738, 'max_q_value': 0.2804572880268097, 'min_q_value': -0.9013444781303406, 'mean_td_error': 0.07603331, 'max_td_error': 0.2546777, 'mean_weight': 0.596406102180481}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8820, -0.7821, -0.7397, -0.8751]], device='cuda:0'), reward is -0.99\n",
      "Episode 154/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 6092, 'eps': 0.0, 'buffer_size': 6092, 'q_loss': 2.206719398498535, 'mean_q_value': 0.020739935338497162, 'max_q_value': 0.2263387143611908, 'min_q_value': -0.7187583446502686, 'mean_td_error': 0.06693569, 'max_td_error': 0.53545845, 'mean_weight': 0.5779271721839905}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1239, -0.1381, -0.0128, -0.1662]], device='cuda:0'), reward is -0.99\n",
      "Episode 155/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 6117, 'eps': 0.0, 'buffer_size': 6117, 'q_loss': 1.7501424551010132, 'mean_q_value': 0.01834835298359394, 'max_q_value': 0.2848425805568695, 'min_q_value': -0.7833541035652161, 'mean_td_error': 0.09138085, 'max_td_error': 0.8013096, 'mean_weight': 0.4834180176258087}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8000, -0.4209, -0.6735, -0.6447]], device='cuda:0'), reward is -0.99\n",
      "Episode 156/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 6149, 'eps': 0.0, 'buffer_size': 6149, 'q_loss': 1.4684005975723267, 'mean_q_value': -0.02005583792924881, 'max_q_value': 0.2555675208568573, 'min_q_value': -0.7850582599639893, 'mean_td_error': 0.08366447, 'max_td_error': 0.42474115, 'mean_weight': 0.40141963958740234}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0566, 0.0691, 0.0907, 0.0621]], device='cuda:0'), reward is -0.99\n",
      "Episode 157/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 6168, 'eps': 0.0, 'buffer_size': 6168, 'q_loss': 1.5042935609817505, 'mean_q_value': -0.14774256944656372, 'max_q_value': 0.18768900632858276, 'min_q_value': -0.950178861618042, 'mean_td_error': 0.10462931, 'max_td_error': 0.52289176, 'mean_weight': 0.46657490730285645}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5365, -0.6595, -0.4386, -0.4835]], device='cuda:0'), reward is -0.99\n",
      "Episode 158/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 6202, 'eps': 0.0, 'buffer_size': 6202, 'q_loss': 1.6619354486465454, 'mean_q_value': -0.014314495958387852, 'max_q_value': 0.233831986784935, 'min_q_value': -0.9689358472824097, 'mean_td_error': 0.06141758, 'max_td_error': 0.24517938, 'mean_weight': 0.457300066947937}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4157,  0.0085, -0.0377, -0.0800]], device='cuda:0'), reward is -0.99\n",
      "Episode 159/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 6245, 'eps': 0.0, 'buffer_size': 6245, 'q_loss': 2.084465980529785, 'mean_q_value': -0.02282942831516266, 'max_q_value': 0.31179147958755493, 'min_q_value': -0.6267789006233215, 'mean_td_error': 0.10935399, 'max_td_error': 0.5215908, 'mean_weight': 0.5608538389205933}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0425,  0.0063, -0.0058, -0.0571]], device='cuda:0'), reward is -0.99\n",
      "Episode 160/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 6272, 'eps': 0.0, 'buffer_size': 6272, 'q_loss': 1.3220651149749756, 'mean_q_value': -0.012991474941372871, 'max_q_value': 0.22726240754127502, 'min_q_value': -0.7942488789558411, 'mean_td_error': 0.09695853, 'max_td_error': 0.81555456, 'mean_weight': 0.3482368588447571}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8270, -0.7529, -0.6199, -0.7658]], device='cuda:0'), reward is -0.99\n",
      "Episode 161/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 6307, 'eps': 0.0, 'buffer_size': 6307, 'q_loss': 1.9708155393600464, 'mean_q_value': 0.02988555282354355, 'max_q_value': 0.282022625207901, 'min_q_value': -0.5794858932495117, 'mean_td_error': 0.11211005, 'max_td_error': 0.6307872, 'mean_weight': 0.5235095024108887}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1243, 0.1049, 0.1364, 0.1009]], device='cuda:0'), reward is -0.99\n",
      "Episode 162/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 6348, 'eps': 0.0, 'buffer_size': 6348, 'q_loss': 2.3318190574645996, 'mean_q_value': -0.03577876463532448, 'max_q_value': 0.22333963215351105, 'min_q_value': -0.5510679483413696, 'mean_td_error': 0.101889275, 'max_td_error': 0.4607157, 'mean_weight': 0.6316352486610413}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2082, -0.1713, -0.0934, -0.1115]], device='cuda:0'), reward is -0.99\n",
      "Episode 163/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 6370, 'eps': 0.0, 'buffer_size': 6370, 'q_loss': 1.6537336111068726, 'mean_q_value': -0.011678526178002357, 'max_q_value': 0.309436172246933, 'min_q_value': -0.8761435747146606, 'mean_td_error': 0.141808, 'max_td_error': 1.0580932, 'mean_weight': 0.46424001455307007}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5007, -0.3099, -0.5427, -0.4196]], device='cuda:0'), reward is -0.99\n",
      "Episode 164/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 6404, 'eps': 0.0, 'buffer_size': 6404, 'q_loss': 2.401581048965454, 'mean_q_value': -0.03782154992222786, 'max_q_value': 0.22664864361286163, 'min_q_value': -0.9585816860198975, 'mean_td_error': 0.12571284, 'max_td_error': 1.05992, 'mean_weight': 0.6694768667221069}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1298, -0.1275, -0.1205, -0.1656]], device='cuda:0'), reward is -0.99\n",
      "Episode 165/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 6445, 'eps': 0.0, 'buffer_size': 6445, 'q_loss': 1.880162000656128, 'mean_q_value': 0.10451214015483856, 'max_q_value': 0.33741819858551025, 'min_q_value': -0.34696412086486816, 'mean_td_error': 0.09555839, 'max_td_error': 0.5554087, 'mean_weight': 0.49520814418792725}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4370, -0.3196, -0.0867, -0.3446]], device='cuda:0'), reward is -0.99\n",
      "Episode 166/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 6468, 'eps': 0.0, 'buffer_size': 6468, 'q_loss': 2.307941436767578, 'mean_q_value': -0.038324274122714996, 'max_q_value': 0.40130606293678284, 'min_q_value': -0.910335898399353, 'mean_td_error': 0.08488925, 'max_td_error': 0.6354193, 'mean_weight': 0.6435487270355225}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2335, -0.0987, -0.2352, -0.3362]], device='cuda:0'), reward is -0.99\n",
      "Episode 167/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 6493, 'eps': 0.0, 'buffer_size': 6493, 'q_loss': 1.8569462299346924, 'mean_q_value': -0.016291135922074318, 'max_q_value': 0.281905859708786, 'min_q_value': -0.8206784725189209, 'mean_td_error': 0.06490296, 'max_td_error': 0.26016662, 'mean_weight': 0.5055454969406128}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4264, -0.4042, -0.3759, -0.4343]], device='cuda:0'), reward is -0.99\n",
      "Episode 168/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 6522, 'eps': 0.0, 'buffer_size': 6522, 'q_loss': 1.954244613647461, 'mean_q_value': -0.05920593440532684, 'max_q_value': 0.2525043487548828, 'min_q_value': -0.9100270867347717, 'mean_td_error': 0.14452931, 'max_td_error': 0.7958976, 'mean_weight': 0.5561425685882568}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4844, -0.7102, -0.5719, -0.5935]], device='cuda:0'), reward is -0.99\n",
      "Episode 169/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 6567, 'eps': 0.0, 'buffer_size': 6567, 'q_loss': 1.3532071113586426, 'mean_q_value': 0.023439764976501465, 'max_q_value': 0.34177762269973755, 'min_q_value': -0.7897050380706787, 'mean_td_error': 0.093897715, 'max_td_error': 0.5269891, 'mean_weight': 0.36626946926116943}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1326, 0.0937, 0.1259, 0.0958]], device='cuda:0'), reward is -0.99\n",
      "Episode 170/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 6614, 'eps': 0.0, 'buffer_size': 6614, 'q_loss': 2.2943801879882812, 'mean_q_value': 0.01282430998980999, 'max_q_value': 0.24592819809913635, 'min_q_value': -0.7166698575019836, 'mean_td_error': 0.08927617, 'max_td_error': 0.37733865, 'mean_weight': 0.6089752316474915}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6466, -0.4350, -0.5961, -0.6973]], device='cuda:0'), reward is -0.99\n",
      "Episode 171/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 6666, 'eps': 0.0, 'buffer_size': 6666, 'q_loss': 2.171759843826294, 'mean_q_value': 0.05586179718375206, 'max_q_value': 0.2596922218799591, 'min_q_value': -0.9452557563781738, 'mean_td_error': 0.104503915, 'max_td_error': 0.8618415, 'mean_weight': 0.5929498076438904}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1561, 0.1124, 0.1502, 0.1425]], device='cuda:0'), reward is -0.99\n",
      "Episode 172/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 6695, 'eps': 0.0, 'buffer_size': 6695, 'q_loss': 2.220864772796631, 'mean_q_value': 0.04628317803144455, 'max_q_value': 0.33404362201690674, 'min_q_value': -0.7182066440582275, 'mean_td_error': 0.07478966, 'max_td_error': 0.31214333, 'mean_weight': 0.5949184894561768}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0137,  0.1227,  0.1949,  0.1119]], device='cuda:0'), reward is -0.99\n",
      "Episode 173/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 6716, 'eps': 0.0, 'buffer_size': 6716, 'q_loss': 1.4817270040512085, 'mean_q_value': 0.008650276809930801, 'max_q_value': 0.29972729086875916, 'min_q_value': -0.9648128151893616, 'mean_td_error': 0.14274871, 'max_td_error': 1.1435294, 'mean_weight': 0.40739133954048157}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7339, -0.7605, -0.7160, -0.6899]], device='cuda:0'), reward is -0.99\n",
      "Episode 174/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 6763, 'eps': 0.0, 'buffer_size': 6763, 'q_loss': 2.3014724254608154, 'mean_q_value': 0.037474364042282104, 'max_q_value': 0.32348281145095825, 'min_q_value': -0.9295174479484558, 'mean_td_error': 0.07734233, 'max_td_error': 0.6334119, 'mean_weight': 0.6138128638267517}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1720, 0.1852, 0.1964, 0.1972]], device='cuda:0'), reward is -0.99\n",
      "Episode 175/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 6783, 'eps': 0.0, 'buffer_size': 6783, 'q_loss': 1.7800335884094238, 'mean_q_value': 0.012323969975113869, 'max_q_value': 0.3255484104156494, 'min_q_value': -0.9759988784790039, 'mean_td_error': 0.06973414, 'max_td_error': 0.43099248, 'mean_weight': 0.4872840642929077}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3213, -0.3856, -0.2835, -0.2851]], device='cuda:0'), reward is -0.99\n",
      "Episode 176/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 6839, 'eps': 0.0, 'buffer_size': 6839, 'q_loss': 1.6009886264801025, 'mean_q_value': -0.059014614671468735, 'max_q_value': 0.24319660663604736, 'min_q_value': -0.7946620583534241, 'mean_td_error': 0.087773696, 'max_td_error': 0.37747538, 'mean_weight': 0.4325467050075531}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0862, -0.0256,  0.0078,  0.0099]], device='cuda:0'), reward is -0.99\n",
      "Episode 177/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 6864, 'eps': 0.0, 'buffer_size': 6864, 'q_loss': 1.9044687747955322, 'mean_q_value': 0.06856684386730194, 'max_q_value': 0.21503886580467224, 'min_q_value': -0.32028019428253174, 'mean_td_error': 0.03918816, 'max_td_error': 0.15062292, 'mean_weight': 0.4998995065689087}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9293, -0.9491, -0.9150, -0.9510]], device='cuda:0'), reward is -0.99\n",
      "Episode 178/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 6894, 'eps': 0.0, 'buffer_size': 6894, 'q_loss': 1.5634533166885376, 'mean_q_value': -0.11910919845104218, 'max_q_value': 0.2883331775665283, 'min_q_value': -0.8831446766853333, 'mean_td_error': 0.11518587, 'max_td_error': 0.6927242, 'mean_weight': 0.44715598225593567}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3351, -0.2987, -0.3271, -0.3754]], device='cuda:0'), reward is -0.99\n",
      "Episode 179/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 6936, 'eps': 0.0, 'buffer_size': 6936, 'q_loss': 1.246243953704834, 'mean_q_value': -0.01598895713686943, 'max_q_value': 0.3224242925643921, 'min_q_value': -0.8874784111976624, 'mean_td_error': 0.06555684, 'max_td_error': 0.284468, 'mean_weight': 0.34492218494415283}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4710, -0.1610, -0.2866, -0.4720]], device='cuda:0'), reward is -0.99\n",
      "Episode 180/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 6969, 'eps': 0.0, 'buffer_size': 6969, 'q_loss': 2.0613152980804443, 'mean_q_value': 0.02290436066687107, 'max_q_value': 0.25398150086402893, 'min_q_value': -0.8675134181976318, 'mean_td_error': 0.0778673, 'max_td_error': 0.41979092, 'mean_weight': 0.5547688007354736}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1757, 0.1639, 0.1620, 0.1728]], device='cuda:0'), reward is -0.99\n",
      "Episode 181/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 6991, 'eps': 0.0, 'buffer_size': 6991, 'q_loss': 1.1801247596740723, 'mean_q_value': 0.019704680889844894, 'max_q_value': 0.24312366545200348, 'min_q_value': -0.5963665246963501, 'mean_td_error': 0.09905641, 'max_td_error': 0.9919618, 'mean_weight': 0.3161476254463196}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1036, 0.1145, 0.0886, 0.1018]], device='cuda:0'), reward is -0.99\n",
      "Episode 182/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 7012, 'eps': 0.0, 'buffer_size': 7012, 'q_loss': 1.9817469120025635, 'mean_q_value': -0.07437742501497269, 'max_q_value': 0.21709096431732178, 'min_q_value': -0.8551413416862488, 'mean_td_error': 0.06883217, 'max_td_error': 0.42496595, 'mean_weight': 0.5500556230545044}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0106, 0.1234, 0.1449, 0.0111]], device='cuda:0'), reward is -0.99\n",
      "Episode 183/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 7039, 'eps': 0.0, 'buffer_size': 7039, 'q_loss': 1.7107386589050293, 'mean_q_value': 0.018852990120649338, 'max_q_value': 0.30891314148902893, 'min_q_value': -0.8373050689697266, 'mean_td_error': 0.073650524, 'max_td_error': 0.46916938, 'mean_weight': 0.4756881594657898}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8008, -0.9086, -0.7743, -0.8945]], device='cuda:0'), reward is -0.99\n",
      "Episode 184/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 7073, 'eps': 0.0, 'buffer_size': 7073, 'q_loss': 1.5435125827789307, 'mean_q_value': 0.012155757285654545, 'max_q_value': 0.286431223154068, 'min_q_value': -0.9297785758972168, 'mean_td_error': 0.08188022, 'max_td_error': 0.512132, 'mean_weight': 0.42702844738960266}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1976, -0.2219, -0.1827, -0.2280]], device='cuda:0'), reward is -0.99\n",
      "Episode 185/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 7119, 'eps': 0.0, 'buffer_size': 7119, 'q_loss': 1.7687177658081055, 'mean_q_value': 0.029658706858754158, 'max_q_value': 0.3063199520111084, 'min_q_value': -0.9799920916557312, 'mean_td_error': 0.05277579, 'max_td_error': 0.38536274, 'mean_weight': 0.4859098792076111}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2016, -0.1425, -0.1830, -0.2281]], device='cuda:0'), reward is -0.99\n",
      "Episode 186/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 7167, 'eps': 0.0, 'buffer_size': 7167, 'q_loss': 1.5868003368377686, 'mean_q_value': -0.025716744363307953, 'max_q_value': 0.3179221749305725, 'min_q_value': -0.8290016055107117, 'mean_td_error': 0.08395906, 'max_td_error': 0.52236, 'mean_weight': 0.4423801600933075}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6366, -0.7446, -0.5901, -0.7853]], device='cuda:0'), reward is -0.99\n",
      "Episode 187/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 7201, 'eps': 0.0, 'buffer_size': 7201, 'q_loss': 2.6458585262298584, 'mean_q_value': 0.061221759766340256, 'max_q_value': 0.34683817625045776, 'min_q_value': -0.8830887079238892, 'mean_td_error': 0.04135277, 'max_td_error': 0.1330137, 'mean_weight': 0.7116271257400513}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2565, -0.5333, -0.2307, -0.1964]], device='cuda:0'), reward is -0.99\n",
      "Episode 188/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 7244, 'eps': 0.0, 'buffer_size': 7244, 'q_loss': 1.6992175579071045, 'mean_q_value': -0.0116660101339221, 'max_q_value': 0.21521063148975372, 'min_q_value': -0.8139561414718628, 'mean_td_error': 0.1037215, 'max_td_error': 0.70648944, 'mean_weight': 0.4757227301597595}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1786, -0.1831, -0.1294, -0.1424]], device='cuda:0'), reward is -0.99\n",
      "Episode 189/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 7293, 'eps': 0.0, 'buffer_size': 7293, 'q_loss': 1.9577885866165161, 'mean_q_value': 0.056126147508621216, 'max_q_value': 0.33024734258651733, 'min_q_value': -0.9829382300376892, 'mean_td_error': 0.06715783, 'max_td_error': 0.3180785, 'mean_weight': 0.5316216945648193}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3518, -0.2613, -0.5315, -0.3404]], device='cuda:0'), reward is -0.99\n",
      "Episode 190/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 7314, 'eps': 0.0, 'buffer_size': 7314, 'q_loss': 1.5809036493301392, 'mean_q_value': -0.04419751465320587, 'max_q_value': 0.26909422874450684, 'min_q_value': -0.9481613039970398, 'mean_td_error': 0.11005718, 'max_td_error': 0.6383563, 'mean_weight': 0.4410460293292999}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8526, -0.7959, -0.7442, -0.8026]], device='cuda:0'), reward is -0.99\n",
      "Episode 191/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 7365, 'eps': 0.0, 'buffer_size': 7365, 'q_loss': 2.1161866188049316, 'mean_q_value': 0.012316521257162094, 'max_q_value': 0.2568131685256958, 'min_q_value': -0.8966148495674133, 'mean_td_error': 0.057173025, 'max_td_error': 0.3604049, 'mean_weight': 0.5785974860191345}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7566, -0.8498, -0.5878, -0.7447]], device='cuda:0'), reward is -0.99\n",
      "Episode 192/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 7400, 'eps': 0.0, 'buffer_size': 7400, 'q_loss': 1.8043642044067383, 'mean_q_value': -0.1237620934844017, 'max_q_value': 0.2066543698310852, 'min_q_value': -0.9762412905693054, 'mean_td_error': 0.098030366, 'max_td_error': 0.49279577, 'mean_weight': 0.5491106510162354}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0065, -0.0847,  0.0358, -0.0892]], device='cuda:0'), reward is -0.99\n",
      "Episode 193/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 7463, 'eps': 0.0, 'buffer_size': 7463, 'q_loss': 1.547481656074524, 'mean_q_value': -0.0412110909819603, 'max_q_value': 0.2058085799217224, 'min_q_value': -0.6530731916427612, 'mean_td_error': 0.10335508, 'max_td_error': 0.7043028, 'mean_weight': 0.4248533248901367}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4703, -0.7194, -0.4022, -0.4268]], device='cuda:0'), reward is -0.99\n",
      "Episode 194/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 7490, 'eps': 0.0, 'buffer_size': 7490, 'q_loss': 1.4739959239959717, 'mean_q_value': -0.052303217351436615, 'max_q_value': 0.26562073826789856, 'min_q_value': -0.9068124890327454, 'mean_td_error': 0.074160226, 'max_td_error': 0.453584, 'mean_weight': 0.40800392627716064}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7178, -0.9328, -0.7772, -0.8113]], device='cuda:0'), reward is -0.99\n",
      "Episode 195/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 7547, 'eps': 0.0, 'buffer_size': 7547, 'q_loss': 1.765512228012085, 'mean_q_value': -0.03677593916654587, 'max_q_value': 0.222774937748909, 'min_q_value': -0.822944700717926, 'mean_td_error': 0.09308307, 'max_td_error': 0.406249, 'mean_weight': 0.48605361580848694}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0052,  0.0008,  0.0020,  0.0283]], device='cuda:0'), reward is -0.99\n",
      "Episode 196/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 7568, 'eps': 0.0, 'buffer_size': 7568, 'q_loss': 1.696913242340088, 'mean_q_value': -0.009586658328771591, 'max_q_value': 0.2782438397407532, 'min_q_value': -0.7852793335914612, 'mean_td_error': 0.08626123, 'max_td_error': 0.66617566, 'mean_weight': 0.4678666293621063}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7854, -0.7869, -0.6956, -0.6798]], device='cuda:0'), reward is -0.99\n",
      "Episode 197/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 7619, 'eps': 0.0, 'buffer_size': 7619, 'q_loss': 1.8197619915008545, 'mean_q_value': -0.0307723768055439, 'max_q_value': 0.24430418014526367, 'min_q_value': -0.9902446866035461, 'mean_td_error': 0.068949774, 'max_td_error': 0.4204678, 'mean_weight': 0.5070328712463379}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0047,  0.1615,  0.0882, -0.0866]], device='cuda:0'), reward is -0.99\n",
      "Episode 198/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 7649, 'eps': 0.0, 'buffer_size': 7649, 'q_loss': 1.9081405401229858, 'mean_q_value': -0.015103943645954132, 'max_q_value': 0.21959447860717773, 'min_q_value': -0.8776910305023193, 'mean_td_error': 0.08188595, 'max_td_error': 0.32528177, 'mean_weight': 0.5152534246444702}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0283, -0.0320, -0.0677, -0.0319]], device='cuda:0'), reward is -0.99\n",
      "Episode 199/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 7673, 'eps': 0.0, 'buffer_size': 7673, 'q_loss': 1.594960331916809, 'mean_q_value': -0.10077202320098877, 'max_q_value': 0.2913020849227905, 'min_q_value': -0.8603183627128601, 'mean_td_error': 0.07313548, 'max_td_error': 0.32572967, 'mean_weight': 0.440375953912735}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4767, -0.6220, -0.5080, -0.5693]], device='cuda:0'), reward is -0.99\n",
      "Episode 200/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 7726, 'eps': 0.0, 'buffer_size': 7726, 'q_loss': 1.7251555919647217, 'mean_q_value': 0.002410236746072769, 'max_q_value': 0.24135839939117432, 'min_q_value': -0.8612266182899475, 'mean_td_error': 0.086547896, 'max_td_error': 0.41096592, 'mean_weight': 0.4668319821357727}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9358, -0.9457, -0.9495, -0.9462]], device='cuda:0'), reward is -0.99\n",
      "Episode 201/1000000: {'total_return': -0.0699999999999994, 'steps': 93, 'total_steps': 7819, 'eps': 0.0, 'buffer_size': 7819, 'q_loss': 2.2457520961761475, 'mean_q_value': -0.09014508873224258, 'max_q_value': 0.24895939230918884, 'min_q_value': -0.9811294078826904, 'mean_td_error': 0.10582146, 'max_td_error': 1.0144509, 'mean_weight': 0.6290425658226013}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1174, -0.0815, -0.0542, -0.0617]], device='cuda:0'), reward is -0.99\n",
      "Episode 202/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 7848, 'eps': 0.0, 'buffer_size': 7848, 'q_loss': 1.7408660650253296, 'mean_q_value': -0.03381569683551788, 'max_q_value': 0.26047828793525696, 'min_q_value': -0.9076277613639832, 'mean_td_error': 0.07236226, 'max_td_error': 0.42452604, 'mean_weight': 0.48269572854042053}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4124, -0.5220, -0.4609, -0.5084]], device='cuda:0'), reward is -0.99\n",
      "Episode 203/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 7876, 'eps': 0.0, 'buffer_size': 7876, 'q_loss': 2.032477855682373, 'mean_q_value': -0.0037581436336040497, 'max_q_value': 0.3118916153907776, 'min_q_value': -0.7748039960861206, 'mean_td_error': 0.090325445, 'max_td_error': 0.49273723, 'mean_weight': 0.5497175455093384}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1491, -0.1545, -0.1711, -0.1579]], device='cuda:0'), reward is -0.99\n",
      "Episode 204/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 7922, 'eps': 0.0, 'buffer_size': 7922, 'q_loss': 1.5297778844833374, 'mean_q_value': -0.15168529748916626, 'max_q_value': 0.3862591087818146, 'min_q_value': -0.9036508202552795, 'mean_td_error': 0.08811462, 'max_td_error': 0.5449761, 'mean_weight': 0.45947161316871643}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8394, -0.9373, -0.8475, -0.9402]], device='cuda:0'), reward is -0.99\n",
      "Episode 205/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 7957, 'eps': 0.0, 'buffer_size': 7957, 'q_loss': 1.8745933771133423, 'mean_q_value': -0.08604944497346878, 'max_q_value': 0.28016725182533264, 'min_q_value': -0.8553411960601807, 'mean_td_error': 0.12651812, 'max_td_error': 0.9166268, 'mean_weight': 0.5502316951751709}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2843, -0.0225,  0.0402, -0.4001]], device='cuda:0'), reward is -0.99\n",
      "Episode 206/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 7992, 'eps': 0.0, 'buffer_size': 7992, 'q_loss': 1.299193024635315, 'mean_q_value': 0.010792509652674198, 'max_q_value': 0.2647700309753418, 'min_q_value': -0.8851562738418579, 'mean_td_error': 0.053684253, 'max_td_error': 0.3289616, 'mean_weight': 0.3529541492462158}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2587, -0.1049, -0.1625, -0.2355]], device='cuda:0'), reward is -0.99\n",
      "Episode 207/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 8037, 'eps': 0.0, 'buffer_size': 8037, 'q_loss': 2.205615520477295, 'mean_q_value': -0.019874215126037598, 'max_q_value': 0.22632838785648346, 'min_q_value': -0.6105497479438782, 'mean_td_error': 0.07882257, 'max_td_error': 0.43774486, 'mean_weight': 0.6216026544570923}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8362, -0.7710, -0.8285, -0.8356]], device='cuda:0'), reward is -0.99\n",
      "Episode 208/1000000: {'total_return': 0.07000000000000073, 'steps': 107, 'total_steps': 8144, 'eps': 0.0, 'buffer_size': 8144, 'q_loss': 1.5743944644927979, 'mean_q_value': -0.041775740683078766, 'max_q_value': 0.21893323957920074, 'min_q_value': -0.9739216566085815, 'mean_td_error': 0.06716831, 'max_td_error': 0.4341935, 'mean_weight': 0.43086594343185425}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6376, -0.5547, -0.5126, -0.6383]], device='cuda:0'), reward is -0.99\n",
      "Episode 209/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 8189, 'eps': 0.0, 'buffer_size': 8189, 'q_loss': 1.5724756717681885, 'mean_q_value': -0.017689233645796776, 'max_q_value': 0.2705032229423523, 'min_q_value': -0.95537269115448, 'mean_td_error': 0.06943917, 'max_td_error': 0.2332722, 'mean_weight': 0.4269280433654785}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6774, -0.7698, -0.6406, -0.6528]], device='cuda:0'), reward is -0.99\n",
      "Episode 210/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 8264, 'eps': 0.0, 'buffer_size': 8264, 'q_loss': 1.509709358215332, 'mean_q_value': -0.12924382090568542, 'max_q_value': 0.245630145072937, 'min_q_value': -0.976992130279541, 'mean_td_error': 0.08575435, 'max_td_error': 0.38797906, 'mean_weight': 0.4198873043060303}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0888,  0.1458, -0.0173, -0.3994]], device='cuda:0'), reward is -0.99\n",
      "Episode 211/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 8285, 'eps': 0.0, 'buffer_size': 8285, 'q_loss': 2.172699451446533, 'mean_q_value': -0.04603539779782295, 'max_q_value': 0.25400638580322266, 'min_q_value': -0.9593214392662048, 'mean_td_error': 0.06623672, 'max_td_error': 0.4555784, 'mean_weight': 0.6091679334640503}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0657,  0.1471,  0.1321, -0.0101]], device='cuda:0'), reward is -0.99\n",
      "Episode 212/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 8308, 'eps': 0.0, 'buffer_size': 8308, 'q_loss': 1.662881851196289, 'mean_q_value': 0.0672038197517395, 'max_q_value': 0.3593752086162567, 'min_q_value': -0.7937127351760864, 'mean_td_error': 0.08078034, 'max_td_error': 0.39230815, 'mean_weight': 0.44989341497421265}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0513, -0.1626, -0.0638, -0.1011]], device='cuda:0'), reward is -0.99\n",
      "Episode 213/1000000: {'total_return': -0.14999999999999947, 'steps': 85, 'total_steps': 8393, 'eps': 0.0, 'buffer_size': 8393, 'q_loss': 1.8218905925750732, 'mean_q_value': -0.1292000263929367, 'max_q_value': 0.24374286830425262, 'min_q_value': -0.897747278213501, 'mean_td_error': 0.1092616, 'max_td_error': 0.5766406, 'mean_weight': 0.5670814514160156}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6368, -0.7360, -0.7395, -0.7390]], device='cuda:0'), reward is -0.99\n",
      "Episode 214/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 8415, 'eps': 0.0, 'buffer_size': 8415, 'q_loss': 1.6841143369674683, 'mean_q_value': -0.1685217022895813, 'max_q_value': 0.2595687210559845, 'min_q_value': -0.9974654912948608, 'mean_td_error': 0.15043677, 'max_td_error': 0.5892831, 'mean_weight': 0.48323336243629456}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3200, -0.3280, -0.2913, -0.3289]], device='cuda:0'), reward is -0.99\n",
      "Episode 215/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 8478, 'eps': 0.0, 'buffer_size': 8478, 'q_loss': 1.4705818891525269, 'mean_q_value': -0.14543624222278595, 'max_q_value': 0.24551063776016235, 'min_q_value': -0.9723135828971863, 'mean_td_error': 0.11897726, 'max_td_error': 0.6281355, 'mean_weight': 0.4216015338897705}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8294, -0.2797, -0.4612, -0.3974]], device='cuda:0'), reward is -0.99\n",
      "Episode 216/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 8503, 'eps': 0.0, 'buffer_size': 8503, 'q_loss': 1.7910635471343994, 'mean_q_value': -0.09843231737613678, 'max_q_value': 0.30705133080482483, 'min_q_value': -0.9789677858352661, 'mean_td_error': 0.12743643, 'max_td_error': 0.53051406, 'mean_weight': 0.5256366729736328}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1026, 0.0614, 0.0291, 0.0796]], device='cuda:0'), reward is -0.99\n",
      "Episode 217/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 8530, 'eps': 0.0, 'buffer_size': 8530, 'q_loss': 1.3983184099197388, 'mean_q_value': -0.09368891268968582, 'max_q_value': 0.23564767837524414, 'min_q_value': -0.9692510962486267, 'mean_td_error': 0.05962588, 'max_td_error': 0.32148898, 'mean_weight': 0.4311599135398865}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8382, -0.8445, -0.8475, -0.8791]], device='cuda:0'), reward is -0.99\n",
      "Episode 218/1000000: {'total_return': 0.19000000000000083, 'steps': 119, 'total_steps': 8649, 'eps': 0.0, 'buffer_size': 8649, 'q_loss': 1.5239574909210205, 'mean_q_value': -0.10218781977891922, 'max_q_value': 0.23678970336914062, 'min_q_value': -0.9499147534370422, 'mean_td_error': 0.08631812, 'max_td_error': 0.59346735, 'mean_weight': 0.4374643862247467}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1144, -0.1267, -0.1092, -0.0984]], device='cuda:0'), reward is -0.99\n",
      "Episode 219/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 8682, 'eps': 0.0, 'buffer_size': 8682, 'q_loss': 1.50468111038208, 'mean_q_value': -0.08725407719612122, 'max_q_value': 0.2140301614999771, 'min_q_value': -0.9553515315055847, 'mean_td_error': 0.15637201, 'max_td_error': 1.0883499, 'mean_weight': 0.44370877742767334}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1313, -0.0193,  0.0123,  0.0035]], device='cuda:0'), reward is -0.99\n",
      "Episode 220/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 8729, 'eps': 0.0, 'buffer_size': 8729, 'q_loss': 1.7946393489837646, 'mean_q_value': -0.08946225792169571, 'max_q_value': 0.2617655098438263, 'min_q_value': -1.0066524744033813, 'mean_td_error': 0.09843443, 'max_td_error': 0.9070165, 'mean_weight': 0.5079382061958313}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2006, -0.2552, -0.1556, -0.1344]], device='cuda:0'), reward is -0.99\n",
      "Episode 221/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 8764, 'eps': 0.0, 'buffer_size': 8764, 'q_loss': 1.7692883014678955, 'mean_q_value': 0.009004054591059685, 'max_q_value': 0.27662599086761475, 'min_q_value': -0.8958749175071716, 'mean_td_error': 0.058674593, 'max_td_error': 0.3579699, 'mean_weight': 0.49386703968048096}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5483, -0.4948, -0.4156, -0.4189]], device='cuda:0'), reward is -0.99\n",
      "Episode 222/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 8799, 'eps': 0.0, 'buffer_size': 8799, 'q_loss': 1.4240882396697998, 'mean_q_value': -0.016698502004146576, 'max_q_value': 0.2240636944770813, 'min_q_value': -0.8976640701293945, 'mean_td_error': 0.055255845, 'max_td_error': 0.27605763, 'mean_weight': 0.39356398582458496}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3552, -0.1253, -0.0598, -0.1426]], device='cuda:0'), reward is -0.99\n",
      "Episode 223/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 8823, 'eps': 0.0, 'buffer_size': 8823, 'q_loss': 1.6684916019439697, 'mean_q_value': -0.1338447779417038, 'max_q_value': 0.2973388433456421, 'min_q_value': -0.8106787204742432, 'mean_td_error': 0.13334715, 'max_td_error': 0.7290584, 'mean_weight': 0.49940234422683716}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7965, -0.7390, -0.7407, -0.7290]], device='cuda:0'), reward is -0.99\n",
      "Episode 224/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 8866, 'eps': 0.0, 'buffer_size': 8866, 'q_loss': 1.5061824321746826, 'mean_q_value': -0.07659149169921875, 'max_q_value': 0.3699604868888855, 'min_q_value': -0.8873280882835388, 'mean_td_error': 0.078777626, 'max_td_error': 0.46315196, 'mean_weight': 0.4373440146446228}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0799, -0.0288,  0.0285, -0.0706]], device='cuda:0'), reward is -0.99\n",
      "Episode 225/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 8886, 'eps': 0.0, 'buffer_size': 8886, 'q_loss': 1.3859740495681763, 'mean_q_value': -0.08186355233192444, 'max_q_value': 0.2301291823387146, 'min_q_value': -0.971692681312561, 'mean_td_error': 0.0794243, 'max_td_error': 0.4155071, 'mean_weight': 0.39077359437942505}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9505, -0.9847, -0.9711, -1.0008]], device='cuda:0'), reward is -0.99\n",
      "Episode 226/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 8919, 'eps': 0.0, 'buffer_size': 8919, 'q_loss': 2.3819613456726074, 'mean_q_value': -0.027095364406704903, 'max_q_value': 0.305167555809021, 'min_q_value': -0.7765897512435913, 'mean_td_error': 0.1024242, 'max_td_error': 0.43820608, 'mean_weight': 0.6773802042007446}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2609, -0.0630, -0.3283, -0.0803]], device='cuda:0'), reward is -0.99\n",
      "Episode 227/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 8946, 'eps': 0.0, 'buffer_size': 8946, 'q_loss': 1.8804235458374023, 'mean_q_value': -0.03951111435890198, 'max_q_value': 0.23186057806015015, 'min_q_value': -0.7001373767852783, 'mean_td_error': 0.1045948, 'max_td_error': 0.4940048, 'mean_weight': 0.515283465385437}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5053, -0.5412, -0.5330, -0.5696]], device='cuda:0'), reward is -0.99\n",
      "Episode 228/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 8966, 'eps': 0.0, 'buffer_size': 8966, 'q_loss': 1.9080333709716797, 'mean_q_value': -0.07170729339122772, 'max_q_value': 0.30136585235595703, 'min_q_value': -0.95063716173172, 'mean_td_error': 0.09450254, 'max_td_error': 0.5919325, 'mean_weight': 0.5545498132705688}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5092, -0.3745, -0.2205, -0.4424]], device='cuda:0'), reward is -0.99\n",
      "Episode 229/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 9018, 'eps': 0.0, 'buffer_size': 9018, 'q_loss': 2.0471858978271484, 'mean_q_value': 0.03466247767210007, 'max_q_value': 0.28760576248168945, 'min_q_value': -0.9398475289344788, 'mean_td_error': 0.05759097, 'max_td_error': 0.27331573, 'mean_weight': 0.5537729263305664}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6411, -0.6483, -0.6165, -0.7004]], device='cuda:0'), reward is -0.99\n",
      "Episode 230/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 9039, 'eps': 0.0, 'buffer_size': 9039, 'q_loss': 1.8297386169433594, 'mean_q_value': -0.03891177847981453, 'max_q_value': 0.34381014108657837, 'min_q_value': -0.9080108404159546, 'mean_td_error': 0.052935913, 'max_td_error': 0.37740183, 'mean_weight': 0.5306280851364136}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8806, -0.9478, -0.8968, -0.9118]], device='cuda:0'), reward is -0.99\n",
      "Episode 231/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 9109, 'eps': 0.0, 'buffer_size': 9109, 'q_loss': 1.2164047956466675, 'mean_q_value': -0.11319336295127869, 'max_q_value': 0.23965002596378326, 'min_q_value': -0.9772444367408752, 'mean_td_error': 0.062138546, 'max_td_error': 0.36337554, 'mean_weight': 0.3595263957977295}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0049,  0.0134, -0.0572, -0.1135]], device='cuda:0'), reward is -0.99\n",
      "Episode 232/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 9138, 'eps': 0.0, 'buffer_size': 9138, 'q_loss': 1.6175613403320312, 'mean_q_value': -0.1289861500263214, 'max_q_value': 0.2712278366088867, 'min_q_value': -0.9131633043289185, 'mean_td_error': 0.048413105, 'max_td_error': 0.18641436, 'mean_weight': 0.47395530343055725}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4011, -0.2481, -0.0305, -0.3406]], device='cuda:0'), reward is -0.99\n",
      "Episode 233/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 9163, 'eps': 0.0, 'buffer_size': 9163, 'q_loss': 2.2091660499572754, 'mean_q_value': 0.007386842742562294, 'max_q_value': 0.41330239176750183, 'min_q_value': -0.9394265413284302, 'mean_td_error': 0.07694512, 'max_td_error': 0.32319117, 'mean_weight': 0.5979328155517578}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7834, -0.8735, -0.7369, -0.8018]], device='cuda:0'), reward is -0.99\n",
      "Episode 234/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 9212, 'eps': 0.0, 'buffer_size': 9212, 'q_loss': 2.0371451377868652, 'mean_q_value': 0.0042287372052669525, 'max_q_value': 0.24982325732707977, 'min_q_value': -0.9636864066123962, 'mean_td_error': 0.06503475, 'max_td_error': 0.42109734, 'mean_weight': 0.5555394887924194}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8794, -0.8948, -0.8969, -0.8930]], device='cuda:0'), reward is -0.99\n",
      "Episode 235/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 9232, 'eps': 0.0, 'buffer_size': 9232, 'q_loss': 1.248489260673523, 'mean_q_value': -0.07253442704677582, 'max_q_value': 0.3037608861923218, 'min_q_value': -0.9316375851631165, 'mean_td_error': 0.05883884, 'max_td_error': 0.23735632, 'mean_weight': 0.35490337014198303}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8823, -0.8429, -0.7942, -0.7374]], device='cuda:0'), reward is -0.99\n",
      "Episode 236/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 9253, 'eps': 0.0, 'buffer_size': 9253, 'q_loss': 1.8674521446228027, 'mean_q_value': -0.01741977035999298, 'max_q_value': 0.3101578950881958, 'min_q_value': -0.8168851137161255, 'mean_td_error': 0.11417039, 'max_td_error': 0.4637639, 'mean_weight': 0.5179064273834229}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8375, -0.8511, -0.7955, -0.8361]], device='cuda:0'), reward is -0.99\n",
      "Episode 237/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 9294, 'eps': 0.0, 'buffer_size': 9294, 'q_loss': 1.266981601715088, 'mean_q_value': -0.10835046321153641, 'max_q_value': 0.36676883697509766, 'min_q_value': -0.9719311594963074, 'mean_td_error': 0.078794315, 'max_td_error': 0.53675663, 'mean_weight': 0.385768324136734}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9114, -0.9102, -0.9065, -0.8919]], device='cuda:0'), reward is -0.99\n",
      "Episode 238/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 9351, 'eps': 0.0, 'buffer_size': 9351, 'q_loss': 1.7980927228927612, 'mean_q_value': 0.028831269592046738, 'max_q_value': 0.2987383008003235, 'min_q_value': -0.8201910257339478, 'mean_td_error': 0.07537699, 'max_td_error': 0.5138255, 'mean_weight': 0.4859907031059265}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1814, 0.1686, 0.1831, 0.1281]], device='cuda:0'), reward is -0.99\n",
      "Episode 239/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 9380, 'eps': 0.0, 'buffer_size': 9380, 'q_loss': 2.164031982421875, 'mean_q_value': -0.10519595444202423, 'max_q_value': 0.23821522295475006, 'min_q_value': -0.9686259031295776, 'mean_td_error': 0.08313534, 'max_td_error': 0.4701332, 'mean_weight': 0.6332886219024658}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8243, -0.8295, -0.8141, -0.8071]], device='cuda:0'), reward is -0.99\n",
      "Episode 240/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 9401, 'eps': 0.0, 'buffer_size': 9401, 'q_loss': 1.8426926136016846, 'mean_q_value': -0.031707894057035446, 'max_q_value': 0.3431129455566406, 'min_q_value': -0.9581902623176575, 'mean_td_error': 0.074445546, 'max_td_error': 0.44510812, 'mean_weight': 0.5314313173294067}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1569, 0.1025, 0.1103, 0.0797]], device='cuda:0'), reward is -0.99\n",
      "Episode 241/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 9423, 'eps': 0.0, 'buffer_size': 9423, 'q_loss': 1.9141849279403687, 'mean_q_value': 0.015137378126382828, 'max_q_value': 0.2652847170829773, 'min_q_value': -0.7253826260566711, 'mean_td_error': 0.08604996, 'max_td_error': 1.2207742, 'mean_weight': 0.5321463346481323}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1005, -0.0678,  0.0582, -0.3429]], device='cuda:0'), reward is -0.99\n",
      "Episode 242/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 9442, 'eps': 0.0, 'buffer_size': 9442, 'q_loss': 1.8953375816345215, 'mean_q_value': -0.04165254533290863, 'max_q_value': 0.22506195306777954, 'min_q_value': -0.8099389672279358, 'mean_td_error': 0.13296814, 'max_td_error': 1.0799407, 'mean_weight': 0.5415902137756348}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6617, -0.5295, -0.5774, -0.5189]], device='cuda:0'), reward is -0.99\n",
      "Episode 243/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 9485, 'eps': 0.0, 'buffer_size': 9485, 'q_loss': 1.2675013542175293, 'mean_q_value': -0.013162853196263313, 'max_q_value': 0.2760038375854492, 'min_q_value': -0.9247607588768005, 'mean_td_error': 0.06617256, 'max_td_error': 0.34823945, 'mean_weight': 0.363739550113678}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8756, -0.7689, -0.8134, -0.8412]], device='cuda:0'), reward is -0.99\n",
      "Episode 244/1000000: {'total_return': 6.661338147750939e-16, 'steps': 100, 'total_steps': 9585, 'eps': 0.0, 'buffer_size': 9585, 'q_loss': 2.100210189819336, 'mean_q_value': -0.13934901356697083, 'max_q_value': 0.32424482703208923, 'min_q_value': -0.9627706408500671, 'mean_td_error': 0.05671174, 'max_td_error': 0.2594099, 'mean_weight': 0.6063210368156433}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1035, -0.0857, -0.1079, -0.1266]], device='cuda:0'), reward is -0.99\n",
      "Episode 245/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 9621, 'eps': 0.0, 'buffer_size': 9621, 'q_loss': 1.7855870723724365, 'mean_q_value': -0.0023326128721237183, 'max_q_value': 0.3057568669319153, 'min_q_value': -0.8330816626548767, 'mean_td_error': 0.0810738, 'max_td_error': 0.29795843, 'mean_weight': 0.48708605766296387}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9505, -0.9798, -0.8843, -0.8367]], device='cuda:0'), reward is -0.99\n",
      "Episode 246/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 9680, 'eps': 0.0, 'buffer_size': 9680, 'q_loss': 1.0292881727218628, 'mean_q_value': -0.13833031058311462, 'max_q_value': 0.29699772596359253, 'min_q_value': -0.952370285987854, 'mean_td_error': 0.11759656, 'max_td_error': 0.7743554, 'mean_weight': 0.3343277871608734}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3833, -0.3409, -0.3060, -0.4832]], device='cuda:0'), reward is -0.99\n",
      "Episode 247/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 9704, 'eps': 0.0, 'buffer_size': 9704, 'q_loss': 1.8625555038452148, 'mean_q_value': -0.13853409886360168, 'max_q_value': 0.3675149977207184, 'min_q_value': -0.9630599617958069, 'mean_td_error': 0.08943683, 'max_td_error': 0.6392621, 'mean_weight': 0.5549056529998779}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2064, 0.2334, 0.2112, 0.2066]], device='cuda:0'), reward is -0.99\n",
      "Episode 248/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 9727, 'eps': 0.0, 'buffer_size': 9727, 'q_loss': 2.1809160709381104, 'mean_q_value': -0.11307942867279053, 'max_q_value': 0.23734095692634583, 'min_q_value': -0.9224379658699036, 'mean_td_error': 0.0739506, 'max_td_error': 0.40506268, 'mean_weight': 0.6259876489639282}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5558, -0.5698, -0.5471, -0.5438]], device='cuda:0'), reward is -0.99\n",
      "Episode 249/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 9776, 'eps': 0.0, 'buffer_size': 9776, 'q_loss': 1.683025598526001, 'mean_q_value': -0.0679827332496643, 'max_q_value': 0.2233872413635254, 'min_q_value': -0.800525963306427, 'mean_td_error': 0.07770297, 'max_td_error': 0.2742148, 'mean_weight': 0.47757554054260254}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3088, -0.2773, -0.4284, -0.6610]], device='cuda:0'), reward is -0.99\n",
      "Episode 250/1000000: {'total_return': -0.86, 'steps': 14, 'total_steps': 9790, 'eps': 0.0, 'buffer_size': 9790, 'q_loss': 2.150245189666748, 'mean_q_value': 0.02434757724404335, 'max_q_value': 0.28941452503204346, 'min_q_value': -0.601635217666626, 'mean_td_error': 0.06928229, 'max_td_error': 0.30949426, 'mean_weight': 0.5788304805755615}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0300, 0.0727, 0.0248, 0.0604]], device='cuda:0'), reward is -0.99\n",
      "Episode 251/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 9813, 'eps': 0.0, 'buffer_size': 9813, 'q_loss': 1.6614148616790771, 'mean_q_value': -0.1141713485121727, 'max_q_value': 0.2792046070098877, 'min_q_value': -0.9630172848701477, 'mean_td_error': 0.0879715, 'max_td_error': 0.567345, 'mean_weight': 0.5052030086517334}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1134, -0.0492, -0.1830, -0.2684]], device='cuda:0'), reward is -0.99\n",
      "Episode 252/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 9834, 'eps': 0.0, 'buffer_size': 9834, 'q_loss': 1.7627098560333252, 'mean_q_value': -0.0544365830719471, 'max_q_value': 0.2600713074207306, 'min_q_value': -0.9886921048164368, 'mean_td_error': 0.072102614, 'max_td_error': 0.33222875, 'mean_weight': 0.501545786857605}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2563, 0.2538, 0.2517, 0.2539]], device='cuda:0'), reward is -0.99\n",
      "Episode 253/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 9856, 'eps': 0.0, 'buffer_size': 9856, 'q_loss': 1.7471542358398438, 'mean_q_value': -0.021320534870028496, 'max_q_value': 0.26928889751434326, 'min_q_value': -0.9418506026268005, 'mean_td_error': 0.05192145, 'max_td_error': 0.22609532, 'mean_weight': 0.494475781917572}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0028, 0.1854, 0.1348, 0.2118]], device='cuda:0'), reward is -0.99\n",
      "Episode 254/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 9884, 'eps': 0.0, 'buffer_size': 9884, 'q_loss': 1.4778811931610107, 'mean_q_value': 0.02494296059012413, 'max_q_value': 0.29946401715278625, 'min_q_value': -0.854097306728363, 'mean_td_error': 0.110402554, 'max_td_error': 0.6420466, 'mean_weight': 0.41980209946632385}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1068, 0.0940, 0.1171, 0.0965]], device='cuda:0'), reward is -0.99\n",
      "Episode 255/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 9919, 'eps': 0.0, 'buffer_size': 9919, 'q_loss': 1.7326469421386719, 'mean_q_value': 0.017801061272621155, 'max_q_value': 0.2862396240234375, 'min_q_value': -0.9046813249588013, 'mean_td_error': 0.10174664, 'max_td_error': 1.2360009, 'mean_weight': 0.4934416115283966}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3676, -0.3569, -0.3388, -0.3089]], device='cuda:0'), reward is -0.99\n",
      "Episode 256/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 9937, 'eps': 0.0, 'buffer_size': 9937, 'q_loss': 1.9635478258132935, 'mean_q_value': -0.10823766887187958, 'max_q_value': 0.2960174083709717, 'min_q_value': -0.9752468466758728, 'mean_td_error': 0.056542717, 'max_td_error': 0.26010048, 'mean_weight': 0.5748011469841003}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2155,  0.0799, -0.0007, -0.0776]], device='cuda:0'), reward is -0.99\n",
      "Episode 257/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 9973, 'eps': 0.0, 'buffer_size': 9973, 'q_loss': 1.2232861518859863, 'mean_q_value': 0.04798843711614609, 'max_q_value': 0.2608785033226013, 'min_q_value': -0.9440295696258545, 'mean_td_error': 0.06601266, 'max_td_error': 0.38505495, 'mean_weight': 0.3383936285972595}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0937, -0.2069, -0.1010, -0.1305]], device='cuda:0'), reward is -0.99\n",
      "Episode 258/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 10011, 'eps': 0.0, 'buffer_size': 10011, 'q_loss': 1.6101431846618652, 'mean_q_value': -0.11116963624954224, 'max_q_value': 0.2753138542175293, 'min_q_value': -0.9965972900390625, 'mean_td_error': 0.10572678, 'max_td_error': 1.0171176, 'mean_weight': 0.48398929834365845}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9090, -0.9515, -0.9094, -0.9194]], device='cuda:0'), reward is -0.99\n",
      "Episode 259/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 10074, 'eps': 0.0, 'buffer_size': 10074, 'q_loss': 1.7895485162734985, 'mean_q_value': -0.025422658771276474, 'max_q_value': 0.2567363381385803, 'min_q_value': -0.8443822264671326, 'mean_td_error': 0.09311204, 'max_td_error': 0.47468054, 'mean_weight': 0.5150236487388611}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7060, -0.7463, -0.7079, -0.6410]], device='cuda:0'), reward is -0.99\n",
      "Episode 260/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 10098, 'eps': 0.0, 'buffer_size': 10098, 'q_loss': 1.8180897235870361, 'mean_q_value': -0.0209357813000679, 'max_q_value': 0.30489039421081543, 'min_q_value': -0.7728248238563538, 'mean_td_error': 0.071898, 'max_td_error': 0.5517443, 'mean_weight': 0.4982143044471741}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5607, -0.4479, -0.1656, -0.3191]], device='cuda:0'), reward is -0.99\n",
      "Episode 261/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 10131, 'eps': 0.0, 'buffer_size': 10131, 'q_loss': 1.9057849645614624, 'mean_q_value': -0.046853795647621155, 'max_q_value': 0.2618538439273834, 'min_q_value': -0.954005777835846, 'mean_td_error': 0.06768425, 'max_td_error': 0.3542508, 'mean_weight': 0.5234200358390808}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1418, -0.0962, -0.1120, -0.1919]], device='cuda:0'), reward is -0.99\n",
      "Episode 262/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 10155, 'eps': 0.0, 'buffer_size': 10155, 'q_loss': 1.5800371170043945, 'mean_q_value': -0.027147326618433, 'max_q_value': 0.2782931923866272, 'min_q_value': -0.9094575047492981, 'mean_td_error': 0.070882566, 'max_td_error': 0.4294862, 'mean_weight': 0.43832865357398987}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9247, -0.9590, -0.8980, -0.8963]], device='cuda:0'), reward is -0.99\n",
      "Episode 263/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 10219, 'eps': 0.0, 'buffer_size': 10219, 'q_loss': 1.7760522365570068, 'mean_q_value': -0.11931002140045166, 'max_q_value': 0.26676592230796814, 'min_q_value': -0.9556930661201477, 'mean_td_error': 0.09545739, 'max_td_error': 0.5228018, 'mean_weight': 0.5450007319450378}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1343, -0.1751, -0.1210, -0.1947]], device='cuda:0'), reward is -0.99\n",
      "Episode 264/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10238, 'eps': 0.0, 'buffer_size': 10238, 'q_loss': 2.365398645401001, 'mean_q_value': 0.030892388895154, 'max_q_value': 0.30301764607429504, 'min_q_value': -0.8892849683761597, 'mean_td_error': 0.0541385, 'max_td_error': 0.4139573, 'mean_weight': 0.645310640335083}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0950,  0.0398, -0.0174,  0.0835]], device='cuda:0'), reward is -0.99\n",
      "Episode 265/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10257, 'eps': 0.0, 'buffer_size': 10257, 'q_loss': 2.21175479888916, 'mean_q_value': -0.12274099886417389, 'max_q_value': 0.32600975036621094, 'min_q_value': -0.9335609078407288, 'mean_td_error': 0.09379552, 'max_td_error': 0.40503198, 'mean_weight': 0.6485127806663513}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1413, 0.1484, 0.1322, 0.1592]], device='cuda:0'), reward is -0.99\n",
      "Episode 266/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 10278, 'eps': 0.0, 'buffer_size': 10278, 'q_loss': 1.9236271381378174, 'mean_q_value': -0.14527356624603271, 'max_q_value': 0.3357853889465332, 'min_q_value': -0.9521580338478088, 'mean_td_error': 0.096494794, 'max_td_error': 0.96407694, 'mean_weight': 0.5817321538925171}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0278, -0.0207, -0.0007,  0.0447]], device='cuda:0'), reward is -0.99\n",
      "Episode 267/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 10330, 'eps': 0.0, 'buffer_size': 10330, 'q_loss': 2.1131110191345215, 'mean_q_value': -0.07327701151371002, 'max_q_value': 0.2627846300601959, 'min_q_value': -0.9175028800964355, 'mean_td_error': 0.08094765, 'max_td_error': 0.4410398, 'mean_weight': 0.6075834631919861}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2697, -0.3660, -0.2383, -0.2958]], device='cuda:0'), reward is -0.99\n",
      "Episode 268/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 10371, 'eps': 0.0, 'buffer_size': 10371, 'q_loss': 1.5122778415679932, 'mean_q_value': -0.004223816096782684, 'max_q_value': 0.2786712646484375, 'min_q_value': -0.9519544243812561, 'mean_td_error': 0.058464535, 'max_td_error': 0.3659034, 'mean_weight': 0.41897469758987427}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1972, -0.1951, -0.2213, -0.3574]], device='cuda:0'), reward is -0.99\n",
      "Episode 269/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10390, 'eps': 0.0, 'buffer_size': 10390, 'q_loss': 2.193394184112549, 'mean_q_value': 0.10050058364868164, 'max_q_value': 0.3464338481426239, 'min_q_value': -0.7711926102638245, 'mean_td_error': 0.058836613, 'max_td_error': 0.2664377, 'mean_weight': 0.5819084644317627}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0827,  0.0020, -0.0323,  0.0408]], device='cuda:0'), reward is -0.99\n",
      "Episode 270/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 10412, 'eps': 0.0, 'buffer_size': 10412, 'q_loss': 2.0327353477478027, 'mean_q_value': -0.03659840673208237, 'max_q_value': 0.2790817618370056, 'min_q_value': -0.7298280000686646, 'mean_td_error': 0.08187639, 'max_td_error': 0.3814122, 'mean_weight': 0.5541911721229553}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5827, -0.5502, -0.4266, -0.2511]], device='cuda:0'), reward is -0.99\n",
      "Episode 271/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 10443, 'eps': 0.0, 'buffer_size': 10443, 'q_loss': 1.728817343711853, 'mean_q_value': 0.029171843081712723, 'max_q_value': 0.25795722007751465, 'min_q_value': -0.5588856339454651, 'mean_td_error': 0.06358278, 'max_td_error': 0.2632401, 'mean_weight': 0.47188639640808105}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1457, -0.1661, -0.1558, -0.1260]], device='cuda:0'), reward is -0.99\n",
      "Episode 272/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10462, 'eps': 0.0, 'buffer_size': 10462, 'q_loss': 1.2898612022399902, 'mean_q_value': -0.11926507949829102, 'max_q_value': 0.3375510573387146, 'min_q_value': -0.9740875363349915, 'mean_td_error': 0.07784902, 'max_td_error': 0.5833926, 'mean_weight': 0.39462578296661377}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6003, -0.6482, -0.5687, -0.6188]], device='cuda:0'), reward is -0.99\n",
      "Episode 273/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 10496, 'eps': 0.0, 'buffer_size': 10496, 'q_loss': 1.5836915969848633, 'mean_q_value': -0.1333494782447815, 'max_q_value': 0.25163212418556213, 'min_q_value': -0.9119828343391418, 'mean_td_error': 0.07756491, 'max_td_error': 0.28241533, 'mean_weight': 0.4858240783214569}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1264, 0.1229, 0.1007, 0.0814]], device='cuda:0'), reward is -0.99\n",
      "Episode 274/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 10524, 'eps': 0.0, 'buffer_size': 10524, 'q_loss': 1.918511152267456, 'mean_q_value': -0.05897180736064911, 'max_q_value': 0.26371851563453674, 'min_q_value': -0.9656839370727539, 'mean_td_error': 0.062306505, 'max_td_error': 0.48134708, 'mean_weight': 0.5600748062133789}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8283, -0.7759, -0.8229, -0.9017]], device='cuda:0'), reward is -0.99\n",
      "Episode 275/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 10564, 'eps': 0.0, 'buffer_size': 10564, 'q_loss': 1.4470746517181396, 'mean_q_value': 0.008237350732088089, 'max_q_value': 0.32815176248550415, 'min_q_value': -0.9351946711540222, 'mean_td_error': 0.11495954, 'max_td_error': 0.7268839, 'mean_weight': 0.4095449447631836}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4758, -0.5012, -0.4913, -0.5430]], device='cuda:0'), reward is -0.99\n",
      "Episode 276/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10582, 'eps': 0.0, 'buffer_size': 10582, 'q_loss': 1.7578661441802979, 'mean_q_value': -0.07715025544166565, 'max_q_value': 0.2331017553806305, 'min_q_value': -0.9696434736251831, 'mean_td_error': 0.045381725, 'max_td_error': 0.28321743, 'mean_weight': 0.49226969480514526}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2209, 0.3227, 0.2680, 0.3057]], device='cuda:0'), reward is -0.99\n",
      "Episode 277/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 10606, 'eps': 0.0, 'buffer_size': 10606, 'q_loss': 1.4366507530212402, 'mean_q_value': -0.1711747646331787, 'max_q_value': 0.26397404074668884, 'min_q_value': -0.9871638417243958, 'mean_td_error': 0.062620506, 'max_td_error': 0.28211135, 'mean_weight': 0.455159455537796}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2342, -0.2212, -0.2140, -0.2632]], device='cuda:0'), reward is -0.99\n",
      "Episode 278/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10624, 'eps': 0.0, 'buffer_size': 10624, 'q_loss': 2.199939012527466, 'mean_q_value': -0.0860682874917984, 'max_q_value': 0.28533661365509033, 'min_q_value': -0.9820517897605896, 'mean_td_error': 0.068113685, 'max_td_error': 0.6122011, 'mean_weight': 0.6559553742408752}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8541, -0.8297, -0.7600, -0.8055]], device='cuda:0'), reward is -0.99\n",
      "Episode 279/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 10664, 'eps': 0.0, 'buffer_size': 10664, 'q_loss': 2.0638208389282227, 'mean_q_value': -0.11121122539043427, 'max_q_value': 0.25490090250968933, 'min_q_value': -0.9447861313819885, 'mean_td_error': 0.07295704, 'max_td_error': 0.29104763, 'mean_weight': 0.6005983352661133}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6071,  0.1188, -0.1421, -0.3945]], device='cuda:0'), reward is -0.99\n",
      "Episode 280/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 10697, 'eps': 0.0, 'buffer_size': 10697, 'q_loss': 1.3407361507415771, 'mean_q_value': -0.07948527485132217, 'max_q_value': 0.2651934027671814, 'min_q_value': -0.9369996190071106, 'mean_td_error': 0.06501876, 'max_td_error': 0.3393093, 'mean_weight': 0.3980124890804291}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0906, -0.0943, -0.0833, -0.0831]], device='cuda:0'), reward is -0.99\n",
      "Episode 281/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10716, 'eps': 0.0, 'buffer_size': 10716, 'q_loss': 1.3377960920333862, 'mean_q_value': -0.0608215406537056, 'max_q_value': 0.27835893630981445, 'min_q_value': -0.9347404837608337, 'mean_td_error': 0.07254596, 'max_td_error': 0.621818, 'mean_weight': 0.3822013735771179}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3544, -0.2758, -0.4699, -0.3127]], device='cuda:0'), reward is -0.99\n",
      "Episode 282/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 10735, 'eps': 0.0, 'buffer_size': 10735, 'q_loss': 1.865189552307129, 'mean_q_value': 0.04844662919640541, 'max_q_value': 0.28224828839302063, 'min_q_value': -0.664374053478241, 'mean_td_error': 0.080739565, 'max_td_error': 1.0549579, 'mean_weight': 0.49782368540763855}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0074, -0.0631, -0.0242,  0.0214]], device='cuda:0'), reward is -0.99\n",
      "Episode 283/1000000: {'total_return': -0.1899999999999995, 'steps': 81, 'total_steps': 10816, 'eps': 0.0, 'buffer_size': 10816, 'q_loss': 1.4371201992034912, 'mean_q_value': -0.00765170156955719, 'max_q_value': 0.29319149255752563, 'min_q_value': -0.944167971611023, 'mean_td_error': 0.07799119, 'max_td_error': 0.42987168, 'mean_weight': 0.40776365995407104}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0703, 0.0807, 0.0910, 0.1080]], device='cuda:0'), reward is -0.99\n",
      "Episode 284/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10834, 'eps': 0.0, 'buffer_size': 10834, 'q_loss': 2.007570743560791, 'mean_q_value': -0.12015743553638458, 'max_q_value': 0.30694812536239624, 'min_q_value': -0.9510889649391174, 'mean_td_error': 0.11551143, 'max_td_error': 0.8363921, 'mean_weight': 0.616428792476654}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1857, -0.0709,  0.0076, -0.0037]], device='cuda:0'), reward is -0.99\n",
      "Episode 285/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10852, 'eps': 0.0, 'buffer_size': 10852, 'q_loss': 2.2253217697143555, 'mean_q_value': -0.0020338036119937897, 'max_q_value': 0.25609952211380005, 'min_q_value': -0.9327550530433655, 'mean_td_error': 0.043535173, 'max_td_error': 0.14964062, 'mean_weight': 0.6163284182548523}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0765, 0.0714, 0.0821, 0.0830]], device='cuda:0'), reward is -0.99\n",
      "Episode 286/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 10872, 'eps': 0.0, 'buffer_size': 10872, 'q_loss': 1.8206894397735596, 'mean_q_value': -0.047339171171188354, 'max_q_value': 0.2818070650100708, 'min_q_value': -0.9643444418907166, 'mean_td_error': 0.051159464, 'max_td_error': 0.1849578, 'mean_weight': 0.544243574142456}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0783, -0.0826, -0.0704, -0.0703]], device='cuda:0'), reward is -0.99\n",
      "Episode 287/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 10893, 'eps': 0.0, 'buffer_size': 10893, 'q_loss': 1.5256550312042236, 'mean_q_value': -0.07676562666893005, 'max_q_value': 0.307064026594162, 'min_q_value': -0.9596495032310486, 'mean_td_error': 0.07179312, 'max_td_error': 0.3783891, 'mean_weight': 0.46112746000289917}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0298, 0.0331, 0.0335, 0.0348]], device='cuda:0'), reward is -0.99\n",
      "Episode 288/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10911, 'eps': 0.0, 'buffer_size': 10911, 'q_loss': 1.5848454236984253, 'mean_q_value': 0.022889528423547745, 'max_q_value': 0.2901660203933716, 'min_q_value': -0.5145005583763123, 'mean_td_error': 0.06675141, 'max_td_error': 0.47549862, 'mean_weight': 0.4277716875076294}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3078, -0.2060, -0.3924, -0.3374]], device='cuda:0'), reward is -0.99\n",
      "Episode 289/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 10936, 'eps': 0.0, 'buffer_size': 10936, 'q_loss': 2.1774606704711914, 'mean_q_value': 0.044336456805467606, 'max_q_value': 0.24940842390060425, 'min_q_value': -0.9320642948150635, 'mean_td_error': 0.046915106, 'max_td_error': 0.16206434, 'mean_weight': 0.6077589988708496}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6445, -0.6228, -0.6403, -0.6095]], device='cuda:0'), reward is -0.99\n",
      "Episode 290/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 10954, 'eps': 0.0, 'buffer_size': 10954, 'q_loss': 1.2588835954666138, 'mean_q_value': -0.03422166407108307, 'max_q_value': 0.279581218957901, 'min_q_value': -0.6881733536720276, 'mean_td_error': 0.079693496, 'max_td_error': 0.47484773, 'mean_weight': 0.34871697425842285}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8951, -0.8407, -0.8591, -0.8730]], device='cuda:0'), reward is -0.99\n",
      "Episode 291/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 11005, 'eps': 0.0, 'buffer_size': 11005, 'q_loss': 1.9944658279418945, 'mean_q_value': -0.10733750462532043, 'max_q_value': 0.3174281120300293, 'min_q_value': -0.9748974442481995, 'mean_td_error': 0.10555069, 'max_td_error': 0.9511656, 'mean_weight': 0.6089539527893066}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0653, 0.1288, 0.1546, 0.0290]], device='cuda:0'), reward is -0.99\n",
      "Episode 292/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 11032, 'eps': 0.0, 'buffer_size': 11032, 'q_loss': 1.626942753791809, 'mean_q_value': 0.011986946687102318, 'max_q_value': 0.3143579661846161, 'min_q_value': -0.8386102914810181, 'mean_td_error': 0.07709078, 'max_td_error': 0.40466353, 'mean_weight': 0.4575660824775696}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5352, -0.6623, -0.5555, -0.5930]], device='cuda:0'), reward is -0.99\n",
      "Episode 293/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11051, 'eps': 0.0, 'buffer_size': 11051, 'q_loss': 1.5622448921203613, 'mean_q_value': -0.03529394045472145, 'max_q_value': 0.298963725566864, 'min_q_value': -0.8136405348777771, 'mean_td_error': 0.094173044, 'max_td_error': 0.551649, 'mean_weight': 0.4393572211265564}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7673, -0.8714, -0.7895, -0.8690]], device='cuda:0'), reward is -0.99\n",
      "Episode 294/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11070, 'eps': 0.0, 'buffer_size': 11070, 'q_loss': 1.2910792827606201, 'mean_q_value': 0.007556304335594177, 'max_q_value': 0.28536319732666016, 'min_q_value': -0.7829440832138062, 'mean_td_error': 0.07389053, 'max_td_error': 0.46349525, 'mean_weight': 0.3504466414451599}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4290, -0.2924, -0.5367, -0.7052]], device='cuda:0'), reward is -0.99\n",
      "Episode 295/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 11108, 'eps': 0.0, 'buffer_size': 11108, 'q_loss': 2.070664882659912, 'mean_q_value': -0.043396979570388794, 'max_q_value': 0.3306949734687805, 'min_q_value': -0.9546214938163757, 'mean_td_error': 0.09644672, 'max_td_error': 0.50883657, 'mean_weight': 0.5886546969413757}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1267, -0.2307, -0.1882, -0.3097]], device='cuda:0'), reward is -0.99\n",
      "Episode 296/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 11138, 'eps': 0.0, 'buffer_size': 11138, 'q_loss': 2.2330522537231445, 'mean_q_value': 0.018553704023361206, 'max_q_value': 0.2774512469768524, 'min_q_value': -0.9007692933082581, 'mean_td_error': 0.08131625, 'max_td_error': 1.0713358, 'mean_weight': 0.6203762292861938}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-1.0159, -1.0141, -1.0166, -1.0200]], device='cuda:0'), reward is -0.99\n",
      "Episode 297/1000000: {'total_return': -0.14999999999999947, 'steps': 85, 'total_steps': 11223, 'eps': 0.0, 'buffer_size': 11223, 'q_loss': 1.7932783365249634, 'mean_q_value': -0.08213238418102264, 'max_q_value': 0.461874395608902, 'min_q_value': -0.949364185333252, 'mean_td_error': 0.07390187, 'max_td_error': 0.4004, 'mean_weight': 0.5190130472183228}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7534, -0.7263, -0.7461, -0.8042]], device='cuda:0'), reward is -0.99\n",
      "Episode 298/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 11285, 'eps': 0.0, 'buffer_size': 11285, 'q_loss': 1.8195735216140747, 'mean_q_value': -0.08922316879034042, 'max_q_value': 0.30043527483940125, 'min_q_value': -0.8882051110267639, 'mean_td_error': 0.08952096, 'max_td_error': 0.69326556, 'mean_weight': 0.5291478633880615}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3776, -0.3964, -0.4455, -0.4581]], device='cuda:0'), reward is -0.99\n",
      "Episode 299/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 11317, 'eps': 0.0, 'buffer_size': 11317, 'q_loss': 1.571714162826538, 'mean_q_value': -0.09196865558624268, 'max_q_value': 0.3172461688518524, 'min_q_value': -0.9406214952468872, 'mean_td_error': 0.09890018, 'max_td_error': 0.3811291, 'mean_weight': 0.46069008111953735}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7415, -0.8050, -0.7382, -0.7978]], device='cuda:0'), reward is -0.99\n",
      "Episode 300/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 11335, 'eps': 0.0, 'buffer_size': 11335, 'q_loss': 1.7525854110717773, 'mean_q_value': -0.08825897425413132, 'max_q_value': 0.30819544196128845, 'min_q_value': -1.0136330127716064, 'mean_td_error': 0.05697021, 'max_td_error': 0.22172064, 'mean_weight': 0.5135483741760254}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9346, -0.9375, -0.9408, -0.9360]], device='cuda:0'), reward is -0.99\n",
      "Episode 301/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 11353, 'eps': 0.0, 'buffer_size': 11353, 'q_loss': 1.1843287944793701, 'mean_q_value': -0.03682229295372963, 'max_q_value': 0.3027295768260956, 'min_q_value': -0.9649787545204163, 'mean_td_error': 0.055662654, 'max_td_error': 0.17171036, 'mean_weight': 0.33001047372817993}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4699, -0.4952, -0.4116, -0.5147]], device='cuda:0'), reward is -0.99\n",
      "Episode 302/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 11388, 'eps': 0.0, 'buffer_size': 11388, 'q_loss': 1.695141077041626, 'mean_q_value': -0.1765037477016449, 'max_q_value': 0.3143332302570343, 'min_q_value': -1.017907738685608, 'mean_td_error': 0.08041656, 'max_td_error': 0.39951158, 'mean_weight': 0.5215444564819336}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4082, -0.3978, -0.3316, -0.5604]], device='cuda:0'), reward is -0.99\n",
      "Episode 303/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 11432, 'eps': 0.0, 'buffer_size': 11432, 'q_loss': 1.796370267868042, 'mean_q_value': -0.07001683861017227, 'max_q_value': 0.29732754826545715, 'min_q_value': -0.9054889678955078, 'mean_td_error': 0.08428152, 'max_td_error': 0.532377, 'mean_weight': 0.5210312604904175}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4107, -0.5160, -0.5580, -0.5941]], device='cuda:0'), reward is -0.99\n",
      "Episode 304/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 11461, 'eps': 0.0, 'buffer_size': 11461, 'q_loss': 1.9219447374343872, 'mean_q_value': -0.11183673143386841, 'max_q_value': 0.2735178470611572, 'min_q_value': -0.9093454480171204, 'mean_td_error': 0.07507928, 'max_td_error': 0.56857765, 'mean_weight': 0.5895789861679077}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0965, 0.0858, 0.0973, 0.0997]], device='cuda:0'), reward is -0.99\n",
      "Episode 305/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 11482, 'eps': 0.0, 'buffer_size': 11482, 'q_loss': 1.3890936374664307, 'mean_q_value': 0.08397252857685089, 'max_q_value': 0.2444240152835846, 'min_q_value': -0.7123063802719116, 'mean_td_error': 0.072261676, 'max_td_error': 0.44702768, 'mean_weight': 0.375602126121521}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2431, -0.2294, -0.2255, -0.1608]], device='cuda:0'), reward is -0.99\n",
      "Episode 306/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 11502, 'eps': 0.0, 'buffer_size': 11502, 'q_loss': 1.4787085056304932, 'mean_q_value': -0.1335863322019577, 'max_q_value': 0.2805597186088562, 'min_q_value': -0.9483163952827454, 'mean_td_error': 0.09106033, 'max_td_error': 0.35174024, 'mean_weight': 0.4286487400531769}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4148, -0.4415, -0.4131, -0.4170]], device='cuda:0'), reward is -0.99\n",
      "Episode 307/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11521, 'eps': 0.0, 'buffer_size': 11521, 'q_loss': 1.8743343353271484, 'mean_q_value': -0.06264761835336685, 'max_q_value': 0.25173360109329224, 'min_q_value': -0.960940957069397, 'mean_td_error': 0.058827735, 'max_td_error': 0.452896, 'mean_weight': 0.5347005724906921}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4939, -0.5402, -0.5056, -0.6251]], device='cuda:0'), reward is -0.99\n",
      "Episode 308/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 11558, 'eps': 0.0, 'buffer_size': 11558, 'q_loss': 1.7141931056976318, 'mean_q_value': -0.01809099316596985, 'max_q_value': 0.3100515604019165, 'min_q_value': -0.8597897887229919, 'mean_td_error': 0.06109585, 'max_td_error': 0.25006855, 'mean_weight': 0.4750683903694153}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0419,  0.0550, -0.0395, -0.0473]], device='cuda:0'), reward is -0.99\n",
      "Episode 309/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 11587, 'eps': 0.0, 'buffer_size': 11587, 'q_loss': 0.9444552659988403, 'mean_q_value': -0.11439726501703262, 'max_q_value': 0.2895974814891815, 'min_q_value': -0.9426665902137756, 'mean_td_error': 0.0679462, 'max_td_error': 0.57151437, 'mean_weight': 0.28183501958847046}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5550, -0.5982, -0.5531, -0.5717]], device='cuda:0'), reward is -0.99\n",
      "Episode 310/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11606, 'eps': 0.0, 'buffer_size': 11606, 'q_loss': 1.7750542163848877, 'mean_q_value': -0.12894177436828613, 'max_q_value': 0.28556153178215027, 'min_q_value': -0.9330676794052124, 'mean_td_error': 0.13077992, 'max_td_error': 0.6666781, 'mean_weight': 0.5223563313484192}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3900, -0.3550, -0.4436, -0.3399]], device='cuda:0'), reward is -0.99\n",
      "Episode 311/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 11624, 'eps': 0.0, 'buffer_size': 11624, 'q_loss': 1.9367423057556152, 'mean_q_value': -0.042225830256938934, 'max_q_value': 0.3225220739841461, 'min_q_value': -0.7554067373275757, 'mean_td_error': 0.098682374, 'max_td_error': 0.47392976, 'mean_weight': 0.5479707717895508}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1394, 0.0793, 0.1452, 0.0348]], device='cuda:0'), reward is -0.99\n",
      "Episode 312/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11643, 'eps': 0.0, 'buffer_size': 11643, 'q_loss': 1.9718060493469238, 'mean_q_value': -0.06282655894756317, 'max_q_value': 0.3430914878845215, 'min_q_value': -0.8672962188720703, 'mean_td_error': 0.06539443, 'max_td_error': 0.32581818, 'mean_weight': 0.5655478835105896}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5777, -0.6778, -0.6373, -0.5888]], device='cuda:0'), reward is -0.99\n",
      "Episode 313/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 11662, 'eps': 0.0, 'buffer_size': 11662, 'q_loss': 2.0886757373809814, 'mean_q_value': 0.023841332644224167, 'max_q_value': 0.3724060654640198, 'min_q_value': -0.738629937171936, 'mean_td_error': 0.0804291, 'max_td_error': 0.45383167, 'mean_weight': 0.5711957216262817}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2273, -0.0542, -0.1349, -0.3395]], device='cuda:0'), reward is -0.99\n",
      "Episode 314/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 11711, 'eps': 0.0, 'buffer_size': 11711, 'q_loss': 1.921730875968933, 'mean_q_value': 0.012114666402339935, 'max_q_value': 0.285114586353302, 'min_q_value': -0.9099559187889099, 'mean_td_error': 0.111573264, 'max_td_error': 0.46489298, 'mean_weight': 0.5450636148452759}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6723, -0.6144, -0.5058, -0.6679]], device='cuda:0'), reward is -0.99\n",
      "Episode 315/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 11741, 'eps': 0.0, 'buffer_size': 11741, 'q_loss': 1.6384810209274292, 'mean_q_value': 0.019222550094127655, 'max_q_value': 0.27861613035202026, 'min_q_value': -0.776726484298706, 'mean_td_error': 0.07882391, 'max_td_error': 0.5496379, 'mean_weight': 0.4593331813812256}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1191,  0.0351, -0.0384, -0.0066]], device='cuda:0'), reward is -0.99\n",
      "Episode 316/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 11761, 'eps': 0.0, 'buffer_size': 11761, 'q_loss': 1.978783130645752, 'mean_q_value': 0.03885357826948166, 'max_q_value': 0.24790386855602264, 'min_q_value': -0.669083297252655, 'mean_td_error': 0.06059333, 'max_td_error': 0.18440259, 'mean_weight': 0.5332990884780884}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2384, -0.1228, -0.1924, -0.1383]], device='cuda:0'), reward is -0.99\n",
      "Episode 317/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 11788, 'eps': 0.0, 'buffer_size': 11788, 'q_loss': 2.1618752479553223, 'mean_q_value': -0.06599969416856766, 'max_q_value': 0.28733542561531067, 'min_q_value': -0.7865096926689148, 'mean_td_error': 0.060738448, 'max_td_error': 0.24486691, 'mean_weight': 0.638546347618103}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8157, -0.6649, -0.7592, -0.9131]], device='cuda:0'), reward is -0.99\n",
      "Episode 318/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 11845, 'eps': 0.0, 'buffer_size': 11845, 'q_loss': 1.8918416500091553, 'mean_q_value': -0.03463360667228699, 'max_q_value': 0.27695006132125854, 'min_q_value': -0.9262332320213318, 'mean_td_error': 0.100029156, 'max_td_error': 0.99633807, 'mean_weight': 0.547907829284668}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7809, -0.7250, -0.7155, -0.7108]], device='cuda:0'), reward is -0.99\n",
      "Episode 319/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 11892, 'eps': 0.0, 'buffer_size': 11892, 'q_loss': 1.723595380783081, 'mean_q_value': -0.1107187420129776, 'max_q_value': 0.25748318433761597, 'min_q_value': -0.9476151466369629, 'mean_td_error': 0.10373513, 'max_td_error': 0.58697283, 'mean_weight': 0.5188228487968445}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1679, -0.0366, -0.1331,  0.0009]], device='cuda:0'), reward is -0.99\n",
      "Episode 320/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 11910, 'eps': 0.0, 'buffer_size': 11910, 'q_loss': 1.5816102027893066, 'mean_q_value': -0.04162612184882164, 'max_q_value': 0.317001074552536, 'min_q_value': -0.9742965698242188, 'mean_td_error': 0.10964353, 'max_td_error': 0.9140555, 'mean_weight': 0.4571956396102905}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9557, -0.9566, -0.9656, -0.9510]], device='cuda:0'), reward is -0.99\n",
      "Episode 321/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 11928, 'eps': 0.0, 'buffer_size': 11928, 'q_loss': 1.735079288482666, 'mean_q_value': -0.10713639110326767, 'max_q_value': 0.2720547020435333, 'min_q_value': -0.9727298021316528, 'mean_td_error': 0.05990707, 'max_td_error': 0.42732546, 'mean_weight': 0.5021262168884277}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0304, -0.0753,  0.0386,  0.0574]], device='cuda:0'), reward is -0.99\n",
      "Episode 322/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 11951, 'eps': 0.0, 'buffer_size': 11951, 'q_loss': 2.009709358215332, 'mean_q_value': 0.050104014575481415, 'max_q_value': 0.287621408700943, 'min_q_value': -0.9053493738174438, 'mean_td_error': 0.056981064, 'max_td_error': 0.22013164, 'mean_weight': 0.5590378046035767}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9179, -0.9269, -0.9329, -0.8484]], device='cuda:0'), reward is -0.99\n",
      "Episode 323/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 11997, 'eps': 0.0, 'buffer_size': 11997, 'q_loss': 1.851702094078064, 'mean_q_value': -0.12526607513427734, 'max_q_value': 0.26571181416511536, 'min_q_value': -0.9183695316314697, 'mean_td_error': 0.103247315, 'max_td_error': 0.93290406, 'mean_weight': 0.5501402616500854}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6739, -0.2727, -0.3774, -0.3957]], device='cuda:0'), reward is -0.99\n",
      "Episode 324/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 12025, 'eps': 0.0, 'buffer_size': 12025, 'q_loss': 1.725064754486084, 'mean_q_value': -0.045584190636873245, 'max_q_value': 0.2800840139389038, 'min_q_value': -0.9765778183937073, 'mean_td_error': 0.06023722, 'max_td_error': 0.64126474, 'mean_weight': 0.5114325284957886}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0202, -0.1015, -0.1236, -0.0911]], device='cuda:0'), reward is -0.99\n",
      "Episode 325/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 12049, 'eps': 0.0, 'buffer_size': 12049, 'q_loss': 1.0600858926773071, 'mean_q_value': -0.013680268079042435, 'max_q_value': 0.36692988872528076, 'min_q_value': -0.7505461573600769, 'mean_td_error': 0.10087566, 'max_td_error': 0.7219698, 'mean_weight': 0.29162654280662537}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5400, -0.5796, -0.5639, -0.4808]], device='cuda:0'), reward is -0.99\n",
      "Episode 326/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 12085, 'eps': 0.0, 'buffer_size': 12085, 'q_loss': 1.017102599143982, 'mean_q_value': 0.01450325921177864, 'max_q_value': 0.3760019540786743, 'min_q_value': -0.8478991389274597, 'mean_td_error': 0.07013435, 'max_td_error': 0.31494886, 'mean_weight': 0.28570109605789185}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0764,  0.0165, -0.1468, -0.0083]], device='cuda:0'), reward is -0.99\n",
      "Episode 327/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12104, 'eps': 0.0, 'buffer_size': 12104, 'q_loss': 1.654632806777954, 'mean_q_value': -0.009800823405385017, 'max_q_value': 0.302595317363739, 'min_q_value': -0.8459308743476868, 'mean_td_error': 0.056109745, 'max_td_error': 0.26343763, 'mean_weight': 0.4624551832675934}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1225, -0.0539, -0.0517, -0.0846]], device='cuda:0'), reward is -0.99\n",
      "Episode 328/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 12141, 'eps': 0.0, 'buffer_size': 12141, 'q_loss': 1.7638092041015625, 'mean_q_value': -2.7099624276161194e-05, 'max_q_value': 0.3689039349555969, 'min_q_value': -0.9852539300918579, 'mean_td_error': 0.07024744, 'max_td_error': 0.58339334, 'mean_weight': 0.49848222732543945}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1202, -0.1855, -0.1384, -0.2490]], device='cuda:0'), reward is -0.99\n",
      "Episode 329/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 12161, 'eps': 0.0, 'buffer_size': 12161, 'q_loss': 1.5687358379364014, 'mean_q_value': -0.0881882980465889, 'max_q_value': 0.28515729308128357, 'min_q_value': -0.9020570516586304, 'mean_td_error': 0.13763352, 'max_td_error': 0.9304657, 'mean_weight': 0.46134448051452637}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4211, -0.3620, -0.3415, -0.3016]], device='cuda:0'), reward is -0.99\n",
      "Episode 330/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 12197, 'eps': 0.0, 'buffer_size': 12197, 'q_loss': 1.3713228702545166, 'mean_q_value': -0.026402544230222702, 'max_q_value': 0.32890254259109497, 'min_q_value': -0.8865623474121094, 'mean_td_error': 0.057473622, 'max_td_error': 0.19969162, 'mean_weight': 0.3828392028808594}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1346, 0.1332, 0.1372, 0.1423]], device='cuda:0'), reward is -0.99\n",
      "Episode 331/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 12218, 'eps': 0.0, 'buffer_size': 12218, 'q_loss': 1.434050440788269, 'mean_q_value': -0.014830194413661957, 'max_q_value': 0.2662471532821655, 'min_q_value': -0.7843003273010254, 'mean_td_error': 0.05676495, 'max_td_error': 0.1610671, 'mean_weight': 0.3936766982078552}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5851, -0.7634, -0.6121, -0.7101]], device='cuda:0'), reward is -0.99\n",
      "Episode 332/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 12287, 'eps': 0.0, 'buffer_size': 12287, 'q_loss': 2.2617440223693848, 'mean_q_value': -0.05734415352344513, 'max_q_value': 0.282261461019516, 'min_q_value': -0.8122711181640625, 'mean_td_error': 0.091268525, 'max_td_error': 0.74094903, 'mean_weight': 0.6536153554916382}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6082, -0.6022, -0.6166, -0.5958]], device='cuda:0'), reward is -0.99\n",
      "Episode 333/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12306, 'eps': 0.0, 'buffer_size': 12306, 'q_loss': 2.0681896209716797, 'mean_q_value': -0.05261383205652237, 'max_q_value': 0.2858046591281891, 'min_q_value': -0.9517585039138794, 'mean_td_error': 0.05602909, 'max_td_error': 0.23474538, 'mean_weight': 0.6033790707588196}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5166, -0.5496, -0.5526, -0.5187]], device='cuda:0'), reward is -0.99\n",
      "Episode 334/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12325, 'eps': 0.0, 'buffer_size': 12325, 'q_loss': 1.9561645984649658, 'mean_q_value': -0.05612453073263168, 'max_q_value': 0.30423635244369507, 'min_q_value': -0.9015982151031494, 'mean_td_error': 0.0667737, 'max_td_error': 0.568666, 'mean_weight': 0.5933790802955627}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8336, -0.8271, -0.8243, -0.8339]], device='cuda:0'), reward is -0.99\n",
      "Episode 335/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12344, 'eps': 0.0, 'buffer_size': 12344, 'q_loss': 1.5308367013931274, 'mean_q_value': -0.07448247820138931, 'max_q_value': 0.2988396883010864, 'min_q_value': -0.9683659076690674, 'mean_td_error': 0.08317599, 'max_td_error': 0.42328185, 'mean_weight': 0.45321640372276306}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3936, -0.3897, -0.3871, -0.3781]], device='cuda:0'), reward is -0.99\n",
      "Episode 336/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 12364, 'eps': 0.0, 'buffer_size': 12364, 'q_loss': 1.8410887718200684, 'mean_q_value': 0.05763796716928482, 'max_q_value': 0.2628007233142853, 'min_q_value': -0.5804147720336914, 'mean_td_error': 0.060088675, 'max_td_error': 0.19190264, 'mean_weight': 0.4934840798377991}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2508, -0.2799, -0.2234, -0.3594]], device='cuda:0'), reward is -0.99\n",
      "Episode 337/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12383, 'eps': 0.0, 'buffer_size': 12383, 'q_loss': 1.7064825296401978, 'mean_q_value': -0.03638029098510742, 'max_q_value': 0.29029399156570435, 'min_q_value': -0.9537369012832642, 'mean_td_error': 0.062361214, 'max_td_error': 0.37359262, 'mean_weight': 0.49450013041496277}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0374, -0.0168,  0.0336, -0.0273]], device='cuda:0'), reward is -0.99\n",
      "Episode 338/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 12441, 'eps': 0.0, 'buffer_size': 12441, 'q_loss': 1.9677702188491821, 'mean_q_value': -0.15472465753555298, 'max_q_value': 0.3065969944000244, 'min_q_value': -0.9845781326293945, 'mean_td_error': 0.0948636, 'max_td_error': 0.43542838, 'mean_weight': 0.603050708770752}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4943, -0.6589, -0.4469, -0.5478]], device='cuda:0'), reward is -0.99\n",
      "Episode 339/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 12479, 'eps': 0.0, 'buffer_size': 12479, 'q_loss': 1.5021626949310303, 'mean_q_value': -0.010565418750047684, 'max_q_value': 0.32865479588508606, 'min_q_value': -0.889997124671936, 'mean_td_error': 0.071674235, 'max_td_error': 0.40409213, 'mean_weight': 0.425327867269516}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5537, -0.4852, -0.5009, -0.5104]], device='cuda:0'), reward is -0.99\n",
      "Episode 340/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12498, 'eps': 0.0, 'buffer_size': 12498, 'q_loss': 1.8631901741027832, 'mean_q_value': -0.0866328701376915, 'max_q_value': 0.2945687174797058, 'min_q_value': -0.943665087223053, 'mean_td_error': 0.061979312, 'max_td_error': 0.4856466, 'mean_weight': 0.5486434698104858}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6954, -0.9196, -0.7923, -0.8842]], device='cuda:0'), reward is -0.99\n",
      "Episode 341/1000000: {'total_return': -0.85, 'steps': 15, 'total_steps': 12513, 'eps': 0.0, 'buffer_size': 12513, 'q_loss': 1.8735707998275757, 'mean_q_value': -0.04311671108007431, 'max_q_value': 0.28943687677383423, 'min_q_value': -0.9086548089981079, 'mean_td_error': 0.09214969, 'max_td_error': 0.4541126, 'mean_weight': 0.5356922149658203}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1168, 0.0665, 0.1186, 0.0894]], device='cuda:0'), reward is -0.99\n",
      "Episode 342/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 12529, 'eps': 0.0, 'buffer_size': 12529, 'q_loss': 1.7678526639938354, 'mean_q_value': -0.1537245661020279, 'max_q_value': 0.2975652813911438, 'min_q_value': -0.9392372965812683, 'mean_td_error': 0.096039414, 'max_td_error': 0.6011055, 'mean_weight': 0.5416887998580933}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3829, -0.2134, -0.3168, -0.2592]], device='cuda:0'), reward is -0.99\n",
      "Episode 343/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 12550, 'eps': 0.0, 'buffer_size': 12550, 'q_loss': 1.7262303829193115, 'mean_q_value': -0.11941427737474442, 'max_q_value': 0.37481462955474854, 'min_q_value': -0.9784585237503052, 'mean_td_error': 0.13195637, 'max_td_error': 0.6662488, 'mean_weight': 0.561550498008728}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7553, -0.6838, -0.5030, -0.6626]], device='cuda:0'), reward is -0.99\n",
      "Episode 344/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 12584, 'eps': 0.0, 'buffer_size': 12584, 'q_loss': 1.19120454788208, 'mean_q_value': -0.0023811664432287216, 'max_q_value': 0.287742555141449, 'min_q_value': -0.63959801197052, 'mean_td_error': 0.055831745, 'max_td_error': 0.48413187, 'mean_weight': 0.3233095109462738}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8691, -0.8094, -0.8246, -0.8139]], device='cuda:0'), reward is -0.99\n",
      "Episode 345/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 12602, 'eps': 0.0, 'buffer_size': 12602, 'q_loss': 1.829106330871582, 'mean_q_value': -0.06234923005104065, 'max_q_value': 0.23058122396469116, 'min_q_value': -0.9083786606788635, 'mean_td_error': 0.119702995, 'max_td_error': 0.88886887, 'mean_weight': 0.5387440919876099}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0188, 0.0719, 0.0860, 0.0413]], device='cuda:0'), reward is -0.99\n",
      "Episode 346/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 12674, 'eps': 0.0, 'buffer_size': 12674, 'q_loss': 1.3801329135894775, 'mean_q_value': -0.06633248925209045, 'max_q_value': 0.2849082052707672, 'min_q_value': -0.9183549880981445, 'mean_td_error': 0.073816285, 'max_td_error': 0.5856817, 'mean_weight': 0.39259210228919983}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0439, -0.1077, -0.0954, -0.4026]], device='cuda:0'), reward is -0.99\n",
      "Episode 347/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 12700, 'eps': 0.0, 'buffer_size': 12700, 'q_loss': 2.02889347076416, 'mean_q_value': -0.09924158453941345, 'max_q_value': 0.2607046365737915, 'min_q_value': -0.9710934162139893, 'mean_td_error': 0.067570195, 'max_td_error': 0.26568365, 'mean_weight': 0.5908471941947937}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8785, -0.8458, -0.8789, -0.8954]], device='cuda:0'), reward is -0.99\n",
      "Episode 348/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12719, 'eps': 0.0, 'buffer_size': 12719, 'q_loss': 1.195192813873291, 'mean_q_value': -0.015124140307307243, 'max_q_value': 0.3670532703399658, 'min_q_value': -0.8395565152168274, 'mean_td_error': 0.08399171, 'max_td_error': 0.39071196, 'mean_weight': 0.3342224657535553}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7241, -0.5801, -0.5917, -0.6354]], device='cuda:0'), reward is -0.99\n",
      "Episode 349/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12738, 'eps': 0.0, 'buffer_size': 12738, 'q_loss': 1.9024193286895752, 'mean_q_value': 0.033487468957901, 'max_q_value': 0.4003934860229492, 'min_q_value': -0.9562482237815857, 'mean_td_error': 0.094572276, 'max_td_error': 0.56566334, 'mean_weight': 0.5343964099884033}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8588, -0.8298, -0.8768, -0.8654]], device='cuda:0'), reward is -0.99\n",
      "Episode 350/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 12756, 'eps': 0.0, 'buffer_size': 12756, 'q_loss': 1.9975831508636475, 'mean_q_value': 0.009024981409311295, 'max_q_value': 0.35735636949539185, 'min_q_value': -0.6967588663101196, 'mean_td_error': 0.07674694, 'max_td_error': 0.3597179, 'mean_weight': 0.5588251948356628}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8017, -0.8039, -0.7603, -0.7796]], device='cuda:0'), reward is -0.99\n",
      "Episode 351/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 12783, 'eps': 0.0, 'buffer_size': 12783, 'q_loss': 1.763068675994873, 'mean_q_value': -0.140835702419281, 'max_q_value': 0.3295782804489136, 'min_q_value': -0.9720742106437683, 'mean_td_error': 0.09014097, 'max_td_error': 0.6291035, 'mean_weight': 0.5447942018508911}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9315, -0.9210, -0.9180, -0.9304]], device='cuda:0'), reward is -0.99\n",
      "Episode 352/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 12846, 'eps': 0.0, 'buffer_size': 12846, 'q_loss': 1.8778326511383057, 'mean_q_value': -0.04375753179192543, 'max_q_value': 0.3033318519592285, 'min_q_value': -0.9360196590423584, 'mean_td_error': 0.116385795, 'max_td_error': 0.7287482, 'mean_weight': 0.5541532039642334}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8185, -0.7561, -0.7696, -0.7279]], device='cuda:0'), reward is -0.99\n",
      "Episode 353/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 12864, 'eps': 0.0, 'buffer_size': 12864, 'q_loss': 1.8179844617843628, 'mean_q_value': -0.16765367984771729, 'max_q_value': 0.2680608630180359, 'min_q_value': -0.9983651041984558, 'mean_td_error': 0.060337473, 'max_td_error': 0.43218789, 'mean_weight': 0.5828511714935303}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5289, -0.3560, -0.2545, -0.2833]], device='cuda:0'), reward is -0.99\n",
      "Episode 354/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 12897, 'eps': 0.0, 'buffer_size': 12897, 'q_loss': 1.5964748859405518, 'mean_q_value': -0.1403559148311615, 'max_q_value': 0.2947383522987366, 'min_q_value': -1.0051440000534058, 'mean_td_error': 0.102051996, 'max_td_error': 0.43448767, 'mean_weight': 0.4891839027404785}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7145, -0.6031, -0.6104, -0.5517]], device='cuda:0'), reward is -0.99\n",
      "Episode 355/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 12916, 'eps': 0.0, 'buffer_size': 12916, 'q_loss': 1.8689486980438232, 'mean_q_value': 0.005772138014435768, 'max_q_value': 0.30107563734054565, 'min_q_value': -0.9110751152038574, 'mean_td_error': 0.0822498, 'max_td_error': 0.36152655, 'mean_weight': 0.5255037546157837}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6468, -0.4416, -0.4517, -0.4978]], device='cuda:0'), reward is -0.99\n",
      "Episode 356/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 12940, 'eps': 0.0, 'buffer_size': 12940, 'q_loss': 2.0130527019500732, 'mean_q_value': 0.012664907611906528, 'max_q_value': 0.29768869280815125, 'min_q_value': -0.8524616956710815, 'mean_td_error': 0.053124666, 'max_td_error': 0.24017996, 'mean_weight': 0.5496543645858765}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0072,  0.0028, -0.0473, -0.0235]], device='cuda:0'), reward is -0.99\n",
      "Episode 357/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 12970, 'eps': 0.0, 'buffer_size': 12970, 'q_loss': 1.9912235736846924, 'mean_q_value': -0.13821759819984436, 'max_q_value': 0.27927494049072266, 'min_q_value': -0.9316653609275818, 'mean_td_error': 0.060475443, 'max_td_error': 0.22419064, 'mean_weight': 0.6104660034179688}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7991, -0.8906, -0.7641, -0.8675]], device='cuda:0'), reward is -0.99\n",
      "Episode 358/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 13007, 'eps': 0.0, 'buffer_size': 13007, 'q_loss': 1.9146625995635986, 'mean_q_value': -0.05083174258470535, 'max_q_value': 0.25988584756851196, 'min_q_value': -0.9762584567070007, 'mean_td_error': 0.0838082, 'max_td_error': 0.62362325, 'mean_weight': 0.5437638759613037}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8086, -0.8429, -0.7916, -0.8498]], device='cuda:0'), reward is -0.99\n",
      "Episode 359/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13026, 'eps': 0.0, 'buffer_size': 13026, 'q_loss': 1.7625365257263184, 'mean_q_value': -0.09601932764053345, 'max_q_value': 0.33834242820739746, 'min_q_value': -0.9577580094337463, 'mean_td_error': 0.0721654, 'max_td_error': 0.35628808, 'mean_weight': 0.5390638113021851}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5153, -0.4513, -0.4747, -0.4852]], device='cuda:0'), reward is -0.99\n",
      "Episode 360/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13045, 'eps': 0.0, 'buffer_size': 13045, 'q_loss': 1.771064281463623, 'mean_q_value': -0.08447209000587463, 'max_q_value': 0.3087971806526184, 'min_q_value': -0.9659854769706726, 'mean_td_error': 0.07189886, 'max_td_error': 0.36027938, 'mean_weight': 0.5488119721412659}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7702, -0.7307, -0.7399, -0.7561]], device='cuda:0'), reward is -0.99\n",
      "Episode 361/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 13075, 'eps': 0.0, 'buffer_size': 13075, 'q_loss': 1.975433111190796, 'mean_q_value': -0.1650838702917099, 'max_q_value': 0.27873730659484863, 'min_q_value': -0.9665815234184265, 'mean_td_error': 0.06294966, 'max_td_error': 0.2353134, 'mean_weight': 0.5961092710494995}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9958, -0.9848, -0.9777, -0.9906]], device='cuda:0'), reward is -0.99\n",
      "Episode 362/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 13129, 'eps': 0.0, 'buffer_size': 13129, 'q_loss': 2.3138139247894287, 'mean_q_value': -0.06336061656475067, 'max_q_value': 0.31406301259994507, 'min_q_value': -0.8785316944122314, 'mean_td_error': 0.05910517, 'max_td_error': 0.32200852, 'mean_weight': 0.6726950407028198}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8822, -0.8754, -0.9039, -0.8727]], device='cuda:0'), reward is -0.99\n",
      "Episode 363/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 13147, 'eps': 0.0, 'buffer_size': 13147, 'q_loss': 1.513777732849121, 'mean_q_value': -0.023105494678020477, 'max_q_value': 0.3429546654224396, 'min_q_value': -0.9493988156318665, 'mean_td_error': 0.06583533, 'max_td_error': 0.39338994, 'mean_weight': 0.43116337060928345}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4407, -0.5157, -0.4810, -0.5540]], device='cuda:0'), reward is -0.99\n",
      "Episode 364/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 13165, 'eps': 0.0, 'buffer_size': 13165, 'q_loss': 1.133156180381775, 'mean_q_value': -0.04078429937362671, 'max_q_value': 0.3179614543914795, 'min_q_value': -0.6700230240821838, 'mean_td_error': 0.10365297, 'max_td_error': 0.5700365, 'mean_weight': 0.32062387466430664}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2463, -0.3017, -0.3071, -0.4164]], device='cuda:0'), reward is -0.99\n",
      "Episode 365/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13184, 'eps': 0.0, 'buffer_size': 13184, 'q_loss': 1.468672275543213, 'mean_q_value': -0.05786142498254776, 'max_q_value': 0.27685239911079407, 'min_q_value': -0.9446828365325928, 'mean_td_error': 0.10064907, 'max_td_error': 0.74576414, 'mean_weight': 0.4387187957763672}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7769, -0.8662, -0.8281, -0.8187]], device='cuda:0'), reward is -0.99\n",
      "Episode 366/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13203, 'eps': 0.0, 'buffer_size': 13203, 'q_loss': 1.2443838119506836, 'mean_q_value': -0.077886201441288, 'max_q_value': 0.3205209970474243, 'min_q_value': -0.9790991544723511, 'mean_td_error': 0.07578838, 'max_td_error': 0.7053504, 'mean_weight': 0.37988388538360596}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6443, -0.4939, -0.6379, -0.7283]], device='cuda:0'), reward is -0.99\n",
      "Episode 367/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 13246, 'eps': 0.0, 'buffer_size': 13246, 'q_loss': 1.6724141836166382, 'mean_q_value': -0.05217667669057846, 'max_q_value': 0.35687196254730225, 'min_q_value': -0.9631395936012268, 'mean_td_error': 0.08271831, 'max_td_error': 0.47385645, 'mean_weight': 0.48909425735473633}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1564, 0.1686, 0.1679, 0.1635]], device='cuda:0'), reward is -0.99\n",
      "Episode 368/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 13313, 'eps': 0.0, 'buffer_size': 13313, 'q_loss': 1.6328516006469727, 'mean_q_value': -0.039073050022125244, 'max_q_value': 0.3850729167461395, 'min_q_value': -0.9336662292480469, 'mean_td_error': 0.08625913, 'max_td_error': 0.51392215, 'mean_weight': 0.49064284563064575}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9112, -0.9228, -0.9031, -0.9382]], device='cuda:0'), reward is -0.99\n",
      "Episode 369/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 13348, 'eps': 0.0, 'buffer_size': 13348, 'q_loss': 1.4811030626296997, 'mean_q_value': -0.2592085897922516, 'max_q_value': 0.25448083877563477, 'min_q_value': -0.9379788041114807, 'mean_td_error': 0.0793309, 'max_td_error': 0.43982065, 'mean_weight': 0.49090638756752014}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2503, -0.1927, -0.2450, -0.1888]], device='cuda:0'), reward is -0.99\n",
      "Episode 370/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 13366, 'eps': 0.0, 'buffer_size': 13366, 'q_loss': 1.4183796644210815, 'mean_q_value': -0.05832682177424431, 'max_q_value': 0.26081928610801697, 'min_q_value': -0.8949685096740723, 'mean_td_error': 0.06337186, 'max_td_error': 0.22795282, 'mean_weight': 0.4107738733291626}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9572, -0.9570, -0.9703, -0.9439]], device='cuda:0'), reward is -0.99\n",
      "Episode 371/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13385, 'eps': 0.0, 'buffer_size': 13385, 'q_loss': 1.5276401042938232, 'mean_q_value': -0.12442578375339508, 'max_q_value': 0.2998239994049072, 'min_q_value': -0.9629068374633789, 'mean_td_error': 0.06967949, 'max_td_error': 0.39630502, 'mean_weight': 0.4794391989707947}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3799, -0.3936, -0.3352, -0.3886]], device='cuda:0'), reward is -0.99\n",
      "Episode 372/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 13404, 'eps': 0.0, 'buffer_size': 13404, 'q_loss': 2.0114033222198486, 'mean_q_value': -0.049497880041599274, 'max_q_value': 0.2763793468475342, 'min_q_value': -0.7193456888198853, 'mean_td_error': 0.059817128, 'max_td_error': 0.2706535, 'mean_weight': 0.5653579235076904}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7916, -0.5371, -0.6210, -0.6184]], device='cuda:0'), reward is -0.99\n",
      "Episode 373/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 13436, 'eps': 0.0, 'buffer_size': 13436, 'q_loss': 1.9134376049041748, 'mean_q_value': -0.17174962162971497, 'max_q_value': 0.28620681166648865, 'min_q_value': -0.9482415914535522, 'mean_td_error': 0.08377814, 'max_td_error': 0.30025953, 'mean_weight': 0.612968385219574}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4330, -0.3508, -0.5221, -0.6741]], device='cuda:0'), reward is -0.99\n",
      "Episode 374/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 13472, 'eps': 0.0, 'buffer_size': 13472, 'q_loss': 1.6103705167770386, 'mean_q_value': -0.16224892437458038, 'max_q_value': 0.28634804487228394, 'min_q_value': -0.8589600324630737, 'mean_td_error': 0.08272995, 'max_td_error': 0.42701885, 'mean_weight': 0.4809378981590271}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1900, -0.1968, -0.1863, -0.2135]], device='cuda:0'), reward is -0.99\n",
      "Episode 375/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 13549, 'eps': 0.0, 'buffer_size': 13549, 'q_loss': 1.5993913412094116, 'mean_q_value': -0.06341229379177094, 'max_q_value': 0.28187650442123413, 'min_q_value': -0.9786670804023743, 'mean_td_error': 0.044868737, 'max_td_error': 0.23322137, 'mean_weight': 0.4855685830116272}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5759, -0.4627, -0.4407, -0.4966]], device='cuda:0'), reward is -0.99\n",
      "Episode 376/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 13579, 'eps': 0.0, 'buffer_size': 13579, 'q_loss': 2.1870594024658203, 'mean_q_value': -0.1402522474527359, 'max_q_value': 0.28020763397216797, 'min_q_value': -0.7884135246276855, 'mean_td_error': 0.1101505, 'max_td_error': 0.56802976, 'mean_weight': 0.632672131061554}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0041, -0.0677, -0.0189, -0.0469]], device='cuda:0'), reward is -0.99\n",
      "Episode 377/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 13607, 'eps': 0.0, 'buffer_size': 13607, 'q_loss': 1.5015848875045776, 'mean_q_value': 0.049221526831388474, 'max_q_value': 0.3715977370738983, 'min_q_value': -0.7989279627799988, 'mean_td_error': 0.05230545, 'max_td_error': 0.17900327, 'mean_weight': 0.4168020188808441}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2399, -0.2402, -0.1882, -0.3668]], device='cuda:0'), reward is -0.99\n",
      "Episode 378/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 13648, 'eps': 0.0, 'buffer_size': 13648, 'q_loss': 1.4261630773544312, 'mean_q_value': -0.12075842171907425, 'max_q_value': 0.35376638174057007, 'min_q_value': -0.9410174489021301, 'mean_td_error': 0.062294737, 'max_td_error': 0.2497611, 'mean_weight': 0.43983060121536255}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2405, -0.2383, -0.2384, -0.2163]], device='cuda:0'), reward is -0.99\n",
      "Episode 379/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 13680, 'eps': 0.0, 'buffer_size': 13680, 'q_loss': 1.4917278289794922, 'mean_q_value': -0.025227848440408707, 'max_q_value': 0.3096924126148224, 'min_q_value': -0.9326786398887634, 'mean_td_error': 0.06283187, 'max_td_error': 0.49321872, 'mean_weight': 0.4234631657600403}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0834, 0.1069, 0.1104, 0.0943]], device='cuda:0'), reward is -0.99\n",
      "Episode 380/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 13707, 'eps': 0.0, 'buffer_size': 13707, 'q_loss': 1.4612011909484863, 'mean_q_value': -0.1393580287694931, 'max_q_value': 0.2606066167354584, 'min_q_value': -0.9489213228225708, 'mean_td_error': 0.043844745, 'max_td_error': 0.29944217, 'mean_weight': 0.4550016522407532}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3691, -0.1589, -0.1241, -0.2555]], device='cuda:0'), reward is -0.99\n",
      "Episode 381/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 13759, 'eps': 0.0, 'buffer_size': 13759, 'q_loss': 1.5679609775543213, 'mean_q_value': -0.15070222318172455, 'max_q_value': 0.31864601373672485, 'min_q_value': -0.966701328754425, 'mean_td_error': 0.073933065, 'max_td_error': 0.34099057, 'mean_weight': 0.487263947725296}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6560, -0.6377, -0.6673, -0.6353]], device='cuda:0'), reward is -0.99\n",
      "Episode 382/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 13785, 'eps': 0.0, 'buffer_size': 13785, 'q_loss': 1.5242760181427002, 'mean_q_value': -0.06565145403146744, 'max_q_value': 0.32088756561279297, 'min_q_value': -0.969826877117157, 'mean_td_error': 0.06319808, 'max_td_error': 0.32998955, 'mean_weight': 0.4468885362148285}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8612, -0.8610, -0.8128, -0.8813]], device='cuda:0'), reward is -0.99\n",
      "Episode 383/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 13835, 'eps': 0.0, 'buffer_size': 13835, 'q_loss': 1.9154088497161865, 'mean_q_value': -0.11425499618053436, 'max_q_value': 0.2976144552230835, 'min_q_value': -0.9090659618377686, 'mean_td_error': 0.061541807, 'max_td_error': 0.30755937, 'mean_weight': 0.5904006958007812}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7208, -0.7703, -0.7403, -0.6690]], device='cuda:0'), reward is -0.99\n",
      "Episode 384/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 13860, 'eps': 0.0, 'buffer_size': 13860, 'q_loss': 1.5651439428329468, 'mean_q_value': -0.07583333551883698, 'max_q_value': 0.2925353944301605, 'min_q_value': -0.9990327954292297, 'mean_td_error': 0.08416042, 'max_td_error': 1.069012, 'mean_weight': 0.47707653045654297}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0802, -0.0950, -0.0008, -0.0863]], device='cuda:0'), reward is -0.99\n",
      "Episode 385/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 13905, 'eps': 0.0, 'buffer_size': 13905, 'q_loss': 1.749070644378662, 'mean_q_value': -0.1509973406791687, 'max_q_value': 0.29410845041275024, 'min_q_value': -0.958572268486023, 'mean_td_error': 0.06788251, 'max_td_error': 0.4424785, 'mean_weight': 0.5356670618057251}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1619, 0.1990, 0.1923, 0.2161]], device='cuda:0'), reward is -0.99\n",
      "Episode 386/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 13936, 'eps': 0.0, 'buffer_size': 13936, 'q_loss': 1.8748401403427124, 'mean_q_value': -0.0868639126420021, 'max_q_value': 0.34539106488227844, 'min_q_value': -0.9308740496635437, 'mean_td_error': 0.09159903, 'max_td_error': 0.4337362, 'mean_weight': 0.5524291396141052}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2057, -0.1925, -0.1670, -0.1348]], device='cuda:0'), reward is -0.99\n",
      "Episode 387/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 13976, 'eps': 0.0, 'buffer_size': 13976, 'q_loss': 1.5999441146850586, 'mean_q_value': -0.08555388450622559, 'max_q_value': 0.25381237268447876, 'min_q_value': -0.7770804166793823, 'mean_td_error': 0.10123761, 'max_td_error': 0.63152516, 'mean_weight': 0.48282724618911743}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1714, -0.1561, -0.1479, -0.1651]], device='cuda:0'), reward is -0.99\n",
      "Episode 388/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 13996, 'eps': 0.0, 'buffer_size': 13996, 'q_loss': 1.4011292457580566, 'mean_q_value': -0.08182568848133087, 'max_q_value': 0.36316877603530884, 'min_q_value': -0.9778237342834473, 'mean_td_error': 0.04787191, 'max_td_error': 0.14357151, 'mean_weight': 0.4395448565483093}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3058, -0.2942, -0.2906, -0.2922]], device='cuda:0'), reward is -0.99\n",
      "Episode 389/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 14022, 'eps': 0.0, 'buffer_size': 14022, 'q_loss': 1.5876622200012207, 'mean_q_value': -0.07355616986751556, 'max_q_value': 0.2912445366382599, 'min_q_value': -0.9219788908958435, 'mean_td_error': 0.05308071, 'max_td_error': 0.24855047, 'mean_weight': 0.47424596548080444}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1409, 0.1325, 0.1204, 0.1422]], device='cuda:0'), reward is -0.99\n",
      "Episode 390/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 14042, 'eps': 0.0, 'buffer_size': 14042, 'q_loss': 1.5170345306396484, 'mean_q_value': -0.05656103044748306, 'max_q_value': 0.30747970938682556, 'min_q_value': -0.9681604504585266, 'mean_td_error': 0.05404999, 'max_td_error': 0.2530322, 'mean_weight': 0.4595370590686798}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1737, -0.1578, -0.1690, -0.1578]], device='cuda:0'), reward is -0.99\n",
      "Episode 391/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 14068, 'eps': 0.0, 'buffer_size': 14068, 'q_loss': 1.6270360946655273, 'mean_q_value': -0.10284504294395447, 'max_q_value': 0.2883954644203186, 'min_q_value': -0.9478188753128052, 'mean_td_error': 0.045890994, 'max_td_error': 0.1939435, 'mean_weight': 0.5022650957107544}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3972, -0.4203, -0.3562, -0.4822]], device='cuda:0'), reward is -0.99\n",
      "Episode 392/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 14089, 'eps': 0.0, 'buffer_size': 14089, 'q_loss': 1.5645768642425537, 'mean_q_value': -0.013217910192906857, 'max_q_value': 0.30176085233688354, 'min_q_value': -0.8455277681350708, 'mean_td_error': 0.069288984, 'max_td_error': 0.64062583, 'mean_weight': 0.44591331481933594}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4455, -0.3512, -0.3407, -0.4760]], device='cuda:0'), reward is -0.99\n",
      "Episode 393/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 14146, 'eps': 0.0, 'buffer_size': 14146, 'q_loss': 1.384223461151123, 'mean_q_value': -0.15453225374221802, 'max_q_value': 0.25026535987854004, 'min_q_value': -0.8622060418128967, 'mean_td_error': 0.10987432, 'max_td_error': 0.5293564, 'mean_weight': 0.4049909710884094}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5908, -0.4976, -0.6198, -0.5722]], device='cuda:0'), reward is -0.99\n",
      "Episode 394/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 14205, 'eps': 0.0, 'buffer_size': 14205, 'q_loss': 1.231898546218872, 'mean_q_value': -0.07269139587879181, 'max_q_value': 0.2955746054649353, 'min_q_value': -0.970727264881134, 'mean_td_error': 0.057185054, 'max_td_error': 0.3821989, 'mean_weight': 0.3718084990978241}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1643, -0.1115, -0.1109, -0.2451]], device='cuda:0'), reward is -0.99\n",
      "Episode 395/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 14260, 'eps': 0.0, 'buffer_size': 14260, 'q_loss': 1.601613998413086, 'mean_q_value': -0.0013354718685150146, 'max_q_value': 0.28420165181159973, 'min_q_value': -0.8235422968864441, 'mean_td_error': 0.06440629, 'max_td_error': 0.34303227, 'mean_weight': 0.4463960528373718}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8601, -0.8334, -0.8281, -0.8498]], device='cuda:0'), reward is -0.99\n",
      "Episode 396/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 14285, 'eps': 0.0, 'buffer_size': 14285, 'q_loss': 2.349445343017578, 'mean_q_value': 0.012808714061975479, 'max_q_value': 0.33800631761550903, 'min_q_value': -0.7766422629356384, 'mean_td_error': 0.04931339, 'max_td_error': 0.19271746, 'mean_weight': 0.6539793610572815}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5996, -0.3657, -0.4009, -0.3535]], device='cuda:0'), reward is -0.99\n",
      "Episode 397/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 14313, 'eps': 0.0, 'buffer_size': 14313, 'q_loss': 1.9713284969329834, 'mean_q_value': -0.14445260167121887, 'max_q_value': 0.3371698260307312, 'min_q_value': -0.9719972610473633, 'mean_td_error': 0.068277925, 'max_td_error': 0.2426126, 'mean_weight': 0.6052321195602417}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3416, -0.2845, -0.2542, -0.3651]], device='cuda:0'), reward is -0.99\n",
      "Episode 398/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 14374, 'eps': 0.0, 'buffer_size': 14374, 'q_loss': 2.05928635597229, 'mean_q_value': -0.09966902434825897, 'max_q_value': 0.28749898076057434, 'min_q_value': -0.8710819482803345, 'mean_td_error': 0.1254045, 'max_td_error': 0.67187285, 'mean_weight': 0.6181647181510925}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4434, -0.4969, -0.3527, -0.3995]], device='cuda:0'), reward is -0.99\n",
      "Episode 399/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 14399, 'eps': 0.0, 'buffer_size': 14399, 'q_loss': 1.6493279933929443, 'mean_q_value': -0.017590992152690887, 'max_q_value': 0.3162943422794342, 'min_q_value': -0.9110125303268433, 'mean_td_error': 0.05576411, 'max_td_error': 0.25101173, 'mean_weight': 0.4685153663158417}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7219, -0.8430, -0.6904, -0.6351]], device='cuda:0'), reward is -0.99\n",
      "Episode 400/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 14439, 'eps': 0.0, 'buffer_size': 14439, 'q_loss': 1.2686805725097656, 'mean_q_value': -0.1698538064956665, 'max_q_value': 0.2748867869377136, 'min_q_value': -0.9634917378425598, 'mean_td_error': 0.07117009, 'max_td_error': 0.4267779, 'mean_weight': 0.3966066837310791}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0470, -0.1117, -0.5117, -0.1355]], device='cuda:0'), reward is -0.99\n",
      "Episode 401/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 14463, 'eps': 0.0, 'buffer_size': 14463, 'q_loss': 1.6590150594711304, 'mean_q_value': -0.10112941265106201, 'max_q_value': 0.31592437624931335, 'min_q_value': -0.8974955677986145, 'mean_td_error': 0.08435939, 'max_td_error': 0.9742035, 'mean_weight': 0.4936572015285492}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6101, -0.5871, -0.5627, -0.5605]], device='cuda:0'), reward is -0.99\n",
      "Episode 402/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 14505, 'eps': 0.0, 'buffer_size': 14505, 'q_loss': 2.425565719604492, 'mean_q_value': -0.0265344325453043, 'max_q_value': 0.23721815645694733, 'min_q_value': -0.9797306060791016, 'mean_td_error': 0.054527614, 'max_td_error': 0.30303234, 'mean_weight': 0.6835992336273193}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3544, -0.3379, -0.3264, -0.3830]], device='cuda:0'), reward is -0.99\n",
      "Episode 403/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 14548, 'eps': 0.0, 'buffer_size': 14548, 'q_loss': 1.6726285219192505, 'mean_q_value': -0.13967379927635193, 'max_q_value': 0.28371936082839966, 'min_q_value': -0.8948831558227539, 'mean_td_error': 0.12809733, 'max_td_error': 0.6582348, 'mean_weight': 0.5169610381126404}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0784, -0.0711, -0.0862, -0.1046]], device='cuda:0'), reward is -0.99\n",
      "Episode 404/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 14573, 'eps': 0.0, 'buffer_size': 14573, 'q_loss': 1.2294436693191528, 'mean_q_value': -0.08780624717473984, 'max_q_value': 0.31666135787963867, 'min_q_value': -0.9437968134880066, 'mean_td_error': 0.056759804, 'max_td_error': 0.19368415, 'mean_weight': 0.36223307251930237}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6559, -0.7995, -0.7023, -0.7698]], device='cuda:0'), reward is -0.99\n",
      "Episode 405/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 14612, 'eps': 0.0, 'buffer_size': 14612, 'q_loss': 1.8805689811706543, 'mean_q_value': -0.07207946479320526, 'max_q_value': 0.3749960660934448, 'min_q_value': -0.9072529673576355, 'mean_td_error': 0.06737283, 'max_td_error': 0.36660677, 'mean_weight': 0.5590983629226685}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7161, -0.6804, -0.5410, -0.3907]], device='cuda:0'), reward is -0.99\n",
      "Episode 406/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 14647, 'eps': 0.0, 'buffer_size': 14647, 'q_loss': 2.141249179840088, 'mean_q_value': 0.03749517351388931, 'max_q_value': 0.31859642267227173, 'min_q_value': -0.9290875792503357, 'mean_td_error': 0.06909378, 'max_td_error': 0.37885624, 'mean_weight': 0.6091805696487427}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0982, -0.1025, -0.0916, -0.0936]], device='cuda:0'), reward is -0.99\n",
      "Episode 407/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 14691, 'eps': 0.0, 'buffer_size': 14691, 'q_loss': 1.740260362625122, 'mean_q_value': -0.024155348539352417, 'max_q_value': 0.32630500197410583, 'min_q_value': -0.9187788963317871, 'mean_td_error': 0.0712016, 'max_td_error': 0.54693955, 'mean_weight': 0.511135458946228}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8838, -0.8832, -0.8860, -0.9084]], device='cuda:0'), reward is -0.99\n",
      "Episode 408/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 14732, 'eps': 0.0, 'buffer_size': 14732, 'q_loss': 1.5201749801635742, 'mean_q_value': -0.08630131185054779, 'max_q_value': 0.24897238612174988, 'min_q_value': -0.9477715492248535, 'mean_td_error': 0.09347252, 'max_td_error': 0.59120256, 'mean_weight': 0.43111085891723633}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5023, -0.5041, -0.5525, -0.4531]], device='cuda:0'), reward is -0.99\n",
      "Episode 409/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 14751, 'eps': 0.0, 'buffer_size': 14751, 'q_loss': 1.2867079973220825, 'mean_q_value': -0.08489324152469635, 'max_q_value': 0.27513325214385986, 'min_q_value': -0.9103813171386719, 'mean_td_error': 0.051203266, 'max_td_error': 0.3429144, 'mean_weight': 0.37309080362319946}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1254, 0.1374, 0.1347, 0.1463]], device='cuda:0'), reward is -0.99\n",
      "Episode 410/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 14771, 'eps': 0.0, 'buffer_size': 14771, 'q_loss': 1.4583314657211304, 'mean_q_value': 0.03777899965643883, 'max_q_value': 0.38913753628730774, 'min_q_value': -0.8719342350959778, 'mean_td_error': 0.06015797, 'max_td_error': 0.3023448, 'mean_weight': 0.4001234769821167}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4552, -0.6353, -0.4885, -0.4211]], device='cuda:0'), reward is -0.99\n",
      "Episode 411/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 14808, 'eps': 0.0, 'buffer_size': 14808, 'q_loss': 0.9020835161209106, 'mean_q_value': -0.10499753057956696, 'max_q_value': 0.30173444747924805, 'min_q_value': -0.9623866677284241, 'mean_td_error': 0.063788, 'max_td_error': 0.3854156, 'mean_weight': 0.26418256759643555}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4551, -0.4960, -0.6205, -0.4024]], device='cuda:0'), reward is -0.99\n",
      "Episode 412/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 14844, 'eps': 0.0, 'buffer_size': 14844, 'q_loss': 1.8916192054748535, 'mean_q_value': -0.05549140274524689, 'max_q_value': 0.2989591360092163, 'min_q_value': -0.9391027092933655, 'mean_td_error': 0.068494394, 'max_td_error': 0.3357972, 'mean_weight': 0.5524696111679077}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5865, -0.6568, -0.5267, -0.4526]], device='cuda:0'), reward is -0.99\n",
      "Episode 413/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 14878, 'eps': 0.0, 'buffer_size': 14878, 'q_loss': 1.5185704231262207, 'mean_q_value': -0.0743592232465744, 'max_q_value': 0.2739819288253784, 'min_q_value': -0.9016609191894531, 'mean_td_error': 0.09458123, 'max_td_error': 1.1303992, 'mean_weight': 0.43924927711486816}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3241, -0.2627, -0.2981, -0.3042]], device='cuda:0'), reward is -0.99\n",
      "Episode 414/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 14914, 'eps': 0.0, 'buffer_size': 14914, 'q_loss': 1.3935935497283936, 'mean_q_value': -0.13425397872924805, 'max_q_value': 0.2998667359352112, 'min_q_value': -0.9504712820053101, 'mean_td_error': 0.07548496, 'max_td_error': 0.31533134, 'mean_weight': 0.41844838857650757}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5489, -0.4120, -0.4491, -0.5293]], device='cuda:0'), reward is -0.99\n",
      "Episode 415/1000000: {'total_return': -0.16999999999999948, 'steps': 83, 'total_steps': 14997, 'eps': 0.0, 'buffer_size': 14997, 'q_loss': 0.7479290962219238, 'mean_q_value': -0.09795916080474854, 'max_q_value': 0.3397819995880127, 'min_q_value': -0.8077809810638428, 'mean_td_error': 0.09478716, 'max_td_error': 0.4373519, 'mean_weight': 0.22427624464035034}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3966, -0.4220, -0.2919, -0.2241]], device='cuda:0'), reward is -0.99\n",
      "Episode 416/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 15042, 'eps': 0.0, 'buffer_size': 15042, 'q_loss': 1.3403666019439697, 'mean_q_value': -0.13558878004550934, 'max_q_value': 0.3316481411457062, 'min_q_value': -0.9520895481109619, 'mean_td_error': 0.06621252, 'max_td_error': 0.25749782, 'mean_weight': 0.4412573575973511}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6366, -0.6232, -0.6235, -0.6005]], device='cuda:0'), reward is -0.99\n",
      "Episode 417/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 15084, 'eps': 0.0, 'buffer_size': 15084, 'q_loss': 1.6618788242340088, 'mean_q_value': -0.10086558014154434, 'max_q_value': 0.3128349184989929, 'min_q_value': -0.9528617262840271, 'mean_td_error': 0.045733716, 'max_td_error': 0.30996335, 'mean_weight': 0.49911707639694214}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8836, -0.8807, -0.8654, -0.8659]], device='cuda:0'), reward is -0.99\n",
      "Episode 418/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 15120, 'eps': 0.0, 'buffer_size': 15120, 'q_loss': 1.9341099262237549, 'mean_q_value': -0.16886426508426666, 'max_q_value': 0.2740247845649719, 'min_q_value': -0.9474779963493347, 'mean_td_error': 0.09975478, 'max_td_error': 0.49682707, 'mean_weight': 0.5997692346572876}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1598, -0.1478, -0.1348, -0.1373]], device='cuda:0'), reward is -0.99\n",
      "Episode 419/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 15160, 'eps': 0.0, 'buffer_size': 15160, 'q_loss': 2.0248777866363525, 'mean_q_value': -0.014988206326961517, 'max_q_value': 0.30329808592796326, 'min_q_value': -0.9904278516769409, 'mean_td_error': 0.07217643, 'max_td_error': 0.693141, 'mean_weight': 0.5850490927696228}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0528, -0.1289, -0.0531, -0.1766]], device='cuda:0'), reward is -0.99\n",
      "Episode 420/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 15212, 'eps': 0.0, 'buffer_size': 15212, 'q_loss': 1.771411657333374, 'mean_q_value': -0.14760161936283112, 'max_q_value': 0.3009810447692871, 'min_q_value': -0.9696527719497681, 'mean_td_error': 0.08767358, 'max_td_error': 0.34524602, 'mean_weight': 0.5447413921356201}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2420, -0.1970, -0.1530, -0.1797]], device='cuda:0'), reward is -0.99\n",
      "Episode 421/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 15241, 'eps': 0.0, 'buffer_size': 15241, 'q_loss': 1.4187798500061035, 'mean_q_value': -0.04106910526752472, 'max_q_value': 0.2583123743534088, 'min_q_value': -0.7656944394111633, 'mean_td_error': 0.08825436, 'max_td_error': 0.2786491, 'mean_weight': 0.38836705684661865}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7828, -0.7136, -0.7149, -0.8215]], device='cuda:0'), reward is -0.99\n",
      "Episode 422/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 15286, 'eps': 0.0, 'buffer_size': 15286, 'q_loss': 2.186927318572998, 'mean_q_value': -0.02814560942351818, 'max_q_value': 0.3206857144832611, 'min_q_value': -0.8078708052635193, 'mean_td_error': 0.07328617, 'max_td_error': 0.27713132, 'mean_weight': 0.6472306251525879}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9737, -0.9763, -0.9449, -0.9531]], device='cuda:0'), reward is -0.99\n",
      "Episode 423/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 15332, 'eps': 0.0, 'buffer_size': 15332, 'q_loss': 1.6691193580627441, 'mean_q_value': -0.06952932476997375, 'max_q_value': 0.3303598165512085, 'min_q_value': -0.9545930027961731, 'mean_td_error': 0.07503953, 'max_td_error': 0.32148325, 'mean_weight': 0.4877012372016907}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5409, -0.4763, -0.4797, -0.4983]], device='cuda:0'), reward is -0.99\n",
      "Episode 424/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 15366, 'eps': 0.0, 'buffer_size': 15366, 'q_loss': 1.3164708614349365, 'mean_q_value': -0.10981233417987823, 'max_q_value': 0.33370617032051086, 'min_q_value': -0.9527924060821533, 'mean_td_error': 0.07415283, 'max_td_error': 0.55096626, 'mean_weight': 0.4073850214481354}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3696, -0.3704, -0.3231, -0.4931]], device='cuda:0'), reward is -0.99\n",
      "Episode 425/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 15399, 'eps': 0.0, 'buffer_size': 15399, 'q_loss': 1.7024743556976318, 'mean_q_value': -0.04062914848327637, 'max_q_value': 0.34766054153442383, 'min_q_value': -0.950677216053009, 'mean_td_error': 0.076446325, 'max_td_error': 0.40070248, 'mean_weight': 0.5080878734588623}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2584, -0.3184, -0.3212, -0.0905]], device='cuda:0'), reward is -0.99\n",
      "Episode 426/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 15432, 'eps': 0.0, 'buffer_size': 15432, 'q_loss': 2.107236862182617, 'mean_q_value': -0.009134287014603615, 'max_q_value': 0.30560702085494995, 'min_q_value': -0.6392901539802551, 'mean_td_error': 0.09472732, 'max_td_error': 0.45508158, 'mean_weight': 0.5967522859573364}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8788, -0.8549, -0.8262, -0.8203]], device='cuda:0'), reward is -0.99\n",
      "Episode 427/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 15467, 'eps': 0.0, 'buffer_size': 15467, 'q_loss': 1.9025616645812988, 'mean_q_value': -0.03864235430955887, 'max_q_value': 0.33051615953445435, 'min_q_value': -0.8768101930618286, 'mean_td_error': 0.0618942, 'max_td_error': 0.14914265, 'mean_weight': 0.5623230338096619}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1568, 0.1770, 0.1647, 0.1789]], device='cuda:0'), reward is -0.99\n",
      "Episode 428/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 15490, 'eps': 0.0, 'buffer_size': 15490, 'q_loss': 1.8946866989135742, 'mean_q_value': -0.16705450415611267, 'max_q_value': 0.26438724994659424, 'min_q_value': -0.9162600040435791, 'mean_td_error': 0.08325338, 'max_td_error': 0.3735894, 'mean_weight': 0.5701851844787598}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2677, -0.3724, -0.3217, -0.4429]], device='cuda:0'), reward is -0.99\n",
      "Episode 429/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 15516, 'eps': 0.0, 'buffer_size': 15516, 'q_loss': 1.6464228630065918, 'mean_q_value': -0.040854744613170624, 'max_q_value': 0.28163179755210876, 'min_q_value': -0.8813192844390869, 'mean_td_error': 0.054597102, 'max_td_error': 0.22050643, 'mean_weight': 0.48032426834106445}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2141, -0.2767, -0.1775, -0.4567]], device='cuda:0'), reward is -0.99\n",
      "Episode 430/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 15539, 'eps': 0.0, 'buffer_size': 15539, 'q_loss': 1.7370052337646484, 'mean_q_value': -0.1316734403371811, 'max_q_value': 0.32445627450942993, 'min_q_value': -0.971710205078125, 'mean_td_error': 0.056476623, 'max_td_error': 0.18630913, 'mean_weight': 0.5244497060775757}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1962, -0.2720, -0.2359, -0.1619]], device='cuda:0'), reward is -0.99\n",
      "Episode 431/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 15582, 'eps': 0.0, 'buffer_size': 15582, 'q_loss': 1.637275218963623, 'mean_q_value': -0.10886011272668839, 'max_q_value': 0.3057583272457123, 'min_q_value': -0.9879620671272278, 'mean_td_error': 0.07925318, 'max_td_error': 0.63657653, 'mean_weight': 0.5345151424407959}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1413, -0.0384, -0.5165, -0.4220]], device='cuda:0'), reward is -0.99\n",
      "Episode 432/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 15604, 'eps': 0.0, 'buffer_size': 15604, 'q_loss': 1.5598556995391846, 'mean_q_value': -0.11075698584318161, 'max_q_value': 0.29327094554901123, 'min_q_value': -0.8611890077590942, 'mean_td_error': 0.099825725, 'max_td_error': 0.42983708, 'mean_weight': 0.4579716622829437}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2436, -0.1411, -0.7380, -0.8098]], device='cuda:0'), reward is -0.99\n",
      "Episode 433/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 15636, 'eps': 0.0, 'buffer_size': 15636, 'q_loss': 1.7705178260803223, 'mean_q_value': -0.07990171015262604, 'max_q_value': 0.3526332974433899, 'min_q_value': -0.9738925695419312, 'mean_td_error': 0.05251029, 'max_td_error': 0.42449784, 'mean_weight': 0.5110265612602234}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7851, -0.7773, -0.7762, -0.7877]], device='cuda:0'), reward is -0.99\n",
      "Episode 434/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 15668, 'eps': 0.0, 'buffer_size': 15668, 'q_loss': 1.6590354442596436, 'mean_q_value': -0.0317891426384449, 'max_q_value': 0.32571518421173096, 'min_q_value': -0.8581627011299133, 'mean_td_error': 0.056853347, 'max_td_error': 0.31913567, 'mean_weight': 0.4782884120941162}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3211, -0.2950, -0.2266, -0.2733]], device='cuda:0'), reward is -0.99\n",
      "Episode 435/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 15722, 'eps': 0.0, 'buffer_size': 15722, 'q_loss': 1.5883628129959106, 'mean_q_value': -0.10545123368501663, 'max_q_value': 0.29501017928123474, 'min_q_value': -0.9435753226280212, 'mean_td_error': 0.08183862, 'max_td_error': 0.37110132, 'mean_weight': 0.47385460138320923}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9631, -0.9643, -0.9586, -0.9681]], device='cuda:0'), reward is -0.99\n",
      "Episode 436/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 15750, 'eps': 0.0, 'buffer_size': 15750, 'q_loss': 1.4174190759658813, 'mean_q_value': -0.10711956769227982, 'max_q_value': 0.38498497009277344, 'min_q_value': -0.9414201378822327, 'mean_td_error': 0.052513205, 'max_td_error': 0.31118223, 'mean_weight': 0.42950958013534546}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7437, -0.8141, -0.7238, -0.9179]], device='cuda:0'), reward is -0.99\n",
      "Episode 437/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 15791, 'eps': 0.0, 'buffer_size': 15791, 'q_loss': 1.5499980449676514, 'mean_q_value': -0.07835198938846588, 'max_q_value': 0.27757880091667175, 'min_q_value': -0.9207470417022705, 'mean_td_error': 0.09133572, 'max_td_error': 0.5251491, 'mean_weight': 0.44910988211631775}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0524, -0.0198,  0.0016, -0.1346]], device='cuda:0'), reward is -0.99\n",
      "Episode 438/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 15809, 'eps': 0.0, 'buffer_size': 15809, 'q_loss': 2.1736488342285156, 'mean_q_value': -0.04037456959486008, 'max_q_value': 0.3562062382698059, 'min_q_value': -0.9449220895767212, 'mean_td_error': 0.09670886, 'max_td_error': 0.6547257, 'mean_weight': 0.6584385633468628}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9689, -0.9711, -0.9670, -0.9770]], device='cuda:0'), reward is -0.99\n",
      "Episode 439/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 15841, 'eps': 0.0, 'buffer_size': 15841, 'q_loss': 1.1760833263397217, 'mean_q_value': -0.1256616860628128, 'max_q_value': 0.30258405208587646, 'min_q_value': -0.9469072818756104, 'mean_td_error': 0.0626573, 'max_td_error': 0.32987916, 'mean_weight': 0.3638226389884949}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2017, -0.0976, -0.2021, -0.3817]], device='cuda:0'), reward is -0.99\n",
      "Episode 440/1000000: {'total_return': -0.83, 'steps': 17, 'total_steps': 15858, 'eps': 0.0, 'buffer_size': 15858, 'q_loss': 1.2820712327957153, 'mean_q_value': -0.06026262417435646, 'max_q_value': 0.2981971502304077, 'min_q_value': -0.9968991875648499, 'mean_td_error': 0.09465182, 'max_td_error': 0.8241735, 'mean_weight': 0.38494813442230225}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1949, -0.1483, -0.1980, -0.2450]], device='cuda:0'), reward is -0.99\n",
      "Episode 441/1000000: {'total_return': -0.15999999999999948, 'steps': 84, 'total_steps': 15942, 'eps': 0.0, 'buffer_size': 15942, 'q_loss': 1.4329159259796143, 'mean_q_value': -0.04923146218061447, 'max_q_value': 0.34444254636764526, 'min_q_value': -0.9223992824554443, 'mean_td_error': 0.061424036, 'max_td_error': 0.3349702, 'mean_weight': 0.4323827922344208}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2662, -0.3305, -0.2759, -0.3101]], device='cuda:0'), reward is -0.99\n",
      "Episode 442/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 15981, 'eps': 0.0, 'buffer_size': 15981, 'q_loss': 1.6600735187530518, 'mean_q_value': -0.08329588174819946, 'max_q_value': 0.281710147857666, 'min_q_value': -0.8240709900856018, 'mean_td_error': 0.071242064, 'max_td_error': 0.4478467, 'mean_weight': 0.48696014285087585}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1104, -0.0559, -0.1057, -0.2328]], device='cuda:0'), reward is -0.99\n",
      "Episode 443/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 16009, 'eps': 0.0, 'buffer_size': 16009, 'q_loss': 1.7326469421386719, 'mean_q_value': -0.13929235935211182, 'max_q_value': 0.30508777499198914, 'min_q_value': -0.9512084126472473, 'mean_td_error': 0.09175704, 'max_td_error': 0.4672292, 'mean_weight': 0.5327606201171875}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9101, -0.8516, -0.8795, -0.9222]], device='cuda:0'), reward is -0.99\n",
      "Episode 444/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 16077, 'eps': 0.0, 'buffer_size': 16077, 'q_loss': 1.3233534097671509, 'mean_q_value': -0.1363643854856491, 'max_q_value': 0.26419365406036377, 'min_q_value': -0.9194463491439819, 'mean_td_error': 0.118558355, 'max_td_error': 1.0219405, 'mean_weight': 0.40650638937950134}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3250, -0.2723, -0.1021, -0.2938]], device='cuda:0'), reward is -0.99\n",
      "Episode 445/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 16112, 'eps': 0.0, 'buffer_size': 16112, 'q_loss': 1.4388480186462402, 'mean_q_value': -0.13731679320335388, 'max_q_value': 0.23223571479320526, 'min_q_value': -0.8717416524887085, 'mean_td_error': 0.083455116, 'max_td_error': 0.298414, 'mean_weight': 0.4217114746570587}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3429, -0.3166, -0.3955, -0.4467]], device='cuda:0'), reward is -0.99\n",
      "Episode 446/1000000: {'total_return': -0.10999999999999943, 'steps': 89, 'total_steps': 16201, 'eps': 0.0, 'buffer_size': 16201, 'q_loss': 1.575836420059204, 'mean_q_value': -0.12516707181930542, 'max_q_value': 0.2935221195220947, 'min_q_value': -0.7899348139762878, 'mean_td_error': 0.081020355, 'max_td_error': 0.590195, 'mean_weight': 0.47310683131217957}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3561, -0.3310, -0.2331, -0.3473]], device='cuda:0'), reward is -0.99\n",
      "Episode 447/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 16233, 'eps': 0.0, 'buffer_size': 16233, 'q_loss': 1.7394602298736572, 'mean_q_value': -0.13009044528007507, 'max_q_value': 0.3151138722896576, 'min_q_value': -0.9455261826515198, 'mean_td_error': 0.065236315, 'max_td_error': 0.58807063, 'mean_weight': 0.5344172120094299}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0469, 0.0391, 0.0526, 0.0451]], device='cuda:0'), reward is -0.99\n",
      "Episode 448/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 16249, 'eps': 0.0, 'buffer_size': 16249, 'q_loss': 1.7599213123321533, 'mean_q_value': -0.03506613150238991, 'max_q_value': 0.3363352417945862, 'min_q_value': -0.9561350345611572, 'mean_td_error': 0.09805645, 'max_td_error': 0.93766505, 'mean_weight': 0.5341364145278931}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2242, -0.2018, -0.2132, -0.2204]], device='cuda:0'), reward is -0.99\n",
      "Episode 449/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 16307, 'eps': 0.0, 'buffer_size': 16307, 'q_loss': 2.1415138244628906, 'mean_q_value': -0.10888826102018356, 'max_q_value': 0.2670307755470276, 'min_q_value': -0.975929319858551, 'mean_td_error': 0.04845661, 'max_td_error': 0.20678362, 'mean_weight': 0.6691423058509827}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5738, -0.6165, -0.5434, -0.6330]], device='cuda:0'), reward is -0.99\n",
      "Episode 450/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 16339, 'eps': 0.0, 'buffer_size': 16339, 'q_loss': 1.1380321979522705, 'mean_q_value': -0.08247828483581543, 'max_q_value': 0.35017770528793335, 'min_q_value': -0.915489673614502, 'mean_td_error': 0.07863691, 'max_td_error': 0.538852, 'mean_weight': 0.3466570973396301}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5035, -0.4772, -0.3424, -0.3031]], device='cuda:0'), reward is -0.99\n",
      "Episode 451/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 16376, 'eps': 0.0, 'buffer_size': 16376, 'q_loss': 1.434842824935913, 'mean_q_value': -0.06022591143846512, 'max_q_value': 0.30203187465667725, 'min_q_value': -0.9919593334197998, 'mean_td_error': 0.061817057, 'max_td_error': 0.38552374, 'mean_weight': 0.42668235301971436}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6091, -0.5367, -0.5528, -0.6533]], device='cuda:0'), reward is -0.99\n",
      "Episode 452/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 16423, 'eps': 0.0, 'buffer_size': 16423, 'q_loss': 1.9160161018371582, 'mean_q_value': -0.08202213048934937, 'max_q_value': 0.29031339287757874, 'min_q_value': -0.9289147853851318, 'mean_td_error': 0.061799765, 'max_td_error': 0.28612489, 'mean_weight': 0.5828310251235962}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5425, -0.7436, -0.6028, -0.7102]], device='cuda:0'), reward is -0.99\n",
      "Episode 453/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 16501, 'eps': 0.0, 'buffer_size': 16501, 'q_loss': 1.784936785697937, 'mean_q_value': -0.050489187240600586, 'max_q_value': 0.2918873429298401, 'min_q_value': -0.8993821144104004, 'mean_td_error': 0.05224509, 'max_td_error': 0.21169451, 'mean_weight': 0.5285941362380981}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7237, -0.6674, -0.8578, -0.8697]], device='cuda:0'), reward is -0.99\n",
      "Episode 454/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 16532, 'eps': 0.0, 'buffer_size': 16532, 'q_loss': 1.5973230600357056, 'mean_q_value': -0.1241283193230629, 'max_q_value': 0.29119592905044556, 'min_q_value': -0.9025194644927979, 'mean_td_error': 0.11601142, 'max_td_error': 1.1350267, 'mean_weight': 0.47250866889953613}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0489, 0.1233, 0.1592, 0.1151]], device='cuda:0'), reward is -0.99\n",
      "Episode 455/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 16565, 'eps': 0.0, 'buffer_size': 16565, 'q_loss': 1.6394963264465332, 'mean_q_value': -0.07373607903718948, 'max_q_value': 0.2631167769432068, 'min_q_value': -0.9230179786682129, 'mean_td_error': 0.067013994, 'max_td_error': 0.26236957, 'mean_weight': 0.4907412528991699}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1137, 0.1268, 0.0774, 0.0082]], device='cuda:0'), reward is -0.99\n",
      "Episode 456/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 16623, 'eps': 0.0, 'buffer_size': 16623, 'q_loss': 1.1714329719543457, 'mean_q_value': -0.08549468219280243, 'max_q_value': 0.36761289834976196, 'min_q_value': -1.0074095726013184, 'mean_td_error': 0.05560872, 'max_td_error': 0.2557981, 'mean_weight': 0.3689708113670349}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9136, -0.8868, -0.9351, -0.9567]], device='cuda:0'), reward is -0.99\n",
      "Episode 457/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 16665, 'eps': 0.0, 'buffer_size': 16665, 'q_loss': 1.5717241764068604, 'mean_q_value': -0.13756607472896576, 'max_q_value': 0.27775388956069946, 'min_q_value': -0.9517541527748108, 'mean_td_error': 0.069436885, 'max_td_error': 0.349185, 'mean_weight': 0.4879336357116699}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2433, -0.2415, -0.2270, -0.2793]], device='cuda:0'), reward is -0.99\n",
      "Episode 458/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 16686, 'eps': 0.0, 'buffer_size': 16686, 'q_loss': 1.5456563234329224, 'mean_q_value': -0.0680554062128067, 'max_q_value': 0.31655353307724, 'min_q_value': -0.9585971832275391, 'mean_td_error': 0.049938146, 'max_td_error': 0.120180815, 'mean_weight': 0.4702022969722748}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6184, -0.3622, -0.4176, -0.4737]], device='cuda:0'), reward is -0.99\n",
      "Episode 459/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 16714, 'eps': 0.0, 'buffer_size': 16714, 'q_loss': 1.081364393234253, 'mean_q_value': -0.03990266099572182, 'max_q_value': 0.29992926120758057, 'min_q_value': -0.8661122918128967, 'mean_td_error': 0.03323806, 'max_td_error': 0.123887, 'mean_weight': 0.33898046612739563}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0552, -0.0727, -0.0473, -0.1221]], device='cuda:0'), reward is -0.99\n",
      "Episode 460/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 16744, 'eps': 0.0, 'buffer_size': 16744, 'q_loss': 1.3809664249420166, 'mean_q_value': -0.13841205835342407, 'max_q_value': 0.3578817844390869, 'min_q_value': -0.9200297594070435, 'mean_td_error': 0.105218306, 'max_td_error': 0.83348703, 'mean_weight': 0.43093323707580566}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0777,  0.0533,  0.0061, -0.0884]], device='cuda:0'), reward is -0.99\n",
      "Episode 461/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 16777, 'eps': 0.0, 'buffer_size': 16777, 'q_loss': 1.9738667011260986, 'mean_q_value': -0.10120145231485367, 'max_q_value': 0.31347525119781494, 'min_q_value': -0.9079698920249939, 'mean_td_error': 0.07482779, 'max_td_error': 0.27457368, 'mean_weight': 0.5906189680099487}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0876, -0.0866, -0.0788, -0.0832]], device='cuda:0'), reward is -0.99\n",
      "Episode 462/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 16820, 'eps': 0.0, 'buffer_size': 16820, 'q_loss': 1.8283541202545166, 'mean_q_value': -0.17141605913639069, 'max_q_value': 0.3274272382259369, 'min_q_value': -0.8393073678016663, 'mean_td_error': 0.11454281, 'max_td_error': 0.47638935, 'mean_weight': 0.5748662948608398}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5469, -0.5129, -0.4868, -0.5106]], device='cuda:0'), reward is -0.99\n",
      "Episode 463/1000000: {'total_return': -0.1799999999999995, 'steps': 82, 'total_steps': 16902, 'eps': 0.0, 'buffer_size': 16902, 'q_loss': 1.068408489227295, 'mean_q_value': -0.018552608788013458, 'max_q_value': 0.3783057928085327, 'min_q_value': -0.9044517278671265, 'mean_td_error': 0.05543296, 'max_td_error': 0.26368928, 'mean_weight': 0.2998847961425781}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4828, -0.4738, -0.4325, -0.4919]], device='cuda:0'), reward is -0.99\n",
      "Episode 464/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 16970, 'eps': 0.0, 'buffer_size': 16970, 'q_loss': 1.6337957382202148, 'mean_q_value': -0.1606798768043518, 'max_q_value': 0.36424389481544495, 'min_q_value': -0.903387188911438, 'mean_td_error': 0.067955285, 'max_td_error': 0.44793844, 'mean_weight': 0.5090007185935974}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6010, -0.7239, -0.6586, -0.6619]], device='cuda:0'), reward is -0.99\n",
      "Episode 465/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 17009, 'eps': 0.0, 'buffer_size': 17009, 'q_loss': 1.7946174144744873, 'mean_q_value': -0.16994211077690125, 'max_q_value': 0.2828928232192993, 'min_q_value': -0.9656789302825928, 'mean_td_error': 0.051989395, 'max_td_error': 0.29845253, 'mean_weight': 0.5508207082748413}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9222, -0.9252, -0.9503, -0.9801]], device='cuda:0'), reward is -0.99\n",
      "Episode 466/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 17082, 'eps': 0.0, 'buffer_size': 17082, 'q_loss': 1.4802759885787964, 'mean_q_value': -0.16811522841453552, 'max_q_value': 0.28722506761550903, 'min_q_value': -0.9440608024597168, 'mean_td_error': 0.09071781, 'max_td_error': 0.4611832, 'mean_weight': 0.44864505529403687}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8112, -0.8156, -0.8139, -0.8105]], device='cuda:0'), reward is -0.99\n",
      "Episode 467/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 17122, 'eps': 0.0, 'buffer_size': 17122, 'q_loss': 2.0520622730255127, 'mean_q_value': -0.1264006644487381, 'max_q_value': 0.28576362133026123, 'min_q_value': -0.9700639247894287, 'mean_td_error': 0.062489465, 'max_td_error': 0.29714978, 'mean_weight': 0.6279395818710327}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0853, 0.1033, 0.1370, 0.1129]], device='cuda:0'), reward is -0.99\n",
      "Episode 468/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 17148, 'eps': 0.0, 'buffer_size': 17148, 'q_loss': 1.6953761577606201, 'mean_q_value': -0.11560370028018951, 'max_q_value': 0.37136274576187134, 'min_q_value': -0.8689360618591309, 'mean_td_error': 0.0682092, 'max_td_error': 0.7932339, 'mean_weight': 0.524925947189331}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9676, -0.9524, -0.9654, -0.9793]], device='cuda:0'), reward is -0.99\n",
      "Episode 469/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 17217, 'eps': 0.0, 'buffer_size': 17217, 'q_loss': 1.787306547164917, 'mean_q_value': -0.0861348807811737, 'max_q_value': 0.35087186098098755, 'min_q_value': -0.9504208564758301, 'mean_td_error': 0.0531189, 'max_td_error': 0.2259484, 'mean_weight': 0.5436207056045532}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5047, -0.4116, -0.4457, -0.5103]], device='cuda:0'), reward is -0.99\n",
      "Episode 470/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 17251, 'eps': 0.0, 'buffer_size': 17251, 'q_loss': 2.0294198989868164, 'mean_q_value': -0.08641739934682846, 'max_q_value': 0.2904863953590393, 'min_q_value': -0.7988579869270325, 'mean_td_error': 0.07819377, 'max_td_error': 0.43774438, 'mean_weight': 0.5799422264099121}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7696, -0.6980, -0.6486, -0.7373]], device='cuda:0'), reward is -0.99\n",
      "Episode 471/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 17316, 'eps': 0.0, 'buffer_size': 17316, 'q_loss': 1.657423973083496, 'mean_q_value': -0.09028643369674683, 'max_q_value': 0.3387150764465332, 'min_q_value': -0.8598004579544067, 'mean_td_error': 0.055311374, 'max_td_error': 0.20552176, 'mean_weight': 0.4766910672187805}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9768, -0.9679, -0.9702, -0.9954]], device='cuda:0'), reward is -0.99\n",
      "Episode 472/1000000: {'total_return': -0.1799999999999995, 'steps': 82, 'total_steps': 17398, 'eps': 0.0, 'buffer_size': 17398, 'q_loss': 1.7920523881912231, 'mean_q_value': -0.00364820659160614, 'max_q_value': 0.3630189001560211, 'min_q_value': -0.6953315734863281, 'mean_td_error': 0.066216804, 'max_td_error': 0.33197364, 'mean_weight': 0.5067126750946045}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7774, -0.8726, -0.7576, -0.7972]], device='cuda:0'), reward is -0.99\n",
      "Episode 473/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 17435, 'eps': 0.0, 'buffer_size': 17435, 'q_loss': 1.668337106704712, 'mean_q_value': -0.02939940057694912, 'max_q_value': 0.3659384846687317, 'min_q_value': -0.9397901296615601, 'mean_td_error': 0.07508576, 'max_td_error': 0.24560067, 'mean_weight': 0.4842834770679474}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9650, -0.9779, -0.9649, -0.9835]], device='cuda:0'), reward is -0.99\n",
      "Episode 474/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 17477, 'eps': 0.0, 'buffer_size': 17477, 'q_loss': 1.3801149129867554, 'mean_q_value': -0.09656387567520142, 'max_q_value': 0.31712695956230164, 'min_q_value': -0.9798433780670166, 'mean_td_error': 0.04551325, 'max_td_error': 0.30124187, 'mean_weight': 0.44408226013183594}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7759, -0.7020, -0.6817, -0.8243]], device='cuda:0'), reward is -0.99\n",
      "Episode 475/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 17525, 'eps': 0.0, 'buffer_size': 17525, 'q_loss': 1.5661520957946777, 'mean_q_value': -0.034280527383089066, 'max_q_value': 0.3373175263404846, 'min_q_value': -0.9250022172927856, 'mean_td_error': 0.036422, 'max_td_error': 0.1532036, 'mean_weight': 0.4703060984611511}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9751, -0.9655, -0.9582, -0.9641]], device='cuda:0'), reward is -0.99\n",
      "Episode 476/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 17571, 'eps': 0.0, 'buffer_size': 17571, 'q_loss': 1.9284465312957764, 'mean_q_value': -0.07750339061021805, 'max_q_value': 0.2753767967224121, 'min_q_value': -0.8024176359176636, 'mean_td_error': 0.06939496, 'max_td_error': 0.1965001, 'mean_weight': 0.5550296306610107}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3943, -0.4071, -0.4538, -0.5511]], device='cuda:0'), reward is -0.99\n",
      "Episode 477/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 17597, 'eps': 0.0, 'buffer_size': 17597, 'q_loss': 1.7829071283340454, 'mean_q_value': -0.23739272356033325, 'max_q_value': 0.2839784026145935, 'min_q_value': -0.974631667137146, 'mean_td_error': 0.06088362, 'max_td_error': 0.20401978, 'mean_weight': 0.5973088145256042}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3400, -0.3515, -0.3731, -0.3026]], device='cuda:0'), reward is -0.99\n",
      "Episode 478/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 17643, 'eps': 0.0, 'buffer_size': 17643, 'q_loss': 1.7232635021209717, 'mean_q_value': -0.11385802924633026, 'max_q_value': 0.3058481216430664, 'min_q_value': -0.9296844601631165, 'mean_td_error': 0.071763456, 'max_td_error': 0.78036475, 'mean_weight': 0.5247886180877686}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0585, 0.0559, 0.0528, 0.0828]], device='cuda:0'), reward is -0.99\n",
      "Episode 479/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 17715, 'eps': 0.0, 'buffer_size': 17715, 'q_loss': 1.467799186706543, 'mean_q_value': -0.07072396576404572, 'max_q_value': 0.30528581142425537, 'min_q_value': -0.7973106503486633, 'mean_td_error': 0.0612868, 'max_td_error': 0.26144105, 'mean_weight': 0.42897191643714905}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7161, -0.5972, -0.6515, -0.7002]], device='cuda:0'), reward is -0.99\n",
      "Episode 480/1000000: {'total_return': 0.12000000000000077, 'steps': 112, 'total_steps': 17827, 'eps': 0.0, 'buffer_size': 17827, 'q_loss': 1.2841391563415527, 'mean_q_value': -0.19356124103069305, 'max_q_value': 0.31514376401901245, 'min_q_value': -0.9555963277816772, 'mean_td_error': 0.04477696, 'max_td_error': 0.21049684, 'mean_weight': 0.4070165157318115}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1940, 0.1907, 0.1960, 0.1954]], device='cuda:0'), reward is -0.99\n",
      "Episode 481/1000000: {'total_return': -0.91, 'steps': 9, 'total_steps': 17836, 'eps': 0.0, 'buffer_size': 17836, 'q_loss': 1.6720986366271973, 'mean_q_value': -0.14302152395248413, 'max_q_value': 0.30430227518081665, 'min_q_value': -0.8280101418495178, 'mean_td_error': 0.07800766, 'max_td_error': 0.4367336, 'mean_weight': 0.5238928198814392}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8799, -0.9226, -0.8854, -0.8011]], device='cuda:0'), reward is -0.99\n",
      "Episode 482/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 17872, 'eps': 0.0, 'buffer_size': 17872, 'q_loss': 2.1255452632904053, 'mean_q_value': -0.09375988692045212, 'max_q_value': 0.3151271939277649, 'min_q_value': -0.858311653137207, 'mean_td_error': 0.07446359, 'max_td_error': 0.38602734, 'mean_weight': 0.6336499452590942}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7743, -0.8262, -0.7616, -0.7408]], device='cuda:0'), reward is -0.99\n",
      "Episode 483/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 17924, 'eps': 0.0, 'buffer_size': 17924, 'q_loss': 1.4035680294036865, 'mean_q_value': -0.14952823519706726, 'max_q_value': 0.3430216312408447, 'min_q_value': -0.9453188180923462, 'mean_td_error': 0.11335078, 'max_td_error': 1.0163983, 'mean_weight': 0.4578057825565338}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8109, -0.8409, -0.8267, -0.8316]], device='cuda:0'), reward is -0.99\n",
      "Episode 484/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 17988, 'eps': 0.0, 'buffer_size': 17988, 'q_loss': 1.2774955034255981, 'mean_q_value': -0.20907029509544373, 'max_q_value': 0.28506702184677124, 'min_q_value': -0.9567133188247681, 'mean_td_error': 0.08465605, 'max_td_error': 0.9017284, 'mean_weight': 0.4228571653366089}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8055, -0.7424, -0.7717, -0.8128]], device='cuda:0'), reward is -0.99\n",
      "Episode 485/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 18022, 'eps': 0.0, 'buffer_size': 18022, 'q_loss': 1.3705050945281982, 'mean_q_value': -0.1881183385848999, 'max_q_value': 0.37564390897750854, 'min_q_value': -0.9661927819252014, 'mean_td_error': 0.07013844, 'max_td_error': 0.461941, 'mean_weight': 0.4237331449985504}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9890, -0.9841, -0.9873, -1.0031]], device='cuda:0'), reward is -0.99\n",
      "Episode 486/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 18047, 'eps': 0.0, 'buffer_size': 18047, 'q_loss': 1.781278371810913, 'mean_q_value': -0.18333843350410461, 'max_q_value': 0.31127485632896423, 'min_q_value': -0.9559550881385803, 'mean_td_error': 0.04680415, 'max_td_error': 0.2897287, 'mean_weight': 0.559168815612793}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0792, -0.0720, -0.0542, -0.0839]], device='cuda:0'), reward is -0.99\n",
      "Episode 487/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 18082, 'eps': 0.0, 'buffer_size': 18082, 'q_loss': 1.2696428298950195, 'mean_q_value': -0.09661979973316193, 'max_q_value': 0.2851604223251343, 'min_q_value': -0.9768128395080566, 'mean_td_error': 0.06454463, 'max_td_error': 0.3312297, 'mean_weight': 0.3770674467086792}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3452, -0.3398, -0.3143, -0.3233]], device='cuda:0'), reward is -0.99\n",
      "Episode 488/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 18154, 'eps': 0.0, 'buffer_size': 18154, 'q_loss': 1.489086627960205, 'mean_q_value': -0.10712838172912598, 'max_q_value': 0.2782022953033447, 'min_q_value': -0.9402698874473572, 'mean_td_error': 0.05191677, 'max_td_error': 0.20565706, 'mean_weight': 0.4491446018218994}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9090, -0.9067, -0.9080, -0.9108]], device='cuda:0'), reward is -0.99\n",
      "Episode 489/1000000: {'total_return': -0.14999999999999947, 'steps': 85, 'total_steps': 18239, 'eps': 0.0, 'buffer_size': 18239, 'q_loss': 1.9690628051757812, 'mean_q_value': -0.0918017253279686, 'max_q_value': 0.3340591788291931, 'min_q_value': -0.9547149538993835, 'mean_td_error': 0.058553874, 'max_td_error': 0.194756, 'mean_weight': 0.5931462645530701}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9253, -0.9193, -0.9203, -0.9303]], device='cuda:0'), reward is -0.99\n",
      "Episode 490/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 18289, 'eps': 0.0, 'buffer_size': 18289, 'q_loss': 1.1123805046081543, 'mean_q_value': -0.21537235379219055, 'max_q_value': 0.26455795764923096, 'min_q_value': -0.9444583654403687, 'mean_td_error': 0.047645725, 'max_td_error': 0.18709466, 'mean_weight': 0.35810279846191406}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6760, -0.6253, -0.5919, -0.6420]], device='cuda:0'), reward is -0.99\n",
      "Episode 491/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 18362, 'eps': 0.0, 'buffer_size': 18362, 'q_loss': 1.3369431495666504, 'mean_q_value': -0.16274625062942505, 'max_q_value': 0.2789049446582794, 'min_q_value': -0.9702045321464539, 'mean_td_error': 0.04367319, 'max_td_error': 0.24641433, 'mean_weight': 0.4108850955963135}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7703, -0.7919, -0.7916, -0.8151]], device='cuda:0'), reward is -0.99\n",
      "Episode 492/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 18407, 'eps': 0.0, 'buffer_size': 18407, 'q_loss': 1.682755947113037, 'mean_q_value': -0.14776811003684998, 'max_q_value': 0.2701182961463928, 'min_q_value': -0.9525611400604248, 'mean_td_error': 0.056414776, 'max_td_error': 0.25601584, 'mean_weight': 0.5235679149627686}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9397, -0.9399, -0.9516, -0.9700]], device='cuda:0'), reward is -0.99\n",
      "Episode 493/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 18461, 'eps': 0.0, 'buffer_size': 18461, 'q_loss': 1.616302728652954, 'mean_q_value': -0.2107769250869751, 'max_q_value': 0.3132697343826294, 'min_q_value': -0.9560402035713196, 'mean_td_error': 0.06279498, 'max_td_error': 0.33794284, 'mean_weight': 0.5360370874404907}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7619, -0.7569, -0.7720, -0.7953]], device='cuda:0'), reward is -0.99\n",
      "Episode 494/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 18530, 'eps': 0.0, 'buffer_size': 18530, 'q_loss': 1.2148504257202148, 'mean_q_value': -0.08261901140213013, 'max_q_value': 0.35856276750564575, 'min_q_value': -0.8775706887245178, 'mean_td_error': 0.047858205, 'max_td_error': 0.1678983, 'mean_weight': 0.35285428166389465}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2304, 0.2325, 0.2416, 0.2443]], device='cuda:0'), reward is -0.99\n",
      "Episode 495/1000000: {'total_return': -0.9299999999999999, 'steps': 7, 'total_steps': 18537, 'eps': 0.0, 'buffer_size': 18537, 'q_loss': 1.4477176666259766, 'mean_q_value': -0.10000339150428772, 'max_q_value': 0.33130526542663574, 'min_q_value': -0.9843724370002747, 'mean_td_error': 0.05838792, 'max_td_error': 0.23852497, 'mean_weight': 0.4362146258354187}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3600, -0.0996, -0.0939, -0.2665]], device='cuda:0'), reward is -0.99\n",
      "Episode 496/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 18591, 'eps': 0.0, 'buffer_size': 18591, 'q_loss': 2.612412452697754, 'mean_q_value': -0.06370089203119278, 'max_q_value': 0.38294509053230286, 'min_q_value': -0.9216724038124084, 'mean_td_error': 0.06650718, 'max_td_error': 0.28581443, 'mean_weight': 0.7622203230857849}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2938, 0.3023, 0.3066, 0.3055]], device='cuda:0'), reward is -0.99\n",
      "Episode 497/1000000: {'total_return': -0.94, 'steps': 6, 'total_steps': 18597, 'eps': 0.0, 'buffer_size': 18597, 'q_loss': 1.3534526824951172, 'mean_q_value': -0.04052475094795227, 'max_q_value': 0.3140341639518738, 'min_q_value': -0.8560469150543213, 'mean_td_error': 0.051127367, 'max_td_error': 0.2666317, 'mean_weight': 0.38718146085739136}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7535, -0.8484, -0.7151, -0.7817]], device='cuda:0'), reward is -0.99\n",
      "Episode 498/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 18649, 'eps': 0.0, 'buffer_size': 18649, 'q_loss': 1.6673524379730225, 'mean_q_value': -0.17791472375392914, 'max_q_value': 0.2656826376914978, 'min_q_value': -0.9366127252578735, 'mean_td_error': 0.04769152, 'max_td_error': 0.26204067, 'mean_weight': 0.5226651430130005}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8165, -0.7683, -0.7706, -0.7150]], device='cuda:0'), reward is -0.99\n",
      "Episode 499/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 18682, 'eps': 0.0, 'buffer_size': 18682, 'q_loss': 1.4530367851257324, 'mean_q_value': -0.13155359029769897, 'max_q_value': 0.2918176054954529, 'min_q_value': -0.9860672950744629, 'mean_td_error': 0.06549652, 'max_td_error': 0.40325436, 'mean_weight': 0.4437277913093567}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7903, -0.6278, -0.5978, -0.6411]], device='cuda:0'), reward is -0.99\n",
      "Episode 500/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 18757, 'eps': 0.0, 'buffer_size': 18757, 'q_loss': 1.3859273195266724, 'mean_q_value': -0.15356945991516113, 'max_q_value': 0.3070210814476013, 'min_q_value': -0.9476881623268127, 'mean_td_error': 0.053268146, 'max_td_error': 0.1475065, 'mean_weight': 0.42416149377822876}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0813,  0.0652,  0.0912, -0.0053]], device='cuda:0'), reward is -0.99\n",
      "Episode 501/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 18791, 'eps': 0.0, 'buffer_size': 18791, 'q_loss': 2.194953680038452, 'mean_q_value': -0.11334862560033798, 'max_q_value': 0.29113417863845825, 'min_q_value': -0.9558448195457458, 'mean_td_error': 0.044440277, 'max_td_error': 0.1460844, 'mean_weight': 0.6875470876693726}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8593, -0.8482, -0.8476, -0.8598]], device='cuda:0'), reward is -0.99\n",
      "Episode 502/1000000: {'total_return': -0.16999999999999948, 'steps': 83, 'total_steps': 18874, 'eps': 0.0, 'buffer_size': 18874, 'q_loss': 1.8225891590118408, 'mean_q_value': -0.005214540287852287, 'max_q_value': 0.3241587281227112, 'min_q_value': -0.9801610112190247, 'mean_td_error': 0.08420658, 'max_td_error': 1.256921, 'mean_weight': 0.5357795357704163}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7556, -0.7979, -0.7301, -0.8096]], device='cuda:0'), reward is -0.99\n",
      "Episode 503/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 18926, 'eps': 0.0, 'buffer_size': 18926, 'q_loss': 1.8153231143951416, 'mean_q_value': -0.17167934775352478, 'max_q_value': 0.25702428817749023, 'min_q_value': -0.9385579824447632, 'mean_td_error': 0.07453047, 'max_td_error': 0.41998255, 'mean_weight': 0.5668188333511353}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0210, -0.0302,  0.0253,  0.0285]], device='cuda:0'), reward is -0.99\n",
      "Episode 504/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 18957, 'eps': 0.0, 'buffer_size': 18957, 'q_loss': 1.6063015460968018, 'mean_q_value': -0.15850239992141724, 'max_q_value': 0.34005028009414673, 'min_q_value': -0.8968016505241394, 'mean_td_error': 0.063847795, 'max_td_error': 0.27276325, 'mean_weight': 0.49473485350608826}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9808, -0.9830, -0.9855, -0.9829]], device='cuda:0'), reward is -0.99\n",
      "Episode 505/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 19021, 'eps': 0.0, 'buffer_size': 19021, 'q_loss': 1.4124419689178467, 'mean_q_value': -0.0408477745950222, 'max_q_value': 0.29671943187713623, 'min_q_value': -0.9065904021263123, 'mean_td_error': 0.04777093, 'max_td_error': 0.2051642, 'mean_weight': 0.4050091505050659}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3057, -0.2185, -0.3802, -0.3978]], device='cuda:0'), reward is -0.99\n",
      "Episode 506/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 19046, 'eps': 0.0, 'buffer_size': 19046, 'q_loss': 1.3307245969772339, 'mean_q_value': -0.23924271762371063, 'max_q_value': 0.31233495473861694, 'min_q_value': -0.9496394395828247, 'mean_td_error': 0.06299336, 'max_td_error': 0.21312058, 'mean_weight': 0.43846893310546875}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9579, -0.9497, -0.9557, -0.9570]], device='cuda:0'), reward is -0.99\n",
      "Episode 507/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 19120, 'eps': 0.0, 'buffer_size': 19120, 'q_loss': 1.9233787059783936, 'mean_q_value': -0.15852031111717224, 'max_q_value': 0.335821270942688, 'min_q_value': -0.9603456258773804, 'mean_td_error': 0.1190914, 'max_td_error': 0.9896675, 'mean_weight': 0.6145775318145752}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1736, -0.2116, -0.2440, -0.4782]], device='cuda:0'), reward is -0.99\n",
      "Episode 508/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 19170, 'eps': 0.0, 'buffer_size': 19170, 'q_loss': 1.5492057800292969, 'mean_q_value': -0.2803163528442383, 'max_q_value': 0.31514638662338257, 'min_q_value': -0.962911069393158, 'mean_td_error': 0.0581213, 'max_td_error': 0.6540188, 'mean_weight': 0.5655116438865662}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0015, -0.0338, -0.0220, -0.0513]], device='cuda:0'), reward is -0.99\n",
      "Episode 509/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 19234, 'eps': 0.0, 'buffer_size': 19234, 'q_loss': 1.7862555980682373, 'mean_q_value': -0.17276063561439514, 'max_q_value': 0.33390331268310547, 'min_q_value': -0.983381450176239, 'mean_td_error': 0.08757959, 'max_td_error': 0.32525903, 'mean_weight': 0.5666016340255737}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6995, -0.5614, -0.4577, -0.5283]], device='cuda:0'), reward is -0.99\n",
      "Episode 510/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 19260, 'eps': 0.0, 'buffer_size': 19260, 'q_loss': 1.5621541738510132, 'mean_q_value': -0.0697077140212059, 'max_q_value': 0.32506346702575684, 'min_q_value': -0.9437569975852966, 'mean_td_error': 0.0498084, 'max_td_error': 0.16523784, 'mean_weight': 0.47538524866104126}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3839, -0.2663, -0.2533, -0.4655]], device='cuda:0'), reward is -0.99\n",
      "Episode 511/1000000: {'total_return': -0.03999999999999937, 'steps': 96, 'total_steps': 19356, 'eps': 0.0, 'buffer_size': 19356, 'q_loss': 1.4179579019546509, 'mean_q_value': -0.0945182740688324, 'max_q_value': 0.2960107624530792, 'min_q_value': -0.9452369809150696, 'mean_td_error': 0.061442196, 'max_td_error': 0.4202539, 'mean_weight': 0.4334120452404022}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0072, 0.0238, 0.0268, 0.0096]], device='cuda:0'), reward is -0.99\n",
      "Episode 512/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 19416, 'eps': 0.0, 'buffer_size': 19416, 'q_loss': 1.6900931596755981, 'mean_q_value': -0.054137084633111954, 'max_q_value': 0.30256539583206177, 'min_q_value': -0.8823309540748596, 'mean_td_error': 0.055527523, 'max_td_error': 0.17326123, 'mean_weight': 0.5034403204917908}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1403, -0.1479, -0.1244, -0.2090]], device='cuda:0'), reward is -0.99\n",
      "Episode 513/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 19466, 'eps': 0.0, 'buffer_size': 19466, 'q_loss': 1.2828046083450317, 'mean_q_value': -0.14823688566684723, 'max_q_value': 0.2896815538406372, 'min_q_value': -0.9678094387054443, 'mean_td_error': 0.058525622, 'max_td_error': 0.41136068, 'mean_weight': 0.3980904519557953}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9129, -0.9460, -0.9134, -0.9049]], device='cuda:0'), reward is -0.99\n",
      "Episode 514/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 19529, 'eps': 0.0, 'buffer_size': 19529, 'q_loss': 1.1632747650146484, 'mean_q_value': -0.20432235300540924, 'max_q_value': 0.2858988046646118, 'min_q_value': -0.9869378805160522, 'mean_td_error': 0.070228495, 'max_td_error': 0.23006621, 'mean_weight': 0.370037317276001}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4189, -0.4309, -0.4057, -0.4167]], device='cuda:0'), reward is -0.99\n",
      "Episode 515/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 19587, 'eps': 0.0, 'buffer_size': 19587, 'q_loss': 1.6570627689361572, 'mean_q_value': -0.06773382425308228, 'max_q_value': 0.2986069321632385, 'min_q_value': -0.927890956401825, 'mean_td_error': 0.060380913, 'max_td_error': 0.20360458, 'mean_weight': 0.48759403824806213}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5143, -0.4683, -0.4321, -0.4640]], device='cuda:0'), reward is -0.99\n",
      "Episode 516/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 19619, 'eps': 0.0, 'buffer_size': 19619, 'q_loss': 1.4719533920288086, 'mean_q_value': -0.12002935260534286, 'max_q_value': 0.31716620922088623, 'min_q_value': -0.9328436255455017, 'mean_td_error': 0.062118072, 'max_td_error': 0.16088402, 'mean_weight': 0.4612656831741333}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5824, -0.5848, -0.5833, -0.5901]], device='cuda:0'), reward is -0.99\n",
      "Episode 517/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 19685, 'eps': 0.0, 'buffer_size': 19685, 'q_loss': 1.7502752542495728, 'mean_q_value': -0.18925517797470093, 'max_q_value': 0.32876285910606384, 'min_q_value': -0.9262657165527344, 'mean_td_error': 0.07376158, 'max_td_error': 0.24919358, 'mean_weight': 0.5441420078277588}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4710, -0.4928, -0.7276, -0.8948]], device='cuda:0'), reward is -0.99\n",
      "Episode 518/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 19741, 'eps': 0.0, 'buffer_size': 19741, 'q_loss': 1.638509750366211, 'mean_q_value': -0.11260928958654404, 'max_q_value': 0.2480485439300537, 'min_q_value': -0.9354218244552612, 'mean_td_error': 0.06760895, 'max_td_error': 0.5014271, 'mean_weight': 0.48650333285331726}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0212, -0.0271, -0.0556, -0.0680]], device='cuda:0'), reward is -0.99\n",
      "Episode 519/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 19806, 'eps': 0.0, 'buffer_size': 19806, 'q_loss': 1.5816569328308105, 'mean_q_value': -0.08230777084827423, 'max_q_value': 0.3382263779640198, 'min_q_value': -0.9450460076332092, 'mean_td_error': 0.05277995, 'max_td_error': 0.20244783, 'mean_weight': 0.49179619550704956}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9377, -0.9664, -0.9437, -0.9622]], device='cuda:0'), reward is -0.99\n",
      "Episode 520/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 19845, 'eps': 0.0, 'buffer_size': 19845, 'q_loss': 1.1746306419372559, 'mean_q_value': -0.22384849190711975, 'max_q_value': 0.30635201930999756, 'min_q_value': -0.9597486853599548, 'mean_td_error': 0.0833153, 'max_td_error': 1.1522341, 'mean_weight': 0.37921616435050964}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6512, -0.6410, -0.6172, -0.6367]], device='cuda:0'), reward is -0.99\n",
      "Episode 521/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 19880, 'eps': 0.0, 'buffer_size': 19880, 'q_loss': 1.6277095079421997, 'mean_q_value': -0.1463291049003601, 'max_q_value': 0.3295537829399109, 'min_q_value': -0.9058014750480652, 'mean_td_error': 0.059807945, 'max_td_error': 0.38951272, 'mean_weight': 0.5326622724533081}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9201, -0.9481, -0.9099, -0.9155]], device='cuda:0'), reward is -0.99\n",
      "Episode 522/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 19917, 'eps': 0.0, 'buffer_size': 19917, 'q_loss': 1.9021503925323486, 'mean_q_value': -0.1288459599018097, 'max_q_value': 0.293775737285614, 'min_q_value': -0.9105756282806396, 'mean_td_error': 0.050915178, 'max_td_error': 0.18147522, 'mean_weight': 0.595025897026062}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8939, -0.9645, -0.8542, -0.8374]], device='cuda:0'), reward is -0.99\n",
      "Episode 523/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 19950, 'eps': 0.0, 'buffer_size': 19950, 'q_loss': 1.827318787574768, 'mean_q_value': -0.07005611062049866, 'max_q_value': 0.3192731738090515, 'min_q_value': -0.9188910722732544, 'mean_td_error': 0.055119373, 'max_td_error': 0.44527054, 'mean_weight': 0.5653778314590454}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1285, -0.1340, -0.1326, -0.1619]], device='cuda:0'), reward is -0.99\n",
      "Episode 524/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 19986, 'eps': 0.0, 'buffer_size': 19986, 'q_loss': 1.756128191947937, 'mean_q_value': -0.13810303807258606, 'max_q_value': 0.3463817238807678, 'min_q_value': -0.9774073362350464, 'mean_td_error': 0.03532421, 'max_td_error': 0.20020203, 'mean_weight': 0.5489813089370728}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5966, -0.4729, -0.4301, -0.4583]], device='cuda:0'), reward is -0.99\n",
      "Episode 525/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 20020, 'eps': 0.0, 'buffer_size': 20020, 'q_loss': 1.3996756076812744, 'mean_q_value': -0.253401517868042, 'max_q_value': 0.30780982971191406, 'min_q_value': -0.9400257468223572, 'mean_td_error': 0.06050654, 'max_td_error': 0.20802814, 'mean_weight': 0.4722653925418854}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6266, -0.5968, -0.5789, -0.5983]], device='cuda:0'), reward is -0.99\n",
      "Episode 526/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 20088, 'eps': 0.0, 'buffer_size': 20088, 'q_loss': 1.4035725593566895, 'mean_q_value': -0.2245086133480072, 'max_q_value': 0.30791133642196655, 'min_q_value': -0.9889608025550842, 'mean_td_error': 0.05424972, 'max_td_error': 0.22468087, 'mean_weight': 0.47677475214004517}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2543, -0.2168, -0.2673, -0.2797]], device='cuda:0'), reward is -0.99\n",
      "Episode 527/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 20121, 'eps': 0.0, 'buffer_size': 20121, 'q_loss': 1.7979249954223633, 'mean_q_value': -0.09268759191036224, 'max_q_value': 0.3206019401550293, 'min_q_value': -0.988813042640686, 'mean_td_error': 0.06216413, 'max_td_error': 0.29854053, 'mean_weight': 0.5625230073928833}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6020, -0.5957, -0.5421, -0.5624]], device='cuda:0'), reward is -0.99\n",
      "Episode 528/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 20190, 'eps': 0.0, 'buffer_size': 20190, 'q_loss': 1.5497119426727295, 'mean_q_value': -0.1849331110715866, 'max_q_value': 0.26618659496307373, 'min_q_value': -0.9631080031394958, 'mean_td_error': 0.075761795, 'max_td_error': 0.17873544, 'mean_weight': 0.4799584746360779}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5659, -0.5425, -0.5789, -0.6401]], device='cuda:0'), reward is -0.99\n",
      "Episode 529/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 20218, 'eps': 0.0, 'buffer_size': 20218, 'q_loss': 2.0229811668395996, 'mean_q_value': -0.10845246911048889, 'max_q_value': 0.3149060904979706, 'min_q_value': -0.8038087487220764, 'mean_td_error': 0.054454166, 'max_td_error': 0.21782243, 'mean_weight': 0.6185482740402222}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4746, -0.3986, -0.2218, -0.3078]], device='cuda:0'), reward is -0.99\n",
      "Episode 530/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 20261, 'eps': 0.0, 'buffer_size': 20261, 'q_loss': 1.8342206478118896, 'mean_q_value': -0.05001283437013626, 'max_q_value': 0.3318163752555847, 'min_q_value': -0.879925549030304, 'mean_td_error': 0.060090616, 'max_td_error': 0.29891425, 'mean_weight': 0.5307008624076843}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6942, -0.7525, -0.6729, -0.7162]], device='cuda:0'), reward is -0.99\n",
      "Episode 531/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 20322, 'eps': 0.0, 'buffer_size': 20322, 'q_loss': 1.2533683776855469, 'mean_q_value': -0.16454502940177917, 'max_q_value': 0.31679368019104004, 'min_q_value': -0.8979684710502625, 'mean_td_error': 0.06692882, 'max_td_error': 0.46546802, 'mean_weight': 0.3799344301223755}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9070, -0.8629, -0.8547, -0.9396]], device='cuda:0'), reward is -0.99\n",
      "Episode 532/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 20357, 'eps': 0.0, 'buffer_size': 20357, 'q_loss': 1.7462444305419922, 'mean_q_value': -0.09460503607988358, 'max_q_value': 0.29729002714157104, 'min_q_value': -0.9290415644645691, 'mean_td_error': 0.05474154, 'max_td_error': 0.27114564, 'mean_weight': 0.5356498956680298}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4831, -0.3108, -0.2722, -0.3123]], device='cuda:0'), reward is -0.99\n",
      "Episode 533/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 20427, 'eps': 0.0, 'buffer_size': 20427, 'q_loss': 1.6306345462799072, 'mean_q_value': -0.07695084065198898, 'max_q_value': 0.3433803915977478, 'min_q_value': -0.92176353931427, 'mean_td_error': 0.08939086, 'max_td_error': 1.0614734, 'mean_weight': 0.49117785692214966}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8780, -0.8571, -0.7193, -0.7127]], device='cuda:0'), reward is -0.99\n",
      "Episode 534/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 20467, 'eps': 0.0, 'buffer_size': 20467, 'q_loss': 1.8025896549224854, 'mean_q_value': -0.06483539938926697, 'max_q_value': 0.3073468804359436, 'min_q_value': -0.9157320857048035, 'mean_td_error': 0.07108544, 'max_td_error': 0.63967144, 'mean_weight': 0.5410213470458984}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8660, -0.8640, -0.8697, -0.8908]], device='cuda:0'), reward is -0.99\n",
      "Episode 535/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 20521, 'eps': 0.0, 'buffer_size': 20521, 'q_loss': 2.098167896270752, 'mean_q_value': -0.07287542521953583, 'max_q_value': 0.3214725852012634, 'min_q_value': -0.9381015300750732, 'mean_td_error': 0.039534483, 'max_td_error': 0.10842848, 'mean_weight': 0.6342217326164246}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1910, 0.1905, 0.1859, 0.1646]], device='cuda:0'), reward is -0.99\n",
      "Episode 536/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 20581, 'eps': 0.0, 'buffer_size': 20581, 'q_loss': 1.4474635124206543, 'mean_q_value': -0.19248101115226746, 'max_q_value': 0.26233363151550293, 'min_q_value': -0.9316645264625549, 'mean_td_error': 0.058629155, 'max_td_error': 0.20036617, 'mean_weight': 0.47421231865882874}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9326, -0.9614, -0.9558, -0.9760]], device='cuda:0'), reward is -0.99\n",
      "Episode 537/1000000: {'total_return': 0.22000000000000086, 'steps': 122, 'total_steps': 20703, 'eps': 0.0, 'buffer_size': 20703, 'q_loss': 1.7767071723937988, 'mean_q_value': -0.19364851713180542, 'max_q_value': 0.30404436588287354, 'min_q_value': -0.927773654460907, 'mean_td_error': 0.048828907, 'max_td_error': 0.13728678, 'mean_weight': 0.5804989337921143}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0499, 0.1143, 0.1377, 0.0465]], device='cuda:0'), reward is -0.99\n",
      "Episode 538/1000000: {'total_return': -0.1899999999999995, 'steps': 81, 'total_steps': 20784, 'eps': 0.0, 'buffer_size': 20784, 'q_loss': 1.4022371768951416, 'mean_q_value': -0.0382651761174202, 'max_q_value': 0.3438943326473236, 'min_q_value': -0.9279888272285461, 'mean_td_error': 0.06371392, 'max_td_error': 0.17908567, 'mean_weight': 0.4185252785682678}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4584, -0.4654, -0.4508, -0.4587]], device='cuda:0'), reward is -0.99\n",
      "Episode 539/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 20852, 'eps': 0.0, 'buffer_size': 20852, 'q_loss': 1.5673418045043945, 'mean_q_value': -0.16495929658412933, 'max_q_value': 0.29954296350479126, 'min_q_value': -0.9785965085029602, 'mean_td_error': 0.077505, 'max_td_error': 0.41429633, 'mean_weight': 0.5080803632736206}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8767, -0.8569, -0.8569, -0.8905]], device='cuda:0'), reward is -0.99\n",
      "Episode 540/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 20920, 'eps': 0.0, 'buffer_size': 20920, 'q_loss': 1.6121338605880737, 'mean_q_value': -0.2161150872707367, 'max_q_value': 0.3185815215110779, 'min_q_value': -0.9589014053344727, 'mean_td_error': 0.05370734, 'max_td_error': 0.23603258, 'mean_weight': 0.536849856376648}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0513, -0.1662, -0.1469, -0.1141]], device='cuda:0'), reward is -0.99\n",
      "Episode 541/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 20948, 'eps': 0.0, 'buffer_size': 20948, 'q_loss': 1.5214002132415771, 'mean_q_value': -0.11462587118148804, 'max_q_value': 0.35796669125556946, 'min_q_value': -0.9705536365509033, 'mean_td_error': 0.045369815, 'max_td_error': 0.18836433, 'mean_weight': 0.4980166256427765}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8684, -0.8761, -0.8758, -0.9185]], device='cuda:0'), reward is -0.99\n",
      "Episode 542/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 20988, 'eps': 0.0, 'buffer_size': 20988, 'q_loss': 1.6430678367614746, 'mean_q_value': -0.1814541518688202, 'max_q_value': 0.3186635673046112, 'min_q_value': -0.9684607982635498, 'mean_td_error': 0.055394337, 'max_td_error': 0.24694061, 'mean_weight': 0.5470636487007141}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4887, -0.4894, -0.4951, -0.5018]], device='cuda:0'), reward is -0.99\n",
      "Episode 543/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 21048, 'eps': 0.0, 'buffer_size': 21048, 'q_loss': 1.4876947402954102, 'mean_q_value': -0.12600094079971313, 'max_q_value': 0.3373681306838989, 'min_q_value': -0.9411299228668213, 'mean_td_error': 0.05052899, 'max_td_error': 0.18603677, 'mean_weight': 0.47808265686035156}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7811, -0.7720, -0.7694, -0.7951]], device='cuda:0'), reward is -0.99\n",
      "Episode 544/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 21080, 'eps': 0.0, 'buffer_size': 21080, 'q_loss': 1.8738784790039062, 'mean_q_value': -0.1507740020751953, 'max_q_value': 0.3117801547050476, 'min_q_value': -0.929758608341217, 'mean_td_error': 0.070523925, 'max_td_error': 0.4342324, 'mean_weight': 0.570747971534729}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6287, -0.4901, -0.4524, -0.6505]], device='cuda:0'), reward is -0.99\n",
      "Episode 545/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 21107, 'eps': 0.0, 'buffer_size': 21107, 'q_loss': 2.0290017127990723, 'mean_q_value': -0.046427685767412186, 'max_q_value': 0.3062950372695923, 'min_q_value': -0.86659836769104, 'mean_td_error': 0.064997695, 'max_td_error': 0.23267767, 'mean_weight': 0.6053345203399658}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4242, -0.4406, -0.5100, -0.5408]], device='cuda:0'), reward is -0.99\n",
      "Episode 546/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 21133, 'eps': 0.0, 'buffer_size': 21133, 'q_loss': 1.8478243350982666, 'mean_q_value': -0.15221911668777466, 'max_q_value': 0.28237563371658325, 'min_q_value': -0.9772371053695679, 'mean_td_error': 0.06617653, 'max_td_error': 0.2703187, 'mean_weight': 0.5800985097885132}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2415,  0.0552,  0.1516,  0.1600]], device='cuda:0'), reward is -0.99\n",
      "Episode 547/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 21181, 'eps': 0.0, 'buffer_size': 21181, 'q_loss': 1.3347437381744385, 'mean_q_value': -0.21209262311458588, 'max_q_value': 0.3322855532169342, 'min_q_value': -0.9450017809867859, 'mean_td_error': 0.049836595, 'max_td_error': 0.18533117, 'mean_weight': 0.44134825468063354}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4296, -0.4207, -0.4717, -0.4899]], device='cuda:0'), reward is -0.99\n",
      "Episode 548/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 21214, 'eps': 0.0, 'buffer_size': 21214, 'q_loss': 1.3650867938995361, 'mean_q_value': -0.1529933214187622, 'max_q_value': 0.2877410352230072, 'min_q_value': -0.9540833234786987, 'mean_td_error': 0.045767926, 'max_td_error': 0.2551148, 'mean_weight': 0.43460994958877563}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5095, -0.4783, -0.4609, -0.4780]], device='cuda:0'), reward is -0.99\n",
      "Episode 549/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 21272, 'eps': 0.0, 'buffer_size': 21272, 'q_loss': 1.4848662614822388, 'mean_q_value': -0.19694167375564575, 'max_q_value': 0.3142154812812805, 'min_q_value': -0.955366849899292, 'mean_td_error': 0.06893996, 'max_td_error': 0.24315953, 'mean_weight': 0.4582926630973816}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7952, -0.9153, -0.7807, -0.9026]], device='cuda:0'), reward is -0.99\n",
      "Episode 550/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 21298, 'eps': 0.0, 'buffer_size': 21298, 'q_loss': 1.5878639221191406, 'mean_q_value': -0.15635843575000763, 'max_q_value': 0.29431650042533875, 'min_q_value': -0.8678928017616272, 'mean_td_error': 0.10529823, 'max_td_error': 0.66341275, 'mean_weight': 0.5027181506156921}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7670, -0.8676, -0.5266, -0.7126]], device='cuda:0'), reward is -0.99\n",
      "Episode 551/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 21367, 'eps': 0.0, 'buffer_size': 21367, 'q_loss': 1.594986915588379, 'mean_q_value': -0.08427552133798599, 'max_q_value': 0.3479940891265869, 'min_q_value': -0.9014136791229248, 'mean_td_error': 0.07418261, 'max_td_error': 0.43636322, 'mean_weight': 0.4776903986930847}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0603, -0.1243, -0.0946, -0.2658]], device='cuda:0'), reward is -0.99\n",
      "Episode 552/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 21431, 'eps': 0.0, 'buffer_size': 21431, 'q_loss': 1.5015003681182861, 'mean_q_value': -0.05341268330812454, 'max_q_value': 0.32014578580856323, 'min_q_value': -0.9007076621055603, 'mean_td_error': 0.050365612, 'max_td_error': 0.15303823, 'mean_weight': 0.46988534927368164}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9596, -0.9652, -0.9537, -0.9602]], device='cuda:0'), reward is -0.99\n",
      "Episode 553/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 21486, 'eps': 0.0, 'buffer_size': 21486, 'q_loss': 1.2611076831817627, 'mean_q_value': -0.26494520902633667, 'max_q_value': 0.31978917121887207, 'min_q_value': -0.9287262558937073, 'mean_td_error': 0.07578277, 'max_td_error': 0.33349735, 'mean_weight': 0.4567887485027313}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6033, -0.5789, -0.5795, -0.5827]], device='cuda:0'), reward is -0.99\n",
      "Episode 554/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 21507, 'eps': 0.0, 'buffer_size': 21507, 'q_loss': 1.3483328819274902, 'mean_q_value': -0.10627363622188568, 'max_q_value': 0.3347356617450714, 'min_q_value': -0.9224167466163635, 'mean_td_error': 0.054399375, 'max_td_error': 0.2067005, 'mean_weight': 0.4100126028060913}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1319, -0.1290, -0.1131, -0.1260]], device='cuda:0'), reward is -0.99\n",
      "Episode 555/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 21562, 'eps': 0.0, 'buffer_size': 21562, 'q_loss': 1.762053370475769, 'mean_q_value': -0.18277275562286377, 'max_q_value': 0.33186715841293335, 'min_q_value': -0.9179121255874634, 'mean_td_error': 0.06520017, 'max_td_error': 0.33782208, 'mean_weight': 0.5694202780723572}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2995, -0.3376, -0.3010, -0.3282]], device='cuda:0'), reward is -0.99\n",
      "Episode 556/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 21606, 'eps': 0.0, 'buffer_size': 21606, 'q_loss': 1.72088623046875, 'mean_q_value': -0.07073623687028885, 'max_q_value': 0.31727564334869385, 'min_q_value': -0.9042097330093384, 'mean_td_error': 0.04799126, 'max_td_error': 0.17740414, 'mean_weight': 0.5211969614028931}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2068, -0.2072, -0.2079, -0.2211]], device='cuda:0'), reward is -0.99\n",
      "Episode 557/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 21657, 'eps': 0.0, 'buffer_size': 21657, 'q_loss': 1.1674463748931885, 'mean_q_value': -0.14381366968154907, 'max_q_value': 0.31693974137306213, 'min_q_value': -0.9477159380912781, 'mean_td_error': 0.07310988, 'max_td_error': 0.3286583, 'mean_weight': 0.3705103397369385}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9253, -0.9023, -0.8972, -0.9265]], device='cuda:0'), reward is -0.99\n",
      "Episode 558/1000000: {'total_return': -0.14999999999999947, 'steps': 85, 'total_steps': 21742, 'eps': 0.0, 'buffer_size': 21742, 'q_loss': 1.3538603782653809, 'mean_q_value': -0.10023026913404465, 'max_q_value': 0.33185145258903503, 'min_q_value': -0.8615716099739075, 'mean_td_error': 0.072466046, 'max_td_error': 0.53392196, 'mean_weight': 0.39646169543266296}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1384, 0.1515, 0.1690, 0.1510]], device='cuda:0'), reward is -0.99\n",
      "Episode 559/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 21782, 'eps': 0.0, 'buffer_size': 21782, 'q_loss': 0.9959980249404907, 'mean_q_value': -0.23398379981517792, 'max_q_value': 0.32238462567329407, 'min_q_value': -0.9700299501419067, 'mean_td_error': 0.082392305, 'max_td_error': 0.6020776, 'mean_weight': 0.3173292875289917}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0704, -0.0531, -0.1098, -0.1079]], device='cuda:0'), reward is -0.99\n",
      "Episode 560/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 21813, 'eps': 0.0, 'buffer_size': 21813, 'q_loss': 1.8495745658874512, 'mean_q_value': -0.08902263641357422, 'max_q_value': 0.34660688042640686, 'min_q_value': -0.874276340007782, 'mean_td_error': 0.05152068, 'max_td_error': 0.2486107, 'mean_weight': 0.5685585737228394}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3517, -0.4005, -0.3465, -0.4772]], device='cuda:0'), reward is -0.99\n",
      "Episode 561/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 21839, 'eps': 0.0, 'buffer_size': 21839, 'q_loss': 1.7606227397918701, 'mean_q_value': -0.04579755291342735, 'max_q_value': 0.3185024857521057, 'min_q_value': -0.9033910036087036, 'mean_td_error': 0.055197902, 'max_td_error': 0.45260084, 'mean_weight': 0.5229500532150269}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6898, -0.6694, -0.7021, -0.7852]], device='cuda:0'), reward is -0.99\n",
      "Episode 562/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 21881, 'eps': 0.0, 'buffer_size': 21881, 'q_loss': 1.5721173286437988, 'mean_q_value': -0.055643126368522644, 'max_q_value': 0.3196163773536682, 'min_q_value': -0.8828436732292175, 'mean_td_error': 0.062091067, 'max_td_error': 0.25208527, 'mean_weight': 0.4870915710926056}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2256, -0.2236, -0.2543, -0.2697]], device='cuda:0'), reward is -0.99\n",
      "Episode 563/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 21905, 'eps': 0.0, 'buffer_size': 21905, 'q_loss': 1.541148066520691, 'mean_q_value': -0.1751973181962967, 'max_q_value': 0.30911922454833984, 'min_q_value': -0.9687600135803223, 'mean_td_error': 0.053871617, 'max_td_error': 0.23722035, 'mean_weight': 0.5156208276748657}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9441, -0.9394, -0.9364, -0.9474]], device='cuda:0'), reward is -0.99\n",
      "Episode 564/1000000: {'total_return': 0.2700000000000009, 'steps': 127, 'total_steps': 22032, 'eps': 0.0, 'buffer_size': 22032, 'q_loss': 1.8672099113464355, 'mean_q_value': -0.09211187809705734, 'max_q_value': 0.3478440046310425, 'min_q_value': -0.8914717435836792, 'mean_td_error': 0.048405945, 'max_td_error': 0.19287413, 'mean_weight': 0.571866512298584}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5696, -0.6494, -0.6125, -0.6538]], device='cuda:0'), reward is -0.99\n",
      "Episode 565/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 22079, 'eps': 0.0, 'buffer_size': 22079, 'q_loss': 1.0899138450622559, 'mean_q_value': -0.16967247426509857, 'max_q_value': 0.3142048716545105, 'min_q_value': -0.941581130027771, 'mean_td_error': 0.06340052, 'max_td_error': 0.28523946, 'mean_weight': 0.3550921380519867}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5345, -0.5206, -0.4494, -0.5360]], device='cuda:0'), reward is -0.99\n",
      "Episode 566/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 22130, 'eps': 0.0, 'buffer_size': 22130, 'q_loss': 1.9877511262893677, 'mean_q_value': -0.0643845796585083, 'max_q_value': 0.33555489778518677, 'min_q_value': -0.9001606702804565, 'mean_td_error': 0.048719473, 'max_td_error': 0.1690985, 'mean_weight': 0.5949050188064575}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5308, -0.5062, -0.4339, -0.4978]], device='cuda:0'), reward is -0.99\n",
      "Episode 567/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 22179, 'eps': 0.0, 'buffer_size': 22179, 'q_loss': 1.8162521123886108, 'mean_q_value': -0.11488620936870575, 'max_q_value': 0.3135813772678375, 'min_q_value': -0.9603968858718872, 'mean_td_error': 0.04240911, 'max_td_error': 0.16972542, 'mean_weight': 0.5471245050430298}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5964, -0.6269, -0.5765, -0.6531]], device='cuda:0'), reward is -0.99\n",
      "Episode 568/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 22212, 'eps': 0.0, 'buffer_size': 22212, 'q_loss': 1.6300212144851685, 'mean_q_value': -0.0892464742064476, 'max_q_value': 0.35218915343284607, 'min_q_value': -0.8494239449501038, 'mean_td_error': 0.10114298, 'max_td_error': 0.6256017, 'mean_weight': 0.48579394817352295}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5698, -0.5152, -0.4703, -0.4813]], device='cuda:0'), reward is -0.99\n",
      "Episode 569/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 22277, 'eps': 0.0, 'buffer_size': 22277, 'q_loss': 1.8944802284240723, 'mean_q_value': -0.18064455687999725, 'max_q_value': 0.25275757908821106, 'min_q_value': -0.9859752655029297, 'mean_td_error': 0.06692089, 'max_td_error': 0.20534179, 'mean_weight': 0.5913045406341553}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3781, -0.4081, -0.4400, -0.5115]], device='cuda:0'), reward is -0.99\n",
      "Episode 570/1000000: {'total_return': -0.7, 'steps': 30, 'total_steps': 22307, 'eps': 0.0, 'buffer_size': 22307, 'q_loss': 1.877950668334961, 'mean_q_value': -0.1431272327899933, 'max_q_value': 0.3487341105937958, 'min_q_value': -0.9808921217918396, 'mean_td_error': 0.04458414, 'max_td_error': 0.112006485, 'mean_weight': 0.6050249338150024}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9174, -0.9340, -0.8613, -0.8771]], device='cuda:0'), reward is -0.99\n",
      "Episode 571/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 22379, 'eps': 0.0, 'buffer_size': 22379, 'q_loss': 1.7336399555206299, 'mean_q_value': -0.18887227773666382, 'max_q_value': 0.33330121636390686, 'min_q_value': -0.8970242142677307, 'mean_td_error': 0.07126023, 'max_td_error': 0.47961852, 'mean_weight': 0.5532222390174866}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4874, -0.5892, -0.4861, -0.4970]], device='cuda:0'), reward is -0.99\n",
      "Episode 572/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 22447, 'eps': 0.0, 'buffer_size': 22447, 'q_loss': 1.5860099792480469, 'mean_q_value': -0.09320897608995438, 'max_q_value': 0.3217005133628845, 'min_q_value': -0.9040703773498535, 'mean_td_error': 0.060609996, 'max_td_error': 0.29836264, 'mean_weight': 0.4730292558670044}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8696, -0.8919, -0.8783, -0.8987]], device='cuda:0'), reward is -0.99\n",
      "Episode 573/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 22491, 'eps': 0.0, 'buffer_size': 22491, 'q_loss': 1.2560691833496094, 'mean_q_value': -0.1539299339056015, 'max_q_value': 0.306226909160614, 'min_q_value': -0.9339431524276733, 'mean_td_error': 0.05724731, 'max_td_error': 0.17677346, 'mean_weight': 0.396071195602417}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4167, -0.4538, -0.4312, -0.4460]], device='cuda:0'), reward is -0.99\n",
      "Episode 574/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 22532, 'eps': 0.0, 'buffer_size': 22532, 'q_loss': 1.6942607164382935, 'mean_q_value': -0.19646558165550232, 'max_q_value': 0.31806427240371704, 'min_q_value': -0.8430643677711487, 'mean_td_error': 0.05455447, 'max_td_error': 0.26530516, 'mean_weight': 0.543289065361023}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9504, -0.9524, -0.9520, -0.9582]], device='cuda:0'), reward is -0.99\n",
      "Episode 575/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 22558, 'eps': 0.0, 'buffer_size': 22558, 'q_loss': 1.3985644578933716, 'mean_q_value': -0.2587500512599945, 'max_q_value': 0.3112095296382904, 'min_q_value': -0.9634960293769836, 'mean_td_error': 0.045627594, 'max_td_error': 0.17100073, 'mean_weight': 0.49481314420700073}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6107, -0.6586, -0.8034, -0.7809]], device='cuda:0'), reward is -0.99\n",
      "Episode 576/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 22579, 'eps': 0.0, 'buffer_size': 22579, 'q_loss': 1.6751012802124023, 'mean_q_value': -0.20432648062705994, 'max_q_value': 0.34359243512153625, 'min_q_value': -0.9322987794876099, 'mean_td_error': 0.06473565, 'max_td_error': 0.2867809, 'mean_weight': 0.563342809677124}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6250, -0.6252, -0.5967, -0.6363]], device='cuda:0'), reward is -0.99\n",
      "Episode 577/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 22603, 'eps': 0.0, 'buffer_size': 22603, 'q_loss': 2.1864261627197266, 'mean_q_value': -0.04162856936454773, 'max_q_value': 0.32425153255462646, 'min_q_value': -0.8409104943275452, 'mean_td_error': 0.05098652, 'max_td_error': 0.22163367, 'mean_weight': 0.6424713134765625}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4814, -0.4360, -0.3886, -0.4157]], device='cuda:0'), reward is -0.99\n",
      "Episode 578/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 22628, 'eps': 0.0, 'buffer_size': 22628, 'q_loss': 1.7688090801239014, 'mean_q_value': -0.12456104159355164, 'max_q_value': 0.32813015580177307, 'min_q_value': -0.9198233485221863, 'mean_td_error': 0.08694477, 'max_td_error': 0.6618239, 'mean_weight': 0.5612532496452332}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9442, -0.9574, -0.9580, -0.9740]], device='cuda:0'), reward is -0.99\n",
      "Episode 579/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 22679, 'eps': 0.0, 'buffer_size': 22679, 'q_loss': 1.4689706563949585, 'mean_q_value': -0.08959650993347168, 'max_q_value': 0.32772842049598694, 'min_q_value': -0.903421938419342, 'mean_td_error': 0.062019072, 'max_td_error': 0.24826127, 'mean_weight': 0.45026350021362305}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7422, -0.7622, -0.7282, -0.7709]], device='cuda:0'), reward is -0.99\n",
      "Episode 580/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 22733, 'eps': 0.0, 'buffer_size': 22733, 'q_loss': 1.0704457759857178, 'mean_q_value': -0.24327421188354492, 'max_q_value': 0.3220266103744507, 'min_q_value': -0.9253379702568054, 'mean_td_error': 0.0597054, 'max_td_error': 0.26740867, 'mean_weight': 0.3591829240322113}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3628, -0.6372, -0.3623, -0.5053]], device='cuda:0'), reward is -0.99\n",
      "Episode 581/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 22760, 'eps': 0.0, 'buffer_size': 22760, 'q_loss': 1.169304609298706, 'mean_q_value': -0.043522514402866364, 'max_q_value': 0.335213303565979, 'min_q_value': -0.9681941270828247, 'mean_td_error': 0.03459561, 'max_td_error': 0.11393559, 'mean_weight': 0.353111207485199}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8821, -0.9387, -0.9146, -0.9276]], device='cuda:0'), reward is -0.99\n",
      "Episode 582/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 22812, 'eps': 0.0, 'buffer_size': 22812, 'q_loss': 1.8065342903137207, 'mean_q_value': -0.10141714662313461, 'max_q_value': 0.32145142555236816, 'min_q_value': -0.8599563241004944, 'mean_td_error': 0.06576094, 'max_td_error': 0.52369815, 'mean_weight': 0.5457374453544617}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4693, -0.3995, -0.3840, -0.3396]], device='cuda:0'), reward is -0.99\n",
      "Episode 583/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 22847, 'eps': 0.0, 'buffer_size': 22847, 'q_loss': 1.3031024932861328, 'mean_q_value': -0.07894644141197205, 'max_q_value': 0.300711452960968, 'min_q_value': -0.9754294157028198, 'mean_td_error': 0.050389227, 'max_td_error': 0.12130235, 'mean_weight': 0.38710084557533264}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2394, -0.3339, -0.2024, -0.3455]], device='cuda:0'), reward is -0.99\n",
      "Episode 584/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 22916, 'eps': 0.0, 'buffer_size': 22916, 'q_loss': 1.643183708190918, 'mean_q_value': -0.13558325171470642, 'max_q_value': 0.32335054874420166, 'min_q_value': -0.9350816011428833, 'mean_td_error': 0.051270545, 'max_td_error': 0.15986168, 'mean_weight': 0.5187003016471863}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4156, -0.3787, -0.3832, -0.3620]], device='cuda:0'), reward is -0.99\n",
      "Episode 585/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 22952, 'eps': 0.0, 'buffer_size': 22952, 'q_loss': 1.522674798965454, 'mean_q_value': -0.2125454545021057, 'max_q_value': 0.2671852707862854, 'min_q_value': -0.9427451491355896, 'mean_td_error': 0.07303006, 'max_td_error': 0.26777044, 'mean_weight': 0.5033048391342163}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9762, -0.9647, -0.9819, -0.9971]], device='cuda:0'), reward is -0.99\n",
      "Episode 586/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 23030, 'eps': 0.0, 'buffer_size': 23030, 'q_loss': 1.0717864036560059, 'mean_q_value': -0.23019666969776154, 'max_q_value': 0.3399253189563751, 'min_q_value': -0.9646848440170288, 'mean_td_error': 0.08064602, 'max_td_error': 0.61972576, 'mean_weight': 0.37099283933639526}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7772, -0.7676, -0.7029, -0.7390]], device='cuda:0'), reward is -0.99\n",
      "Episode 587/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 23092, 'eps': 0.0, 'buffer_size': 23092, 'q_loss': 1.632513403892517, 'mean_q_value': -0.1843474805355072, 'max_q_value': 0.334367573261261, 'min_q_value': -0.8842666745185852, 'mean_td_error': 0.05910758, 'max_td_error': 0.26147985, 'mean_weight': 0.5241189002990723}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6493, -0.7513, -0.5598, -0.6383]], device='cuda:0'), reward is -0.99\n",
      "Episode 588/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 23119, 'eps': 0.0, 'buffer_size': 23119, 'q_loss': 1.4945485591888428, 'mean_q_value': -0.08639474213123322, 'max_q_value': 0.3163401484489441, 'min_q_value': -0.9370611310005188, 'mean_td_error': 0.07550819, 'max_td_error': 0.4999243, 'mean_weight': 0.4570382237434387}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7672, -0.7701, -0.7707, -0.7841]], device='cuda:0'), reward is -0.99\n",
      "Episode 589/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 23154, 'eps': 0.0, 'buffer_size': 23154, 'q_loss': 1.8378539085388184, 'mean_q_value': -0.1075764149427414, 'max_q_value': 0.3568539321422577, 'min_q_value': -0.875285267829895, 'mean_td_error': 0.077153, 'max_td_error': 0.4323287, 'mean_weight': 0.5471622347831726}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3536, -0.3132, -0.0700, -0.2417]], device='cuda:0'), reward is -0.99\n",
      "Episode 590/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 23215, 'eps': 0.0, 'buffer_size': 23215, 'q_loss': 1.445512056350708, 'mean_q_value': -0.16175615787506104, 'max_q_value': 0.328355073928833, 'min_q_value': -0.9598076939582825, 'mean_td_error': 0.050617866, 'max_td_error': 0.20338985, 'mean_weight': 0.4735936224460602}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6802, -0.7248, -0.7165, -0.7241]], device='cuda:0'), reward is -0.99\n",
      "Episode 591/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 23268, 'eps': 0.0, 'buffer_size': 23268, 'q_loss': 1.5320611000061035, 'mean_q_value': -0.07054930925369263, 'max_q_value': 0.3434840440750122, 'min_q_value': -0.9436910152435303, 'mean_td_error': 0.045276, 'max_td_error': 0.16125326, 'mean_weight': 0.4602547883987427}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9342, -0.9516, -0.9453, -0.9436]], device='cuda:0'), reward is -0.99\n",
      "Episode 592/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 23317, 'eps': 0.0, 'buffer_size': 23317, 'q_loss': 1.4033056497573853, 'mean_q_value': -0.08912843465805054, 'max_q_value': 0.33381301164627075, 'min_q_value': -0.9529976844787598, 'mean_td_error': 0.05985581, 'max_td_error': 0.31900078, 'mean_weight': 0.441980242729187}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6466, -0.6893, -0.6544, -0.7310]], device='cuda:0'), reward is -0.99\n",
      "Episode 593/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 23359, 'eps': 0.0, 'buffer_size': 23359, 'q_loss': 1.9485087394714355, 'mean_q_value': -0.23581397533416748, 'max_q_value': 0.3376738429069519, 'min_q_value': -0.9636802673339844, 'mean_td_error': 0.058619455, 'max_td_error': 0.28928816, 'mean_weight': 0.6692442893981934}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8956, -0.9508, -0.8852, -0.9323]], device='cuda:0'), reward is -0.99\n",
      "Episode 594/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 23405, 'eps': 0.0, 'buffer_size': 23405, 'q_loss': 2.18500018119812, 'mean_q_value': -0.08645681291818619, 'max_q_value': 0.3266439437866211, 'min_q_value': -0.9414586424827576, 'mean_td_error': 0.054627206, 'max_td_error': 0.33753636, 'mean_weight': 0.6623997688293457}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8760, -0.8723, -0.8604, -0.7672]], device='cuda:0'), reward is -0.99\n",
      "Episode 595/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 23439, 'eps': 0.0, 'buffer_size': 23439, 'q_loss': 1.314380168914795, 'mean_q_value': -0.19271357357501984, 'max_q_value': 0.32507744431495667, 'min_q_value': -0.9318547248840332, 'mean_td_error': 0.04527495, 'max_td_error': 0.16006082, 'mean_weight': 0.42174988985061646}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0008, -0.0232,  0.0044, -0.0147]], device='cuda:0'), reward is -0.99\n",
      "Episode 596/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 23470, 'eps': 0.0, 'buffer_size': 23470, 'q_loss': 1.9743543863296509, 'mean_q_value': -0.09943676739931107, 'max_q_value': 0.33844423294067383, 'min_q_value': -0.946648359298706, 'mean_td_error': 0.061403476, 'max_td_error': 0.2178413, 'mean_weight': 0.6061058044433594}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7150, -0.7710, -0.7784, -0.8189]], device='cuda:0'), reward is -0.99\n",
      "Episode 597/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 23512, 'eps': 0.0, 'buffer_size': 23512, 'q_loss': 1.7480313777923584, 'mean_q_value': -0.0740242600440979, 'max_q_value': 0.34748461842536926, 'min_q_value': -0.8977704644203186, 'mean_td_error': 0.045355193, 'max_td_error': 0.22990192, 'mean_weight': 0.539957582950592}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0633, 0.0698, 0.1241, 0.0825]], device='cuda:0'), reward is -0.99\n",
      "Episode 598/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 23580, 'eps': 0.0, 'buffer_size': 23580, 'q_loss': 1.3231925964355469, 'mean_q_value': -0.19481949508190155, 'max_q_value': 0.3084698021411896, 'min_q_value': -0.9960511922836304, 'mean_td_error': 0.08818621, 'max_td_error': 0.47933143, 'mean_weight': 0.45902320742607117}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9063, -0.9096, -0.9103, -0.9136]], device='cuda:0'), reward is -0.99\n",
      "Episode 599/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 23641, 'eps': 0.0, 'buffer_size': 23641, 'q_loss': 1.6943243741989136, 'mean_q_value': -0.15986940264701843, 'max_q_value': 0.3181452751159668, 'min_q_value': -0.8997095823287964, 'mean_td_error': 0.060908202, 'max_td_error': 0.42441684, 'mean_weight': 0.5434726476669312}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9578, -0.9641, -0.9468, -0.9555]], device='cuda:0'), reward is -0.99\n",
      "Episode 600/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 23684, 'eps': 0.0, 'buffer_size': 23684, 'q_loss': 1.5630642175674438, 'mean_q_value': -0.09314275532960892, 'max_q_value': 0.3374711573123932, 'min_q_value': -0.8965045809745789, 'mean_td_error': 0.053957894, 'max_td_error': 0.29057485, 'mean_weight': 0.4971786141395569}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5152, -0.5129, -0.5437, -0.4205]], device='cuda:0'), reward is -0.99\n",
      "Episode 601/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 23724, 'eps': 0.0, 'buffer_size': 23724, 'q_loss': 1.7763712406158447, 'mean_q_value': -0.12746380269527435, 'max_q_value': 0.32210755348205566, 'min_q_value': -0.8888683319091797, 'mean_td_error': 0.04531238, 'max_td_error': 0.17037815, 'mean_weight': 0.5497499704360962}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0356, 0.0359, 0.0343, 0.0357]], device='cuda:0'), reward is -0.99\n",
      "Episode 602/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 23757, 'eps': 0.0, 'buffer_size': 23757, 'q_loss': 0.8972307443618774, 'mean_q_value': -0.15131118893623352, 'max_q_value': 0.34098613262176514, 'min_q_value': -1.0029351711273193, 'mean_td_error': 0.046105944, 'max_td_error': 0.15081167, 'mean_weight': 0.30132535099983215}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5672, -0.5907, -0.6077, -0.6524]], device='cuda:0'), reward is -0.99\n",
      "Episode 603/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 23807, 'eps': 0.0, 'buffer_size': 23807, 'q_loss': 1.309657096862793, 'mean_q_value': -0.14822977781295776, 'max_q_value': 0.32072019577026367, 'min_q_value': -0.9367989301681519, 'mean_td_error': 0.037687637, 'max_td_error': 0.1943872, 'mean_weight': 0.41546764969825745}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5798, -0.5689, -0.5632, -0.5783]], device='cuda:0'), reward is -0.99\n",
      "Episode 604/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 23856, 'eps': 0.0, 'buffer_size': 23856, 'q_loss': 1.5351758003234863, 'mean_q_value': -0.0852738469839096, 'max_q_value': 0.3287143409252167, 'min_q_value': -0.9217196106910706, 'mean_td_error': 0.04847989, 'max_td_error': 0.2570787, 'mean_weight': 0.4572460651397705}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9414, -0.9543, -0.9409, -0.9502]], device='cuda:0'), reward is -0.99\n",
      "Episode 605/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 23891, 'eps': 0.0, 'buffer_size': 23891, 'q_loss': 1.4036141633987427, 'mean_q_value': -0.27203911542892456, 'max_q_value': 0.3303130865097046, 'min_q_value': -0.9435496926307678, 'mean_td_error': 0.06656693, 'max_td_error': 0.28533605, 'mean_weight': 0.48275622725486755}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8655, -0.8267, -0.8160, -0.8569]], device='cuda:0'), reward is -0.99\n",
      "Episode 606/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 23939, 'eps': 0.0, 'buffer_size': 23939, 'q_loss': 1.7475202083587646, 'mean_q_value': -0.09423117339611053, 'max_q_value': 0.3506219983100891, 'min_q_value': -0.9719783663749695, 'mean_td_error': 0.044039905, 'max_td_error': 0.27398032, 'mean_weight': 0.5352654457092285}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2480, -0.2106, -0.1571, -0.1335]], device='cuda:0'), reward is -0.99\n",
      "Episode 607/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 23970, 'eps': 0.0, 'buffer_size': 23970, 'q_loss': 1.6414556503295898, 'mean_q_value': -0.1338425874710083, 'max_q_value': 0.3349963426589966, 'min_q_value': -0.940726637840271, 'mean_td_error': 0.05331529, 'max_td_error': 0.22350882, 'mean_weight': 0.5289472341537476}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1581, -0.1353, -0.1504, -0.1151]], device='cuda:0'), reward is -0.99\n",
      "Episode 608/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 24011, 'eps': 0.0, 'buffer_size': 24011, 'q_loss': 1.7302582263946533, 'mean_q_value': -0.07006537169218063, 'max_q_value': 0.36065709590911865, 'min_q_value': -0.9254539012908936, 'mean_td_error': 0.048469737, 'max_td_error': 0.20662725, 'mean_weight': 0.5241527557373047}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4425, -0.4759, -0.4411, -0.4571]], device='cuda:0'), reward is -0.99\n",
      "Episode 609/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 24060, 'eps': 0.0, 'buffer_size': 24060, 'q_loss': 1.8276782035827637, 'mean_q_value': -0.11341921985149384, 'max_q_value': 0.3510657846927643, 'min_q_value': -0.880208432674408, 'mean_td_error': 0.056619354, 'max_td_error': 0.2766011, 'mean_weight': 0.5710691213607788}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4469, -0.4322, -0.4167, -0.4447]], device='cuda:0'), reward is -0.99\n",
      "Episode 610/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 24100, 'eps': 0.0, 'buffer_size': 24100, 'q_loss': 1.8628698587417603, 'mean_q_value': -0.05935036763548851, 'max_q_value': 0.3002023696899414, 'min_q_value': -0.9722737073898315, 'mean_td_error': 0.046636026, 'max_td_error': 0.18259527, 'mean_weight': 0.5835305452346802}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4215, -0.4581, -0.4164, -0.4131]], device='cuda:0'), reward is -0.99\n",
      "Episode 611/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 24134, 'eps': 0.0, 'buffer_size': 24134, 'q_loss': 1.1543675661087036, 'mean_q_value': -0.15937358140945435, 'max_q_value': 0.32276231050491333, 'min_q_value': -0.9384365677833557, 'mean_td_error': 0.06169388, 'max_td_error': 0.28685957, 'mean_weight': 0.356943279504776}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9570, -0.9615, -0.9452, -0.9342]], device='cuda:0'), reward is -0.99\n",
      "Episode 612/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 24187, 'eps': 0.0, 'buffer_size': 24187, 'q_loss': 1.4192057847976685, 'mean_q_value': -0.203462153673172, 'max_q_value': 0.31768733263015747, 'min_q_value': -0.9077948927879333, 'mean_td_error': 0.0571253, 'max_td_error': 0.31684697, 'mean_weight': 0.48828232288360596}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8399, -0.6755, -0.7072, -0.7316]], device='cuda:0'), reward is -0.99\n",
      "Episode 613/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 24220, 'eps': 0.0, 'buffer_size': 24220, 'q_loss': 1.8853585720062256, 'mean_q_value': -0.2185220718383789, 'max_q_value': 0.2862240672111511, 'min_q_value': -0.9429773092269897, 'mean_td_error': 0.05456677, 'max_td_error': 0.24120152, 'mean_weight': 0.6686137318611145}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0549, -0.0514, -0.0456, -0.0591]], device='cuda:0'), reward is -0.99\n",
      "Episode 614/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 24264, 'eps': 0.0, 'buffer_size': 24264, 'q_loss': 1.7325456142425537, 'mean_q_value': -0.11057114601135254, 'max_q_value': 0.3306618928909302, 'min_q_value': -0.9048086404800415, 'mean_td_error': 0.055811998, 'max_td_error': 0.18419224, 'mean_weight': 0.5420323610305786}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9493, -0.9407, -0.9449, -0.9579]], device='cuda:0'), reward is -0.99\n",
      "Episode 615/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 24292, 'eps': 0.0, 'buffer_size': 24292, 'q_loss': 1.3981986045837402, 'mean_q_value': -0.10593950748443604, 'max_q_value': 0.32386577129364014, 'min_q_value': -0.9684192538261414, 'mean_td_error': 0.04562196, 'max_td_error': 0.17899425, 'mean_weight': 0.42822763323783875}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7094, -0.6177, -0.7936, -0.7638]], device='cuda:0'), reward is -0.99\n",
      "Episode 616/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 24312, 'eps': 0.0, 'buffer_size': 24312, 'q_loss': 1.6024553775787354, 'mean_q_value': -0.0803489238023758, 'max_q_value': 0.3313804864883423, 'min_q_value': -0.822370707988739, 'mean_td_error': 0.063579455, 'max_td_error': 0.30373532, 'mean_weight': 0.4969617426395416}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8931, -0.8748, -0.8756, -0.9346]], device='cuda:0'), reward is -0.99\n",
      "Episode 617/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 24381, 'eps': 0.0, 'buffer_size': 24381, 'q_loss': 1.7115678787231445, 'mean_q_value': -0.0971985012292862, 'max_q_value': 0.33974185585975647, 'min_q_value': -0.8985286951065063, 'mean_td_error': 0.059543967, 'max_td_error': 0.42858207, 'mean_weight': 0.535720944404602}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0036,  0.0055,  0.0088, -0.0245]], device='cuda:0'), reward is -0.99\n",
      "Episode 618/1000000: {'total_return': -0.8099999999999999, 'steps': 19, 'total_steps': 24400, 'eps': 0.0, 'buffer_size': 24400, 'q_loss': 1.7606651782989502, 'mean_q_value': -0.12530474364757538, 'max_q_value': 0.35790103673934937, 'min_q_value': -0.8929182291030884, 'mean_td_error': 0.06803708, 'max_td_error': 0.3970387, 'mean_weight': 0.543574869632721}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8857, -0.8840, -0.8939, -0.9069]], device='cuda:0'), reward is -0.99\n",
      "Episode 619/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 24450, 'eps': 0.0, 'buffer_size': 24450, 'q_loss': 1.857753872871399, 'mean_q_value': -0.09241461753845215, 'max_q_value': 0.32674580812454224, 'min_q_value': -0.8369497656822205, 'mean_td_error': 0.07523072, 'max_td_error': 0.35161045, 'mean_weight': 0.5531764030456543}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2808, -0.3706, -0.3242, -0.3469]], device='cuda:0'), reward is -0.99\n",
      "Episode 620/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 24483, 'eps': 0.0, 'buffer_size': 24483, 'q_loss': 1.6015411615371704, 'mean_q_value': -0.20462627708911896, 'max_q_value': 0.32174307107925415, 'min_q_value': -0.9055842161178589, 'mean_td_error': 0.04982923, 'max_td_error': 0.15574169, 'mean_weight': 0.5265975594520569}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0171,  0.0031, -0.0208, -0.0245]], device='cuda:0'), reward is -0.99\n",
      "Episode 621/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 24536, 'eps': 0.0, 'buffer_size': 24536, 'q_loss': 1.5175484418869019, 'mean_q_value': -0.14560197293758392, 'max_q_value': 0.357705295085907, 'min_q_value': -0.9037407040596008, 'mean_td_error': 0.049948484, 'max_td_error': 0.21829015, 'mean_weight': 0.510871171951294}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8464, -0.8191, -0.8043, -0.8204]], device='cuda:0'), reward is -0.99\n",
      "Episode 622/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 24586, 'eps': 0.0, 'buffer_size': 24586, 'q_loss': 1.64547860622406, 'mean_q_value': -0.18073605000972748, 'max_q_value': 0.3333376944065094, 'min_q_value': -0.8798996806144714, 'mean_td_error': 0.061118487, 'max_td_error': 0.44163752, 'mean_weight': 0.5274921655654907}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1836, 0.1625, 0.2144, 0.1585]], device='cuda:0'), reward is -0.99\n",
      "Episode 623/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 24621, 'eps': 0.0, 'buffer_size': 24621, 'q_loss': 1.743086814880371, 'mean_q_value': -0.1774364411830902, 'max_q_value': 0.33678415417671204, 'min_q_value': -0.9641619324684143, 'mean_td_error': 0.07979057, 'max_td_error': 0.4098039, 'mean_weight': 0.5515021681785583}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1051, -0.1131, -0.1555, -0.1545]], device='cuda:0'), reward is -0.99\n",
      "Episode 624/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 24639, 'eps': 0.0, 'buffer_size': 24639, 'q_loss': 1.6712658405303955, 'mean_q_value': -0.3152552843093872, 'max_q_value': 0.28765785694122314, 'min_q_value': -0.9509127736091614, 'mean_td_error': 0.05493357, 'max_td_error': 0.1497514, 'mean_weight': 0.5807541608810425}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6631, -0.3896, -0.4607, -0.4591]], device='cuda:0'), reward is -0.99\n",
      "Episode 625/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 24664, 'eps': 0.0, 'buffer_size': 24664, 'q_loss': 1.531374454498291, 'mean_q_value': -0.15742966532707214, 'max_q_value': 0.330331027507782, 'min_q_value': -0.9456141591072083, 'mean_td_error': 0.054596722, 'max_td_error': 0.34911105, 'mean_weight': 0.49427467584609985}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8622, -0.9170, -0.8357, -0.9153]], device='cuda:0'), reward is -0.99\n",
      "Episode 626/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 24693, 'eps': 0.0, 'buffer_size': 24693, 'q_loss': 2.096780300140381, 'mean_q_value': -0.033397264778614044, 'max_q_value': 0.3321855664253235, 'min_q_value': -0.8599878549575806, 'mean_td_error': 0.048599415, 'max_td_error': 0.16888845, 'mean_weight': 0.6152116060256958}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9841, -0.9619, -0.9636, -0.9781]], device='cuda:0'), reward is -0.99\n",
      "Episode 627/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 24750, 'eps': 0.0, 'buffer_size': 24750, 'q_loss': 1.2388983964920044, 'mean_q_value': -0.18891361355781555, 'max_q_value': 0.3099520206451416, 'min_q_value': -0.9369521141052246, 'mean_td_error': 0.05148504, 'max_td_error': 0.21217205, 'mean_weight': 0.42596352100372314}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1067, 0.1592, 0.1808, 0.1422]], device='cuda:0'), reward is -0.99\n",
      "Episode 628/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 24823, 'eps': 0.0, 'buffer_size': 24823, 'q_loss': 1.7505220174789429, 'mean_q_value': -0.13780248165130615, 'max_q_value': 0.3665684759616852, 'min_q_value': -0.8990880846977234, 'mean_td_error': 0.071195565, 'max_td_error': 0.27842504, 'mean_weight': 0.5588169693946838}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3924, -0.3502, -0.3203, -0.3401]], device='cuda:0'), reward is -0.99\n",
      "Episode 629/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 24895, 'eps': 0.0, 'buffer_size': 24895, 'q_loss': 1.6814467906951904, 'mean_q_value': -0.2041691392660141, 'max_q_value': 0.344800740480423, 'min_q_value': -0.98432457447052, 'mean_td_error': 0.053622317, 'max_td_error': 0.17561409, 'mean_weight': 0.5787551999092102}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0926, 0.0965, 0.1019, 0.0789]], device='cuda:0'), reward is -0.99\n",
      "Episode 630/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 24915, 'eps': 0.0, 'buffer_size': 24915, 'q_loss': 1.5465142726898193, 'mean_q_value': -0.1355317085981369, 'max_q_value': 0.31502825021743774, 'min_q_value': -0.9797006845474243, 'mean_td_error': 0.04558841, 'max_td_error': 0.18610035, 'mean_weight': 0.49994906783103943}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8544, -0.8327, -0.8450, -0.9366]], device='cuda:0'), reward is -0.99\n",
      "Episode 631/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 24959, 'eps': 0.0, 'buffer_size': 24959, 'q_loss': 1.5052273273468018, 'mean_q_value': -0.08457370102405548, 'max_q_value': 0.38827255368232727, 'min_q_value': -0.8860839009284973, 'mean_td_error': 0.044133812, 'max_td_error': 0.19770178, 'mean_weight': 0.46411189436912537}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6854, -0.6573, -0.6923, -0.8554]], device='cuda:0'), reward is -0.99\n",
      "Episode 632/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 25012, 'eps': 0.0, 'buffer_size': 25012, 'q_loss': 1.7001254558563232, 'mean_q_value': -0.17219066619873047, 'max_q_value': 0.3118263781070709, 'min_q_value': -0.9388157725334167, 'mean_td_error': 0.0636545, 'max_td_error': 0.1951842, 'mean_weight': 0.5399388670921326}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8562, -0.8384, -0.8359, -0.8633]], device='cuda:0'), reward is -0.99\n",
      "Episode 633/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 25057, 'eps': 0.0, 'buffer_size': 25057, 'q_loss': 1.2317237854003906, 'mean_q_value': -0.16489823162555695, 'max_q_value': 0.32565343379974365, 'min_q_value': -0.961261510848999, 'mean_td_error': 0.050273716, 'max_td_error': 0.2315076, 'mean_weight': 0.38362765312194824}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0101,  0.0250,  0.0153, -0.0048]], device='cuda:0'), reward is -0.99\n",
      "Episode 634/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 25129, 'eps': 0.0, 'buffer_size': 25129, 'q_loss': 1.2891749143600464, 'mean_q_value': -0.1628139615058899, 'max_q_value': 0.36154699325561523, 'min_q_value': -0.9394170641899109, 'mean_td_error': 0.06263759, 'max_td_error': 0.3496971, 'mean_weight': 0.4144100546836853}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9537, -0.9437, -0.9411, -0.9560]], device='cuda:0'), reward is -0.99\n",
      "Episode 635/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 25166, 'eps': 0.0, 'buffer_size': 25166, 'q_loss': 1.1799919605255127, 'mean_q_value': -0.10350705683231354, 'max_q_value': 0.3052983283996582, 'min_q_value': -0.8987696170806885, 'mean_td_error': 0.10604647, 'max_td_error': 0.89951515, 'mean_weight': 0.37322378158569336}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4646, -0.5234, -0.4877, -0.5237]], device='cuda:0'), reward is -0.99\n",
      "Episode 636/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 25227, 'eps': 0.0, 'buffer_size': 25227, 'q_loss': 2.417214870452881, 'mean_q_value': -0.06682594865560532, 'max_q_value': 0.35494816303253174, 'min_q_value': -0.9576403498649597, 'mean_td_error': 0.061960332, 'max_td_error': 0.31310585, 'mean_weight': 0.7389156818389893}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5066, -0.5034, -0.5037, -0.5067]], device='cuda:0'), reward is -0.99\n",
      "Episode 637/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 25266, 'eps': 0.0, 'buffer_size': 25266, 'q_loss': 2.0626320838928223, 'mean_q_value': -0.06560821831226349, 'max_q_value': 0.3388117551803589, 'min_q_value': -0.939285933971405, 'mean_td_error': 0.038314242, 'max_td_error': 0.20975502, 'mean_weight': 0.6350010633468628}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2431, -0.2585, -0.2447, -0.2606]], device='cuda:0'), reward is -0.99\n",
      "Episode 638/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 25305, 'eps': 0.0, 'buffer_size': 25305, 'q_loss': 2.0414719581604004, 'mean_q_value': -0.1766723394393921, 'max_q_value': 0.3255273997783661, 'min_q_value': -1.0096949338912964, 'mean_td_error': 0.04405517, 'max_td_error': 0.1445427, 'mean_weight': 0.6692339777946472}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1020, -0.0191,  0.0025, -0.0329]], device='cuda:0'), reward is -0.99\n",
      "Episode 639/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 25362, 'eps': 0.0, 'buffer_size': 25362, 'q_loss': 2.009495735168457, 'mean_q_value': -0.04521314054727554, 'max_q_value': 0.32507064938545227, 'min_q_value': -0.7640668749809265, 'mean_td_error': 0.04503192, 'max_td_error': 0.19290681, 'mean_weight': 0.5934454798698425}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8161, -0.7045, -0.7718, -0.8060]], device='cuda:0'), reward is -0.99\n",
      "Episode 640/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 25420, 'eps': 0.0, 'buffer_size': 25420, 'q_loss': 1.195675015449524, 'mean_q_value': -0.15480563044548035, 'max_q_value': 0.32014894485473633, 'min_q_value': -0.9384769201278687, 'mean_td_error': 0.07013914, 'max_td_error': 0.54158336, 'mean_weight': 0.3949340581893921}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8559, -0.8775, -0.8559, -0.8708]], device='cuda:0'), reward is -0.99\n",
      "Episode 641/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 25468, 'eps': 0.0, 'buffer_size': 25468, 'q_loss': 1.7311427593231201, 'mean_q_value': -0.1606968641281128, 'max_q_value': 0.3758464753627777, 'min_q_value': -0.9235302805900574, 'mean_td_error': 0.054741025, 'max_td_error': 0.23401108, 'mean_weight': 0.5455120801925659}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8888, -0.9133, -0.8798, -0.9045]], device='cuda:0'), reward is -0.99\n",
      "Episode 642/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 25532, 'eps': 0.0, 'buffer_size': 25532, 'q_loss': 2.1194252967834473, 'mean_q_value': -0.11006529629230499, 'max_q_value': 0.31631341576576233, 'min_q_value': -0.8630855083465576, 'mean_td_error': 0.04388266, 'max_td_error': 0.17407185, 'mean_weight': 0.6493068933486938}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7813, -0.7708, -0.7583, -0.7888]], device='cuda:0'), reward is -0.99\n",
      "Episode 643/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 25609, 'eps': 0.0, 'buffer_size': 25609, 'q_loss': 1.8893922567367554, 'mean_q_value': -0.012643447145819664, 'max_q_value': 0.35049664974212646, 'min_q_value': -0.8996384143829346, 'mean_td_error': 0.04073261, 'max_td_error': 0.16284668, 'mean_weight': 0.5652963519096375}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1170, 0.1367, 0.1428, 0.1371]], device='cuda:0'), reward is -0.99\n",
      "Episode 644/1000000: {'total_return': -0.11999999999999944, 'steps': 88, 'total_steps': 25697, 'eps': 0.0, 'buffer_size': 25697, 'q_loss': 1.609918475151062, 'mean_q_value': -0.08340238034725189, 'max_q_value': 0.3434024155139923, 'min_q_value': -0.9610760807991028, 'mean_td_error': 0.038538884, 'max_td_error': 0.19642037, 'mean_weight': 0.48329776525497437}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5285, -0.5185, -0.5133, -0.5254]], device='cuda:0'), reward is -0.99\n",
      "Episode 645/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 25729, 'eps': 0.0, 'buffer_size': 25729, 'q_loss': 1.4932392835617065, 'mean_q_value': -0.06689329445362091, 'max_q_value': 0.33710813522338867, 'min_q_value': -0.8966198563575745, 'mean_td_error': 0.07073561, 'max_td_error': 1.0086107, 'mean_weight': 0.4563974440097809}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6643, -0.6601, -0.6763, -0.6931]], device='cuda:0'), reward is -0.99\n",
      "Episode 646/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 25775, 'eps': 0.0, 'buffer_size': 25775, 'q_loss': 2.3224363327026367, 'mean_q_value': -0.06748367846012115, 'max_q_value': 0.3318376839160919, 'min_q_value': -0.8591736555099487, 'mean_td_error': 0.05663732, 'max_td_error': 0.48588926, 'mean_weight': 0.6708476543426514}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7746, -0.7394, -0.7689, -0.7687]], device='cuda:0'), reward is -0.99\n",
      "Episode 647/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 25824, 'eps': 0.0, 'buffer_size': 25824, 'q_loss': 1.1581132411956787, 'mean_q_value': -0.10799786448478699, 'max_q_value': 0.353827565908432, 'min_q_value': -0.9681786894798279, 'mean_td_error': 0.040177494, 'max_td_error': 0.22569314, 'mean_weight': 0.3605983853340149}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5570, -0.5591, -0.5582, -0.5525]], device='cuda:0'), reward is -0.99\n",
      "Episode 648/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 25901, 'eps': 0.0, 'buffer_size': 25901, 'q_loss': 1.8439984321594238, 'mean_q_value': -0.11373423039913177, 'max_q_value': 0.3512468934059143, 'min_q_value': -0.9614639282226562, 'mean_td_error': 0.055788957, 'max_td_error': 0.27903455, 'mean_weight': 0.591816782951355}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9533, -0.9609, -0.9291, -0.9417]], device='cuda:0'), reward is -0.99\n",
      "Episode 649/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 25941, 'eps': 0.0, 'buffer_size': 25941, 'q_loss': 1.7593069076538086, 'mean_q_value': -0.142381489276886, 'max_q_value': 0.28353673219680786, 'min_q_value': -0.7560645937919617, 'mean_td_error': 0.06229411, 'max_td_error': 0.2693917, 'mean_weight': 0.5533592104911804}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4423, -0.5191, -0.4903, -0.5426]], device='cuda:0'), reward is -0.99\n",
      "Episode 650/1000000: {'total_return': -0.0699999999999994, 'steps': 93, 'total_steps': 26034, 'eps': 0.0, 'buffer_size': 26034, 'q_loss': 1.4093973636627197, 'mean_q_value': -0.1650885045528412, 'max_q_value': 0.33934056758880615, 'min_q_value': -1.0033414363861084, 'mean_td_error': 0.04304064, 'max_td_error': 0.24575442, 'mean_weight': 0.45205050706863403}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3975, -0.3689, -0.3717, -0.2769]], device='cuda:0'), reward is -0.99\n",
      "Episode 651/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 26065, 'eps': 0.0, 'buffer_size': 26065, 'q_loss': 1.1537322998046875, 'mean_q_value': -0.2624984383583069, 'max_q_value': 0.3187420964241028, 'min_q_value': -0.9105034470558167, 'mean_td_error': 0.053830564, 'max_td_error': 0.29464078, 'mean_weight': 0.4107692539691925}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7261, -0.7056, -0.6955, -0.7244]], device='cuda:0'), reward is -0.99\n",
      "Episode 652/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 26129, 'eps': 0.0, 'buffer_size': 26129, 'q_loss': 1.2849080562591553, 'mean_q_value': -0.15686184167861938, 'max_q_value': 0.36952024698257446, 'min_q_value': -0.8819372057914734, 'mean_td_error': 0.042147495, 'max_td_error': 0.15609697, 'mean_weight': 0.4155076742172241}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3704, -0.3672, -0.3654, -0.3700]], device='cuda:0'), reward is -0.99\n",
      "Episode 653/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 26173, 'eps': 0.0, 'buffer_size': 26173, 'q_loss': 1.4403553009033203, 'mean_q_value': -0.2456773817539215, 'max_q_value': 0.3566496968269348, 'min_q_value': -0.9894944429397583, 'mean_td_error': 0.08473563, 'max_td_error': 0.4205116, 'mean_weight': 0.5077022314071655}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7200, -0.7662, -0.7261, -0.7488]], device='cuda:0'), reward is -0.99\n",
      "Episode 654/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 26231, 'eps': 0.0, 'buffer_size': 26231, 'q_loss': 1.3038808107376099, 'mean_q_value': -0.20156897604465485, 'max_q_value': 0.35008156299591064, 'min_q_value': -0.9391230344772339, 'mean_td_error': 0.034191467, 'max_td_error': 0.11157194, 'mean_weight': 0.4398585557937622}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6093, -0.6643, -0.6321, -0.6550]], device='cuda:0'), reward is -0.99\n",
      "Episode 655/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 26295, 'eps': 0.0, 'buffer_size': 26295, 'q_loss': 1.4958043098449707, 'mean_q_value': -0.16855871677398682, 'max_q_value': 0.34812015295028687, 'min_q_value': -0.8742806911468506, 'mean_td_error': 0.052432086, 'max_td_error': 0.43073654, 'mean_weight': 0.4839298129081726}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6919, -0.7213, -0.6875, -0.6766]], device='cuda:0'), reward is -0.99\n",
      "Episode 656/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 26323, 'eps': 0.0, 'buffer_size': 26323, 'q_loss': 1.3833853006362915, 'mean_q_value': -0.22409427165985107, 'max_q_value': 0.3390829861164093, 'min_q_value': -0.9747475385665894, 'mean_td_error': 0.056584068, 'max_td_error': 0.28735685, 'mean_weight': 0.472345769405365}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8789, -0.8795, -0.8771, -0.8873]], device='cuda:0'), reward is -0.99\n",
      "Episode 657/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 26362, 'eps': 0.0, 'buffer_size': 26362, 'q_loss': 1.0332310199737549, 'mean_q_value': -0.23727887868881226, 'max_q_value': 0.3003256320953369, 'min_q_value': -0.955397367477417, 'mean_td_error': 0.073828265, 'max_td_error': 0.60257983, 'mean_weight': 0.36251163482666016}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1942, -0.2254, -0.2025, -0.2717]], device='cuda:0'), reward is -0.99\n",
      "Episode 658/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 26401, 'eps': 0.0, 'buffer_size': 26401, 'q_loss': 1.3980834484100342, 'mean_q_value': -0.2002878487110138, 'max_q_value': 0.315609335899353, 'min_q_value': -0.8888741731643677, 'mean_td_error': 0.04718822, 'max_td_error': 0.40540022, 'mean_weight': 0.4656953811645508}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8767, -0.8797, -0.8830, -0.8863]], device='cuda:0'), reward is -0.99\n",
      "Episode 659/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 26442, 'eps': 0.0, 'buffer_size': 26442, 'q_loss': 1.801161289215088, 'mean_q_value': -0.11086120456457138, 'max_q_value': 0.33695679903030396, 'min_q_value': -0.9161972403526306, 'mean_td_error': 0.03151191, 'max_td_error': 0.18924886, 'mean_weight': 0.5782337188720703}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5705, -0.5693, -0.5678, -0.5719]], device='cuda:0'), reward is -0.99\n",
      "Episode 660/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 26487, 'eps': 0.0, 'buffer_size': 26487, 'q_loss': 1.3685107231140137, 'mean_q_value': -0.22406774759292603, 'max_q_value': 0.3253191113471985, 'min_q_value': -0.9129364490509033, 'mean_td_error': 0.062104642, 'max_td_error': 0.33234122, 'mean_weight': 0.450756311416626}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6072, -0.6255, -0.6551, -0.6499]], device='cuda:0'), reward is -0.99\n",
      "Episode 661/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 26520, 'eps': 0.0, 'buffer_size': 26520, 'q_loss': 1.5439362525939941, 'mean_q_value': -0.15446114540100098, 'max_q_value': 0.299862265586853, 'min_q_value': -0.9310460686683655, 'mean_td_error': 0.04606574, 'max_td_error': 0.138358, 'mean_weight': 0.4999648332595825}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5547, -0.6178, -0.5571, -0.5868]], device='cuda:0'), reward is -0.99\n",
      "Episode 662/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 26587, 'eps': 0.0, 'buffer_size': 26587, 'q_loss': 1.4531234502792358, 'mean_q_value': -0.21015547215938568, 'max_q_value': 0.33614838123321533, 'min_q_value': -0.9586984515190125, 'mean_td_error': 0.04060757, 'max_td_error': 0.18974197, 'mean_weight': 0.4970836341381073}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5290, -0.3863, -0.3447, -0.3739]], device='cuda:0'), reward is -0.99\n",
      "Episode 663/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 26622, 'eps': 0.0, 'buffer_size': 26622, 'q_loss': 1.9341061115264893, 'mean_q_value': -0.08653198182582855, 'max_q_value': 0.36682143807411194, 'min_q_value': -0.9146632552146912, 'mean_td_error': 0.041352298, 'max_td_error': 0.17826658, 'mean_weight': 0.6235549449920654}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0583, 0.0636, 0.0421, 0.0373]], device='cuda:0'), reward is -0.99\n",
      "Episode 664/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 26665, 'eps': 0.0, 'buffer_size': 26665, 'q_loss': 1.8844983577728271, 'mean_q_value': -0.12890173494815826, 'max_q_value': 0.3413847088813782, 'min_q_value': -0.8628918528556824, 'mean_td_error': 0.051804513, 'max_td_error': 0.18745598, 'mean_weight': 0.6000834703445435}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5293, -0.5550, -0.5101, -0.5664]], device='cuda:0'), reward is -0.99\n",
      "Episode 665/1000000: {'total_return': -0.2899999999999996, 'steps': 71, 'total_steps': 26736, 'eps': 0.0, 'buffer_size': 26736, 'q_loss': 2.033590793609619, 'mean_q_value': -0.17357568442821503, 'max_q_value': 0.3314099907875061, 'min_q_value': -0.9239000082015991, 'mean_td_error': 0.0516508, 'max_td_error': 0.2750448, 'mean_weight': 0.6551771759986877}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9762, -0.9778, -0.9706, -0.9851]], device='cuda:0'), reward is -0.99\n",
      "Episode 666/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 26800, 'eps': 0.0, 'buffer_size': 26800, 'q_loss': 1.3112843036651611, 'mean_q_value': -0.2004062831401825, 'max_q_value': 0.32059377431869507, 'min_q_value': -0.8815449476242065, 'mean_td_error': 0.065430954, 'max_td_error': 0.24509948, 'mean_weight': 0.43104463815689087}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3694, -0.3681, -0.3062, -0.3513]], device='cuda:0'), reward is -0.99\n",
      "Episode 667/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 26837, 'eps': 0.0, 'buffer_size': 26837, 'q_loss': 1.4568686485290527, 'mean_q_value': -0.16200047731399536, 'max_q_value': 0.3659361004829407, 'min_q_value': -0.8694045543670654, 'mean_td_error': 0.06429085, 'max_td_error': 0.28526098, 'mean_weight': 0.4688366949558258}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1672, -0.1734, -0.1529, -0.1869]], device='cuda:0'), reward is -0.99\n",
      "Episode 668/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 26914, 'eps': 0.0, 'buffer_size': 26914, 'q_loss': 1.2582764625549316, 'mean_q_value': -0.14112059772014618, 'max_q_value': 0.33980593085289, 'min_q_value': -0.9640473127365112, 'mean_td_error': 0.055368006, 'max_td_error': 0.34654814, 'mean_weight': 0.4111604690551758}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3606, -0.4327, -0.3223, -0.3635]], device='cuda:0'), reward is -0.99\n",
      "Episode 669/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 26951, 'eps': 0.0, 'buffer_size': 26951, 'q_loss': 1.4560327529907227, 'mean_q_value': -0.21584452688694, 'max_q_value': 0.3156164884567261, 'min_q_value': -0.982096254825592, 'mean_td_error': 0.04849924, 'max_td_error': 0.17806238, 'mean_weight': 0.49432042241096497}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2451, -0.2314, -0.2399, -0.2773]], device='cuda:0'), reward is -0.99\n",
      "Episode 670/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 26975, 'eps': 0.0, 'buffer_size': 26975, 'q_loss': 1.6639976501464844, 'mean_q_value': -0.17639923095703125, 'max_q_value': 0.3688010573387146, 'min_q_value': -0.9722477793693542, 'mean_td_error': 0.052466318, 'max_td_error': 0.17840368, 'mean_weight': 0.5621659755706787}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7186, -0.7109, -0.6925, -0.7350]], device='cuda:0'), reward is -0.99\n",
      "Episode 671/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 27048, 'eps': 0.0, 'buffer_size': 27048, 'q_loss': 1.741909146308899, 'mean_q_value': -0.16362066566944122, 'max_q_value': 0.3471919000148773, 'min_q_value': -0.93932044506073, 'mean_td_error': 0.054454297, 'max_td_error': 0.22761065, 'mean_weight': 0.575066328048706}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6138, -0.6085, -0.5792, -0.5597]], device='cuda:0'), reward is -0.99\n",
      "Episode 672/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 27118, 'eps': 0.0, 'buffer_size': 27118, 'q_loss': 1.5074594020843506, 'mean_q_value': -0.09896403551101685, 'max_q_value': 0.3146534562110901, 'min_q_value': -0.977566123008728, 'mean_td_error': 0.0727578, 'max_td_error': 0.7424815, 'mean_weight': 0.4692379832267761}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1942, -0.1939, -0.1895, -0.1944]], device='cuda:0'), reward is -0.99\n",
      "Episode 673/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 27159, 'eps': 0.0, 'buffer_size': 27159, 'q_loss': 1.3603150844573975, 'mean_q_value': -0.061635877937078476, 'max_q_value': 0.34768086671829224, 'min_q_value': -0.9078366756439209, 'mean_td_error': 0.06096553, 'max_td_error': 0.3794518, 'mean_weight': 0.41278013586997986}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1427, 0.1417, 0.1455, 0.1447]], device='cuda:0'), reward is -0.99\n",
      "Episode 674/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 27235, 'eps': 0.0, 'buffer_size': 27235, 'q_loss': 1.5443099737167358, 'mean_q_value': -0.23507854342460632, 'max_q_value': 0.3428399860858917, 'min_q_value': -0.926041841506958, 'mean_td_error': 0.06952756, 'max_td_error': 0.4771703, 'mean_weight': 0.5046514272689819}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3570, -0.3896, -0.3787, -0.3480]], device='cuda:0'), reward is -0.99\n",
      "Episode 675/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 27297, 'eps': 0.0, 'buffer_size': 27297, 'q_loss': 1.5197172164916992, 'mean_q_value': -0.1619754135608673, 'max_q_value': 0.3588263690471649, 'min_q_value': -0.8940497636795044, 'mean_td_error': 0.08919473, 'max_td_error': 0.9523311, 'mean_weight': 0.4864944815635681}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7866, -0.8155, -0.7948, -0.7960]], device='cuda:0'), reward is -0.99\n",
      "Episode 676/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 27336, 'eps': 0.0, 'buffer_size': 27336, 'q_loss': 1.7127610445022583, 'mean_q_value': -0.16934403777122498, 'max_q_value': 0.34832996129989624, 'min_q_value': -0.9745429158210754, 'mean_td_error': 0.059090193, 'max_td_error': 0.32084626, 'mean_weight': 0.5676077008247375}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8326, -0.7966, -0.7999, -0.8297]], device='cuda:0'), reward is -0.99\n",
      "Episode 677/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 27413, 'eps': 0.0, 'buffer_size': 27413, 'q_loss': 1.2525436878204346, 'mean_q_value': -0.22225594520568848, 'max_q_value': 0.357546865940094, 'min_q_value': -0.8409549593925476, 'mean_td_error': 0.058277316, 'max_td_error': 0.2614141, 'mean_weight': 0.4378799796104431}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3749, -0.3317, -0.3655, -0.4122]], device='cuda:0'), reward is -0.99\n",
      "Episode 678/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 27464, 'eps': 0.0, 'buffer_size': 27464, 'q_loss': 1.4393013715744019, 'mean_q_value': -0.13589301705360413, 'max_q_value': 0.3526279926300049, 'min_q_value': -0.804949164390564, 'mean_td_error': 0.04381594, 'max_td_error': 0.18268716, 'mean_weight': 0.46342405676841736}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3706, -0.4380, -0.4151, -0.3775]], device='cuda:0'), reward is -0.99\n",
      "Episode 679/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 27493, 'eps': 0.0, 'buffer_size': 27493, 'q_loss': 1.4196869134902954, 'mean_q_value': -0.09847965091466904, 'max_q_value': 0.36203116178512573, 'min_q_value': -0.929877519607544, 'mean_td_error': 0.05052401, 'max_td_error': 0.22573048, 'mean_weight': 0.4509503245353699}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8561, -0.8492, -0.8473, -0.8539]], device='cuda:0'), reward is -0.99\n",
      "Episode 680/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 27563, 'eps': 0.0, 'buffer_size': 27563, 'q_loss': 1.7378261089324951, 'mean_q_value': -0.14304587244987488, 'max_q_value': 0.3368018865585327, 'min_q_value': -0.9231880903244019, 'mean_td_error': 0.048645683, 'max_td_error': 0.23544186, 'mean_weight': 0.560667872428894}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1537, -0.0842, -0.0969, -0.1508]], device='cuda:0'), reward is -0.99\n",
      "Episode 681/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 27616, 'eps': 0.0, 'buffer_size': 27616, 'q_loss': 1.337061882019043, 'mean_q_value': -0.20076212286949158, 'max_q_value': 0.3469442129135132, 'min_q_value': -0.9808669090270996, 'mean_td_error': 0.03857564, 'max_td_error': 0.18895003, 'mean_weight': 0.46529531478881836}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8067, -0.7965, -0.7956, -0.8161]], device='cuda:0'), reward is -0.99\n",
      "Episode 682/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 27660, 'eps': 0.0, 'buffer_size': 27660, 'q_loss': 1.4037702083587646, 'mean_q_value': -0.20781397819519043, 'max_q_value': 0.3497885465621948, 'min_q_value': -0.8895033001899719, 'mean_td_error': 0.033223413, 'max_td_error': 0.12078804, 'mean_weight': 0.4509473145008087}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6107, -0.5836, -0.5634, -0.6333]], device='cuda:0'), reward is -0.99\n",
      "Episode 683/1000000: {'total_return': -0.0699999999999994, 'steps': 93, 'total_steps': 27753, 'eps': 0.0, 'buffer_size': 27753, 'q_loss': 1.2380015850067139, 'mean_q_value': -0.13818711042404175, 'max_q_value': 0.35891449451446533, 'min_q_value': -0.959337055683136, 'mean_td_error': 0.06637542, 'max_td_error': 0.61205846, 'mean_weight': 0.39404624700546265}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6759, -0.5814, -0.5758, -0.6760]], device='cuda:0'), reward is -0.99\n",
      "Episode 684/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 27795, 'eps': 0.0, 'buffer_size': 27795, 'q_loss': 1.900087594985962, 'mean_q_value': -0.1410282552242279, 'max_q_value': 0.3273761570453644, 'min_q_value': -0.9242053627967834, 'mean_td_error': 0.07817863, 'max_td_error': 0.75686467, 'mean_weight': 0.5986738801002502}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8550, -0.8708, -0.8509, -0.8382]], device='cuda:0'), reward is -0.99\n",
      "Episode 685/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 27845, 'eps': 0.0, 'buffer_size': 27845, 'q_loss': 1.133491039276123, 'mean_q_value': -0.1452772170305252, 'max_q_value': 0.3255279064178467, 'min_q_value': -0.9244292974472046, 'mean_td_error': 0.048288047, 'max_td_error': 0.17768374, 'mean_weight': 0.36322712898254395}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8986, -0.8828, -0.8809, -0.9274]], device='cuda:0'), reward is -0.99\n",
      "Episode 686/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 27886, 'eps': 0.0, 'buffer_size': 27886, 'q_loss': 1.7045488357543945, 'mean_q_value': -0.09689926356077194, 'max_q_value': 0.3336581587791443, 'min_q_value': -0.8132461309432983, 'mean_td_error': 0.0475456, 'max_td_error': 0.233814, 'mean_weight': 0.5151005983352661}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1511, -0.1445, -0.1311, -0.1343]], device='cuda:0'), reward is -0.99\n",
      "Episode 687/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 27919, 'eps': 0.0, 'buffer_size': 27919, 'q_loss': 1.7140791416168213, 'mean_q_value': -0.20189207792282104, 'max_q_value': 0.3717394471168518, 'min_q_value': -0.8326799869537354, 'mean_td_error': 0.047370195, 'max_td_error': 0.14772725, 'mean_weight': 0.5827565789222717}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7527, -0.7417, -0.7472, -0.7372]], device='cuda:0'), reward is -0.99\n",
      "Episode 688/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 27960, 'eps': 0.0, 'buffer_size': 27960, 'q_loss': 1.658164620399475, 'mean_q_value': -0.18824619054794312, 'max_q_value': 0.3114665746688843, 'min_q_value': -0.9608939290046692, 'mean_td_error': 0.06317533, 'max_td_error': 0.36517274, 'mean_weight': 0.5497050285339355}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8864, -0.8996, -0.8908, -0.8948]], device='cuda:0'), reward is -0.99\n",
      "Episode 689/1000000: {'total_return': -0.1999999999999995, 'steps': 80, 'total_steps': 28040, 'eps': 0.0, 'buffer_size': 28040, 'q_loss': 1.1543970108032227, 'mean_q_value': -0.20388847589492798, 'max_q_value': 0.36140888929367065, 'min_q_value': -0.9832200407981873, 'mean_td_error': 0.06015691, 'max_td_error': 0.30671802, 'mean_weight': 0.3783363699913025}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1347,  0.1279, -0.0041, -0.0342]], device='cuda:0'), reward is -0.99\n",
      "Episode 690/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 28106, 'eps': 0.0, 'buffer_size': 28106, 'q_loss': 1.8431391716003418, 'mean_q_value': -0.14908583462238312, 'max_q_value': 0.3536667227745056, 'min_q_value': -0.8749735355377197, 'mean_td_error': 0.06130334, 'max_td_error': 0.27021134, 'mean_weight': 0.599703848361969}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8307, -0.8391, -0.8328, -0.8618]], device='cuda:0'), reward is -0.99\n",
      "Episode 691/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 28160, 'eps': 0.0, 'buffer_size': 28160, 'q_loss': 1.3773550987243652, 'mean_q_value': -0.15955358743667603, 'max_q_value': 0.3946326971054077, 'min_q_value': -0.9840943217277527, 'mean_td_error': 0.083018154, 'max_td_error': 0.4149776, 'mean_weight': 0.45439666509628296}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3490, -0.4084, -0.3329, -0.3716]], device='cuda:0'), reward is -0.99\n",
      "Episode 692/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 28196, 'eps': 0.0, 'buffer_size': 28196, 'q_loss': 1.3722652196884155, 'mean_q_value': -0.24122846126556396, 'max_q_value': 0.3352340757846832, 'min_q_value': -0.9286644458770752, 'mean_td_error': 0.0995985, 'max_td_error': 0.79547274, 'mean_weight': 0.4711045026779175}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8486, -0.8738, -0.8462, -0.8492]], device='cuda:0'), reward is -0.99\n",
      "Episode 693/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 28236, 'eps': 0.0, 'buffer_size': 28236, 'q_loss': 1.4074690341949463, 'mean_q_value': -0.15983542799949646, 'max_q_value': 0.3400312066078186, 'min_q_value': -0.9413889050483704, 'mean_td_error': 0.044655386, 'max_td_error': 0.17348093, 'mean_weight': 0.4681394100189209}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6307, -0.6825, -0.6204, -0.5921]], device='cuda:0'), reward is -0.99\n",
      "Episode 694/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 28310, 'eps': 0.0, 'buffer_size': 28310, 'q_loss': 1.7224516868591309, 'mean_q_value': -0.1544942557811737, 'max_q_value': 0.36159050464630127, 'min_q_value': -0.9553511142730713, 'mean_td_error': 0.048411034, 'max_td_error': 0.1423981, 'mean_weight': 0.5526699423789978}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5036, -0.5018, -0.5415, -0.5383]], device='cuda:0'), reward is -0.99\n",
      "Episode 695/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 28368, 'eps': 0.0, 'buffer_size': 28368, 'q_loss': 1.9685252904891968, 'mean_q_value': -0.14823484420776367, 'max_q_value': 0.3539486825466156, 'min_q_value': -0.9420173764228821, 'mean_td_error': 0.032067582, 'max_td_error': 0.08702466, 'mean_weight': 0.6697811484336853}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4705, -0.4862, -0.5659, -0.5177]], device='cuda:0'), reward is -0.99\n",
      "Episode 696/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 28422, 'eps': 0.0, 'buffer_size': 28422, 'q_loss': 1.5240391492843628, 'mean_q_value': -0.19399204850196838, 'max_q_value': 0.3401489853858948, 'min_q_value': -0.9581204056739807, 'mean_td_error': 0.03710883, 'max_td_error': 0.11401962, 'mean_weight': 0.5177643299102783}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9419, -0.9057, -0.8918, -0.9428]], device='cuda:0'), reward is -0.99\n",
      "Episode 697/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 28476, 'eps': 0.0, 'buffer_size': 28476, 'q_loss': 1.7753163576126099, 'mean_q_value': -0.16151335835456848, 'max_q_value': 0.3212973475456238, 'min_q_value': -0.9022794961929321, 'mean_td_error': 0.04808761, 'max_td_error': 0.2291556, 'mean_weight': 0.5636172294616699}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3565, -0.3594, -0.3627, -0.3541]], device='cuda:0'), reward is -0.99\n",
      "Episode 698/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 28516, 'eps': 0.0, 'buffer_size': 28516, 'q_loss': 1.7919076681137085, 'mean_q_value': -0.1230396181344986, 'max_q_value': 0.3783659338951111, 'min_q_value': -0.9065619111061096, 'mean_td_error': 0.08584953, 'max_td_error': 0.5384948, 'mean_weight': 0.5916335582733154}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7487, -0.7060, -0.7120, -0.7422]], device='cuda:0'), reward is -0.99\n",
      "Episode 699/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 28556, 'eps': 0.0, 'buffer_size': 28556, 'q_loss': 1.6607763767242432, 'mean_q_value': -0.23471921682357788, 'max_q_value': 0.37383419275283813, 'min_q_value': -1.0197020769119263, 'mean_td_error': 0.07180835, 'max_td_error': 0.28029722, 'mean_weight': 0.5659059286117554}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8240, -0.8149, -0.8149, -0.8281]], device='cuda:0'), reward is -0.99\n",
      "Episode 700/1000000: {'total_return': -0.12999999999999945, 'steps': 87, 'total_steps': 28643, 'eps': 0.0, 'buffer_size': 28643, 'q_loss': 1.7658960819244385, 'mean_q_value': -0.1736660599708557, 'max_q_value': 0.34362637996673584, 'min_q_value': -0.8884769678115845, 'mean_td_error': 0.04960325, 'max_td_error': 0.19757411, 'mean_weight': 0.5886183977127075}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3530, -0.3433, -0.3427, -0.3611]], device='cuda:0'), reward is -0.99\n",
      "Episode 701/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 28721, 'eps': 0.0, 'buffer_size': 28721, 'q_loss': 1.679999589920044, 'mean_q_value': -0.26257941126823425, 'max_q_value': 0.3414202928543091, 'min_q_value': -0.9225203990936279, 'mean_td_error': 0.044035662, 'max_td_error': 0.16551682, 'mean_weight': 0.5961707830429077}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5211, -0.5824, -0.5188, -0.5797]], device='cuda:0'), reward is -0.99\n",
      "Episode 702/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 28795, 'eps': 0.0, 'buffer_size': 28795, 'q_loss': 1.46043062210083, 'mean_q_value': -0.18448318541049957, 'max_q_value': 0.34014371037483215, 'min_q_value': -0.9164668917655945, 'mean_td_error': 0.07032591, 'max_td_error': 0.4201814, 'mean_weight': 0.4881106913089752}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9555, -0.9257, -0.9148, -0.9678]], device='cuda:0'), reward is -0.99\n",
      "Episode 703/1000000: {'total_return': 6.661338147750939e-16, 'steps': 100, 'total_steps': 28895, 'eps': 0.0, 'buffer_size': 28895, 'q_loss': 1.5983707904815674, 'mean_q_value': -0.16645221412181854, 'max_q_value': 0.3257284164428711, 'min_q_value': -0.9595292806625366, 'mean_td_error': 0.044752404, 'max_td_error': 0.13919437, 'mean_weight': 0.526362955570221}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5556, -0.5302, -0.5139, -0.5162]], device='cuda:0'), reward is -0.99\n",
      "Episode 704/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 28929, 'eps': 0.0, 'buffer_size': 28929, 'q_loss': 1.9551427364349365, 'mean_q_value': -0.19530954957008362, 'max_q_value': 0.3708004653453827, 'min_q_value': -0.9802467823028564, 'mean_td_error': 0.054504894, 'max_td_error': 0.39900458, 'mean_weight': 0.6360146999359131}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8616, -0.8553, -0.8387, -0.8341]], device='cuda:0'), reward is -0.99\n",
      "Episode 705/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 28974, 'eps': 0.0, 'buffer_size': 28974, 'q_loss': 1.1220149993896484, 'mean_q_value': -0.2834984362125397, 'max_q_value': 0.3308146595954895, 'min_q_value': -0.9727348685264587, 'mean_td_error': 0.04734276, 'max_td_error': 0.3647235, 'mean_weight': 0.416908860206604}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8936, -0.9137, -0.8950, -0.8977]], device='cuda:0'), reward is -0.99\n",
      "Episode 706/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 29012, 'eps': 0.0, 'buffer_size': 29012, 'q_loss': 1.8947043418884277, 'mean_q_value': -0.18942004442214966, 'max_q_value': 0.3397548794746399, 'min_q_value': -0.9536650776863098, 'mean_td_error': 0.052913755, 'max_td_error': 0.2876773, 'mean_weight': 0.6582951545715332}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9181, -0.9021, -0.9104, -0.9165]], device='cuda:0'), reward is -0.99\n",
      "Episode 707/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 29051, 'eps': 0.0, 'buffer_size': 29051, 'q_loss': 1.7339433431625366, 'mean_q_value': -0.13847872614860535, 'max_q_value': 0.3196461796760559, 'min_q_value': -0.9795777797698975, 'mean_td_error': 0.040464807, 'max_td_error': 0.12360448, 'mean_weight': 0.563813328742981}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4519, -0.4220, -0.4176, -0.4337]], device='cuda:0'), reward is -0.99\n",
      "Episode 708/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 29083, 'eps': 0.0, 'buffer_size': 29083, 'q_loss': 1.1114393472671509, 'mean_q_value': -0.14221656322479248, 'max_q_value': 0.3562471568584442, 'min_q_value': -0.9945009350776672, 'mean_td_error': 0.046728455, 'max_td_error': 0.30685535, 'mean_weight': 0.36283138394355774}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4099, -0.4134, -0.3899, -0.3956]], device='cuda:0'), reward is -0.99\n",
      "Episode 709/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 29120, 'eps': 0.0, 'buffer_size': 29120, 'q_loss': 1.9474914073944092, 'mean_q_value': -0.1347803771495819, 'max_q_value': 0.3405696153640747, 'min_q_value': -0.9343624114990234, 'mean_td_error': 0.05932118, 'max_td_error': 0.33404148, 'mean_weight': 0.6213079690933228}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8021, -0.7458, -0.7486, -0.8035]], device='cuda:0'), reward is -0.99\n",
      "Episode 710/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 29177, 'eps': 0.0, 'buffer_size': 29177, 'q_loss': 1.5107628107070923, 'mean_q_value': -0.10805515944957733, 'max_q_value': 0.36671513319015503, 'min_q_value': -0.9881813526153564, 'mean_td_error': 0.045427278, 'max_td_error': 0.13665599, 'mean_weight': 0.48782286047935486}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9070, -0.9078, -0.9172, -0.9159]], device='cuda:0'), reward is -0.99\n",
      "Episode 711/1000000: {'total_return': -0.20999999999999952, 'steps': 79, 'total_steps': 29256, 'eps': 0.0, 'buffer_size': 29256, 'q_loss': 1.7696478366851807, 'mean_q_value': -0.1113082617521286, 'max_q_value': 0.35765311121940613, 'min_q_value': -0.920659601688385, 'mean_td_error': 0.04821293, 'max_td_error': 0.17741722, 'mean_weight': 0.5740711688995361}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9239, -0.9186, -0.9157, -0.9419]], device='cuda:0'), reward is -0.99\n",
      "Episode 712/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 29320, 'eps': 0.0, 'buffer_size': 29320, 'q_loss': 1.1155846118927002, 'mean_q_value': -0.1096496731042862, 'max_q_value': 0.33434319496154785, 'min_q_value': -0.9647257328033447, 'mean_td_error': 0.054865967, 'max_td_error': 0.18209681, 'mean_weight': 0.36091262102127075}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7442, -0.6654, -0.6727, -0.7421]], device='cuda:0'), reward is -0.99\n",
      "Episode 713/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 29381, 'eps': 0.0, 'buffer_size': 29381, 'q_loss': 1.4783917665481567, 'mean_q_value': -0.1640002280473709, 'max_q_value': 0.3777681589126587, 'min_q_value': -0.8722224831581116, 'mean_td_error': 0.061821014, 'max_td_error': 0.3665533, 'mean_weight': 0.49008673429489136}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5410, -0.5410, -0.5404, -0.5437]], device='cuda:0'), reward is -0.99\n",
      "Episode 714/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 29442, 'eps': 0.0, 'buffer_size': 29442, 'q_loss': 1.8974595069885254, 'mean_q_value': -0.20261907577514648, 'max_q_value': 0.36348897218704224, 'min_q_value': -0.9514067769050598, 'mean_td_error': 0.051678184, 'max_td_error': 0.19785155, 'mean_weight': 0.6377682089805603}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8527, -0.8391, -0.8505, -0.8652]], device='cuda:0'), reward is -0.99\n",
      "Episode 715/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 29518, 'eps': 0.0, 'buffer_size': 29518, 'q_loss': 1.7966539859771729, 'mean_q_value': -0.21424925327301025, 'max_q_value': 0.34898442029953003, 'min_q_value': -0.871188223361969, 'mean_td_error': 0.046669863, 'max_td_error': 0.2897594, 'mean_weight': 0.5852442979812622}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7327, -0.8703, -0.7557, -0.8106]], device='cuda:0'), reward is -0.99\n",
      "Episode 716/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 29564, 'eps': 0.0, 'buffer_size': 29564, 'q_loss': 1.7448344230651855, 'mean_q_value': -0.10405468940734863, 'max_q_value': 0.38031402230262756, 'min_q_value': -0.9556354284286499, 'mean_td_error': 0.067941085, 'max_td_error': 0.37342894, 'mean_weight': 0.5539892911911011}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8764, -0.8847, -0.8725, -0.8599]], device='cuda:0'), reward is -0.99\n",
      "Episode 717/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 29609, 'eps': 0.0, 'buffer_size': 29609, 'q_loss': 1.9518417119979858, 'mean_q_value': -0.15515746176242828, 'max_q_value': 0.34700268507003784, 'min_q_value': -0.9454522728919983, 'mean_td_error': 0.049915347, 'max_td_error': 0.17151323, 'mean_weight': 0.6294662356376648}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9305, -0.9012, -0.9216, -0.9104]], device='cuda:0'), reward is -0.99\n",
      "Episode 718/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 29675, 'eps': 0.0, 'buffer_size': 29675, 'q_loss': 1.944663405418396, 'mean_q_value': -0.1645413637161255, 'max_q_value': 0.32890433073043823, 'min_q_value': -0.9619525074958801, 'mean_td_error': 0.040536262, 'max_td_error': 0.18300039, 'mean_weight': 0.6449335813522339}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6211, -0.4665, -0.3077, -0.4740]], device='cuda:0'), reward is -0.99\n",
      "Episode 719/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 29753, 'eps': 0.0, 'buffer_size': 29753, 'q_loss': 1.662501335144043, 'mean_q_value': -0.10671429336071014, 'max_q_value': 0.34811827540397644, 'min_q_value': -0.9491415023803711, 'mean_td_error': 0.04342504, 'max_td_error': 0.24094933, 'mean_weight': 0.5135225653648376}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9504, -0.9589, -0.9627, -0.9481]], device='cuda:0'), reward is -0.99\n",
      "Episode 720/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 29807, 'eps': 0.0, 'buffer_size': 29807, 'q_loss': 1.54206383228302, 'mean_q_value': -0.3225315809249878, 'max_q_value': 0.347734272480011, 'min_q_value': -0.9749915599822998, 'mean_td_error': 0.075807884, 'max_td_error': 0.4057425, 'mean_weight': 0.5803157687187195}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1668, -0.1689, -0.1649, -0.1669]], device='cuda:0'), reward is -0.99\n",
      "Episode 721/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 29847, 'eps': 0.0, 'buffer_size': 29847, 'q_loss': 1.5752800703048706, 'mean_q_value': -0.18744270503520966, 'max_q_value': 0.32513660192489624, 'min_q_value': -0.9151003360748291, 'mean_td_error': 0.05863087, 'max_td_error': 0.22284609, 'mean_weight': 0.49851155281066895}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7976, -0.8062, -0.7810, -0.8243]], device='cuda:0'), reward is -0.99\n",
      "Episode 722/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 29915, 'eps': 0.0, 'buffer_size': 29915, 'q_loss': 1.4839487075805664, 'mean_q_value': -0.19035378098487854, 'max_q_value': 0.32026445865631104, 'min_q_value': -0.8583326935768127, 'mean_td_error': 0.048412945, 'max_td_error': 0.12567708, 'mean_weight': 0.49904534220695496}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9480, -0.9446, -0.9480, -0.9518]], device='cuda:0'), reward is -0.99\n",
      "Episode 723/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 29978, 'eps': 0.0, 'buffer_size': 29978, 'q_loss': 1.6406524181365967, 'mean_q_value': -0.132663756608963, 'max_q_value': 0.3426476716995239, 'min_q_value': -0.920672595500946, 'mean_td_error': 0.06202148, 'max_td_error': 0.30501956, 'mean_weight': 0.5388015508651733}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1140, -0.0836, -0.0160, -0.2010]], device='cuda:0'), reward is -0.99\n",
      "Episode 724/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 30028, 'eps': 0.0, 'buffer_size': 30028, 'q_loss': 1.4547959566116333, 'mean_q_value': -0.27068087458610535, 'max_q_value': 0.36710095405578613, 'min_q_value': -0.9177472591400146, 'mean_td_error': 0.049028724, 'max_td_error': 0.1564494, 'mean_weight': 0.5152564644813538}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7241, -0.7144, -0.7041, -0.7280]], device='cuda:0'), reward is -0.99\n",
      "Episode 725/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 30088, 'eps': 0.0, 'buffer_size': 30088, 'q_loss': 1.6581528186798096, 'mean_q_value': -0.12961982190608978, 'max_q_value': 0.35710179805755615, 'min_q_value': -0.9661113619804382, 'mean_td_error': 0.0512006, 'max_td_error': 0.20719278, 'mean_weight': 0.5197539329528809}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8152, -0.8159, -0.8214, -0.8218]], device='cuda:0'), reward is -0.99\n",
      "Episode 726/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 30145, 'eps': 0.0, 'buffer_size': 30145, 'q_loss': 1.2368698120117188, 'mean_q_value': -0.16703402996063232, 'max_q_value': 0.34987396001815796, 'min_q_value': -0.9494912028312683, 'mean_td_error': 0.04783775, 'max_td_error': 0.3738457, 'mean_weight': 0.3879980444908142}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9314, -0.9181, -0.9187, -0.9436]], device='cuda:0'), reward is -0.99\n",
      "Episode 727/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 30220, 'eps': 0.0, 'buffer_size': 30220, 'q_loss': 1.5623605251312256, 'mean_q_value': -0.25700971484184265, 'max_q_value': 0.32849183678627014, 'min_q_value': -0.958104133605957, 'mean_td_error': 0.07835169, 'max_td_error': 0.47163683, 'mean_weight': 0.5784900188446045}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2932, -0.2512, -0.2844, -0.3402]], device='cuda:0'), reward is -0.99\n",
      "Episode 728/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 30263, 'eps': 0.0, 'buffer_size': 30263, 'q_loss': 1.4626805782318115, 'mean_q_value': -0.16545292735099792, 'max_q_value': 0.3807379901409149, 'min_q_value': -0.9144970178604126, 'mean_td_error': 0.042726118, 'max_td_error': 0.21646291, 'mean_weight': 0.4733973443508148}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4906, -0.4603, -0.5212, -0.4835]], device='cuda:0'), reward is -0.99\n",
      "Episode 729/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 30321, 'eps': 0.0, 'buffer_size': 30321, 'q_loss': 1.6946361064910889, 'mean_q_value': -0.1674003005027771, 'max_q_value': 0.37456685304641724, 'min_q_value': -0.8433022499084473, 'mean_td_error': 0.063912086, 'max_td_error': 0.6988386, 'mean_weight': 0.5578944683074951}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1168, -0.0951, -0.1353, -0.1322]], device='cuda:0'), reward is -0.99\n",
      "Episode 730/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 30375, 'eps': 0.0, 'buffer_size': 30375, 'q_loss': 1.92256498336792, 'mean_q_value': -0.07986575365066528, 'max_q_value': 0.3282923102378845, 'min_q_value': -0.9070018529891968, 'mean_td_error': 0.030711897, 'max_td_error': 0.10317129, 'mean_weight': 0.6202582716941833}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0172, 0.0231, 0.0219, 0.0111]], device='cuda:0'), reward is -0.99\n",
      "Episode 731/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 30445, 'eps': 0.0, 'buffer_size': 30445, 'q_loss': 1.8999590873718262, 'mean_q_value': -0.04601164907217026, 'max_q_value': 0.36108142137527466, 'min_q_value': -0.9312012195587158, 'mean_td_error': 0.037385672, 'max_td_error': 0.09646428, 'mean_weight': 0.5629614591598511}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9393, -0.9252, -0.9237, -0.9380]], device='cuda:0'), reward is -0.99\n",
      "Episode 732/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 30506, 'eps': 0.0, 'buffer_size': 30506, 'q_loss': 1.6286303997039795, 'mean_q_value': -0.1961672455072403, 'max_q_value': 0.32618165016174316, 'min_q_value': -0.8842626214027405, 'mean_td_error': 0.06465393, 'max_td_error': 0.89828694, 'mean_weight': 0.5472331047058105}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2715, -0.2659, -0.2628, -0.2766]], device='cuda:0'), reward is -0.99\n",
      "Episode 733/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 30555, 'eps': 0.0, 'buffer_size': 30555, 'q_loss': 1.5301246643066406, 'mean_q_value': -0.28531932830810547, 'max_q_value': 0.34602510929107666, 'min_q_value': -0.9564189910888672, 'mean_td_error': 0.05621635, 'max_td_error': 0.4597423, 'mean_weight': 0.5639523267745972}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0731, -0.0750, -0.0720, -0.0740]], device='cuda:0'), reward is -0.99\n",
      "Episode 734/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 30571, 'eps': 0.0, 'buffer_size': 30571, 'q_loss': 1.7815499305725098, 'mean_q_value': -0.14797765016555786, 'max_q_value': 0.35619068145751953, 'min_q_value': -0.8735179901123047, 'mean_td_error': 0.040304046, 'max_td_error': 0.14708471, 'mean_weight': 0.5823032855987549}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6575, -0.6400, -0.6679, -0.6894]], device='cuda:0'), reward is -0.99\n",
      "Episode 735/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 30628, 'eps': 0.0, 'buffer_size': 30628, 'q_loss': 0.8847429752349854, 'mean_q_value': -0.0831264927983284, 'max_q_value': 0.3361610174179077, 'min_q_value': -0.8777833580970764, 'mean_td_error': 0.049309745, 'max_td_error': 0.14130956, 'mean_weight': 0.27253058552742004}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9182, -0.9082, -0.9077, -0.9201]], device='cuda:0'), reward is -0.99\n",
      "Episode 736/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 30688, 'eps': 0.0, 'buffer_size': 30688, 'q_loss': 1.5913467407226562, 'mean_q_value': -0.19287526607513428, 'max_q_value': 0.36048734188079834, 'min_q_value': -0.9686927199363708, 'mean_td_error': 0.039054282, 'max_td_error': 0.09814513, 'mean_weight': 0.5202763676643372}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6185, -0.7005, -0.6195, -0.6421]], device='cuda:0'), reward is -0.99\n",
      "Episode 737/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 30746, 'eps': 0.0, 'buffer_size': 30746, 'q_loss': 1.9729351997375488, 'mean_q_value': -0.11954120546579361, 'max_q_value': 0.36871522665023804, 'min_q_value': -0.9286789894104004, 'mean_td_error': 0.038907155, 'max_td_error': 0.11849402, 'mean_weight': 0.6299453973770142}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9202, -0.8752, -0.8749, -0.9226]], device='cuda:0'), reward is -0.99\n",
      "Episode 738/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 30823, 'eps': 0.0, 'buffer_size': 30823, 'q_loss': 1.4433937072753906, 'mean_q_value': -0.1400541067123413, 'max_q_value': 0.3518846035003662, 'min_q_value': -0.8604843020439148, 'mean_td_error': 0.04244061, 'max_td_error': 0.29062524, 'mean_weight': 0.4488902688026428}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5994, -0.5648, -0.5477, -0.5512]], device='cuda:0'), reward is -0.99\n",
      "Episode 739/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 30890, 'eps': 0.0, 'buffer_size': 30890, 'q_loss': 1.2757242918014526, 'mean_q_value': -0.26053285598754883, 'max_q_value': 0.3664591908454895, 'min_q_value': -0.9299827814102173, 'mean_td_error': 0.03472879, 'max_td_error': 0.1382004, 'mean_weight': 0.44959861040115356}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7891, -0.8934, -0.7993, -0.8734]], device='cuda:0'), reward is -0.99\n",
      "Episode 740/1000000: {'total_return': -0.15999999999999948, 'steps': 84, 'total_steps': 30974, 'eps': 0.0, 'buffer_size': 30974, 'q_loss': 1.182153344154358, 'mean_q_value': -0.24733443558216095, 'max_q_value': 0.29538679122924805, 'min_q_value': -0.8991435170173645, 'mean_td_error': 0.067833185, 'max_td_error': 0.30608308, 'mean_weight': 0.41635870933532715}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5356, -0.5265, -0.5455, -0.5612]], device='cuda:0'), reward is -0.99\n",
      "Episode 741/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 31029, 'eps': 0.0, 'buffer_size': 31029, 'q_loss': 1.7560452222824097, 'mean_q_value': -0.12044242024421692, 'max_q_value': 0.30905023217201233, 'min_q_value': -0.875131368637085, 'mean_td_error': 0.0599119, 'max_td_error': 0.27709818, 'mean_weight': 0.5600844621658325}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6046, -0.7536, -0.5879, -0.6440]], device='cuda:0'), reward is -0.99\n",
      "Episode 742/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 31093, 'eps': 0.0, 'buffer_size': 31093, 'q_loss': 1.696419596672058, 'mean_q_value': -0.23451517522335052, 'max_q_value': 0.38452786207199097, 'min_q_value': -0.9437066316604614, 'mean_td_error': 0.07256341, 'max_td_error': 0.6192138, 'mean_weight': 0.6007537841796875}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8926, -0.8626, -0.8627, -0.9024]], device='cuda:0'), reward is -0.99\n",
      "Episode 743/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 31158, 'eps': 0.0, 'buffer_size': 31158, 'q_loss': 1.6496939659118652, 'mean_q_value': -0.14474192261695862, 'max_q_value': 0.3454814851284027, 'min_q_value': -0.9227852821350098, 'mean_td_error': 0.047577493, 'max_td_error': 0.31273368, 'mean_weight': 0.5405805110931396}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6672, -0.6791, -0.6531, -0.6674]], device='cuda:0'), reward is -0.99\n",
      "Episode 744/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 31210, 'eps': 0.0, 'buffer_size': 31210, 'q_loss': 1.444706916809082, 'mean_q_value': -0.1415565013885498, 'max_q_value': 0.3268817961215973, 'min_q_value': -0.8915491104125977, 'mean_td_error': 0.07189391, 'max_td_error': 0.24278116, 'mean_weight': 0.4611501693725586}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3208, -0.2836, -0.2863, -0.2994]], device='cuda:0'), reward is -0.99\n",
      "Episode 745/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 31247, 'eps': 0.0, 'buffer_size': 31247, 'q_loss': 1.295619010925293, 'mean_q_value': -0.23676854372024536, 'max_q_value': 0.31842416524887085, 'min_q_value': -0.9046043753623962, 'mean_td_error': 0.05703323, 'max_td_error': 0.26407164, 'mean_weight': 0.44605115056037903}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5168, -0.5235, -0.5183, -0.5178]], device='cuda:0'), reward is -0.99\n",
      "Episode 746/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 31311, 'eps': 0.0, 'buffer_size': 31311, 'q_loss': 1.1607402563095093, 'mean_q_value': -0.10064242035150528, 'max_q_value': 0.36948245763778687, 'min_q_value': -0.9885631799697876, 'mean_td_error': 0.03830561, 'max_td_error': 0.13370115, 'mean_weight': 0.3604806661605835}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3251, -0.3126, -0.3119, -0.3387]], device='cuda:0'), reward is -0.99\n",
      "Episode 747/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 31377, 'eps': 0.0, 'buffer_size': 31377, 'q_loss': 1.9021377563476562, 'mean_q_value': -0.09271201491355896, 'max_q_value': 0.3545334041118622, 'min_q_value': -0.9915602803230286, 'mean_td_error': 0.042061087, 'max_td_error': 0.18579662, 'mean_weight': 0.599116325378418}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1545, 0.1515, 0.1539, 0.1544]], device='cuda:0'), reward is -0.99\n",
      "Episode 748/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 31403, 'eps': 0.0, 'buffer_size': 31403, 'q_loss': 1.2672460079193115, 'mean_q_value': -0.17701998353004456, 'max_q_value': 0.3477168679237366, 'min_q_value': -0.9652923345565796, 'mean_td_error': 0.056167405, 'max_td_error': 0.3251086, 'mean_weight': 0.4081876873970032}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4811, -0.4728, -0.4708, -0.4752]], device='cuda:0'), reward is -0.99\n",
      "Episode 749/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 31428, 'eps': 0.0, 'buffer_size': 31428, 'q_loss': 1.5935604572296143, 'mean_q_value': -0.11530427634716034, 'max_q_value': 0.35163789987564087, 'min_q_value': -0.9872373938560486, 'mean_td_error': 0.04451044, 'max_td_error': 0.16773877, 'mean_weight': 0.5075401663780212}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3128, -0.3154, -0.3134, -0.3133]], device='cuda:0'), reward is -0.99\n",
      "Episode 750/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 31463, 'eps': 0.0, 'buffer_size': 31463, 'q_loss': 1.4800076484680176, 'mean_q_value': -0.15471932291984558, 'max_q_value': 0.34502747654914856, 'min_q_value': -0.8807347416877747, 'mean_td_error': 0.050017774, 'max_td_error': 0.26386094, 'mean_weight': 0.47952425479888916}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0624, 0.0445, 0.0617, 0.0597]], device='cuda:0'), reward is -0.99\n",
      "Episode 751/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 31503, 'eps': 0.0, 'buffer_size': 31503, 'q_loss': 1.5231752395629883, 'mean_q_value': -0.18067073822021484, 'max_q_value': 0.355009526014328, 'min_q_value': -0.9565865993499756, 'mean_td_error': 0.056200847, 'max_td_error': 0.2850321, 'mean_weight': 0.5088982582092285}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9166, -0.8951, -0.8627, -0.8743]], device='cuda:0'), reward is -0.99\n",
      "Episode 752/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 31571, 'eps': 0.0, 'buffer_size': 31571, 'q_loss': 1.6149489879608154, 'mean_q_value': -0.11649163067340851, 'max_q_value': 0.3674258887767792, 'min_q_value': -0.9416356682777405, 'mean_td_error': 0.040761814, 'max_td_error': 0.15760478, 'mean_weight': 0.5242723226547241}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8854, -0.8564, -0.8574, -0.8767]], device='cuda:0'), reward is -0.99\n",
      "Episode 753/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 31629, 'eps': 0.0, 'buffer_size': 31629, 'q_loss': 1.3638386726379395, 'mean_q_value': -0.15947982668876648, 'max_q_value': 0.3435385227203369, 'min_q_value': -0.934815526008606, 'mean_td_error': 0.0506961, 'max_td_error': 0.23593423, 'mean_weight': 0.43673956394195557}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3213, -0.3237, -0.3157, -0.3129]], device='cuda:0'), reward is -0.99\n",
      "Episode 754/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 31669, 'eps': 0.0, 'buffer_size': 31669, 'q_loss': 1.4832184314727783, 'mean_q_value': -0.1808709055185318, 'max_q_value': 0.37558865547180176, 'min_q_value': -0.875347375869751, 'mean_td_error': 0.047115825, 'max_td_error': 0.20230106, 'mean_weight': 0.48188796639442444}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6752, -0.6274, -0.6275, -0.6818]], device='cuda:0'), reward is -0.99\n",
      "Episode 755/1000000: {'total_return': -0.13999999999999946, 'steps': 86, 'total_steps': 31755, 'eps': 0.0, 'buffer_size': 31755, 'q_loss': 1.813692569732666, 'mean_q_value': -0.13680914044380188, 'max_q_value': 0.3436698913574219, 'min_q_value': -0.7351389527320862, 'mean_td_error': 0.06270893, 'max_td_error': 0.42895174, 'mean_weight': 0.555782675743103}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9638, -0.9425, -0.9471, -0.9667]], device='cuda:0'), reward is -0.99\n",
      "Episode 756/1000000: {'total_return': -0.01999999999999935, 'steps': 98, 'total_steps': 31853, 'eps': 0.0, 'buffer_size': 31853, 'q_loss': 1.5117971897125244, 'mean_q_value': -0.2334776073694229, 'max_q_value': 0.37730079889297485, 'min_q_value': -0.9387531876564026, 'mean_td_error': 0.038888626, 'max_td_error': 0.26007855, 'mean_weight': 0.5475559234619141}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6239, -0.5750, -0.5773, -0.6010]], device='cuda:0'), reward is -0.99\n",
      "Episode 757/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 31910, 'eps': 0.0, 'buffer_size': 31910, 'q_loss': 1.6048283576965332, 'mean_q_value': -0.18211814761161804, 'max_q_value': 0.36137712001800537, 'min_q_value': -0.9428912997245789, 'mean_td_error': 0.042844646, 'max_td_error': 0.19406044, 'mean_weight': 0.528873085975647}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6283, -0.5110, -0.5132, -0.5931]], device='cuda:0'), reward is -0.99\n",
      "Episode 758/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 31947, 'eps': 0.0, 'buffer_size': 31947, 'q_loss': 0.9144953489303589, 'mean_q_value': -0.08616488426923752, 'max_q_value': 0.36105015873908997, 'min_q_value': -0.9518230557441711, 'mean_td_error': 0.032882497, 'max_td_error': 0.15462182, 'mean_weight': 0.2830554246902466}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2707, -0.2676, -0.2756, -0.2850]], device='cuda:0'), reward is -0.99\n",
      "Episode 759/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 31980, 'eps': 0.0, 'buffer_size': 31980, 'q_loss': 1.8280104398727417, 'mean_q_value': -0.15875504910945892, 'max_q_value': 0.3851887881755829, 'min_q_value': -0.9527466893196106, 'mean_td_error': 0.058872163, 'max_td_error': 0.15244597, 'mean_weight': 0.5816900730133057}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8240, -0.7719, -0.7655, -0.8121]], device='cuda:0'), reward is -0.99\n",
      "Episode 760/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 32047, 'eps': 0.0, 'buffer_size': 32047, 'q_loss': 1.6260305643081665, 'mean_q_value': -0.23323407769203186, 'max_q_value': 0.3355301022529602, 'min_q_value': -0.9323243498802185, 'mean_td_error': 0.051444255, 'max_td_error': 0.19204119, 'mean_weight': 0.5748387575149536}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9540, -0.9337, -0.9572, -0.9690]], device='cuda:0'), reward is -0.99\n",
      "Episode 761/1000000: {'total_return': -0.14999999999999947, 'steps': 85, 'total_steps': 32132, 'eps': 0.0, 'buffer_size': 32132, 'q_loss': 0.7322291731834412, 'mean_q_value': -0.1022278442978859, 'max_q_value': 0.35192450881004333, 'min_q_value': -0.9766141772270203, 'mean_td_error': 0.0424821, 'max_td_error': 0.14117642, 'mean_weight': 0.23043914139270782}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9600, -0.9388, -0.9161, -0.9351]], device='cuda:0'), reward is -0.99\n",
      "Episode 762/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 32200, 'eps': 0.0, 'buffer_size': 32200, 'q_loss': 1.6295509338378906, 'mean_q_value': -0.23719581961631775, 'max_q_value': 0.3643248379230499, 'min_q_value': -0.8771533370018005, 'mean_td_error': 0.074817054, 'max_td_error': 0.31693107, 'mean_weight': 0.5659806728363037}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8155, -0.7765, -0.7801, -0.8047]], device='cuda:0'), reward is -0.99\n",
      "Episode 763/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 32258, 'eps': 0.0, 'buffer_size': 32258, 'q_loss': 1.5365629196166992, 'mean_q_value': -0.13630321621894836, 'max_q_value': 0.31636613607406616, 'min_q_value': -0.921416163444519, 'mean_td_error': 0.043384627, 'max_td_error': 0.123385936, 'mean_weight': 0.47303318977355957}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8947, -0.8180, -0.8206, -0.8535]], device='cuda:0'), reward is -0.99\n",
      "Episode 764/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 32327, 'eps': 0.0, 'buffer_size': 32327, 'q_loss': 1.4951775074005127, 'mean_q_value': -0.12903434038162231, 'max_q_value': 0.3522471785545349, 'min_q_value': -0.9018435478210449, 'mean_td_error': 0.042078912, 'max_td_error': 0.11189814, 'mean_weight': 0.46653446555137634}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7399, -0.7434, -0.7243, -0.7378]], device='cuda:0'), reward is -0.99\n",
      "Episode 765/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 32395, 'eps': 0.0, 'buffer_size': 32395, 'q_loss': 1.342882752418518, 'mean_q_value': -0.23263761401176453, 'max_q_value': 0.3372023403644562, 'min_q_value': -0.9144326448440552, 'mean_td_error': 0.053058945, 'max_td_error': 0.2247492, 'mean_weight': 0.45006170868873596}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7942, -0.6532, -0.6669, -0.8447]], device='cuda:0'), reward is -0.99\n",
      "Episode 766/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 32460, 'eps': 0.0, 'buffer_size': 32460, 'q_loss': 1.5216779708862305, 'mean_q_value': -0.16760069131851196, 'max_q_value': 0.355038583278656, 'min_q_value': -0.8839104771614075, 'mean_td_error': 0.057717532, 'max_td_error': 0.2944988, 'mean_weight': 0.5066757202148438}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4804, -0.3979, -0.4059, -0.4406]], device='cuda:0'), reward is -0.99\n",
      "Episode 767/1000000: {'total_return': -0.15999999999999948, 'steps': 84, 'total_steps': 32544, 'eps': 0.0, 'buffer_size': 32544, 'q_loss': 1.5933195352554321, 'mean_q_value': -0.17242449522018433, 'max_q_value': 0.35995399951934814, 'min_q_value': -0.9271838068962097, 'mean_td_error': 0.05823958, 'max_td_error': 0.51312697, 'mean_weight': 0.5195483565330505}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3052, -0.2686, -0.2741, -0.2880]], device='cuda:0'), reward is -0.99\n",
      "Episode 768/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 32580, 'eps': 0.0, 'buffer_size': 32580, 'q_loss': 1.663379192352295, 'mean_q_value': -0.13036613166332245, 'max_q_value': 0.37586337327957153, 'min_q_value': -0.9045196771621704, 'mean_td_error': 0.06103651, 'max_td_error': 0.3628049, 'mean_weight': 0.5498150587081909}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9615, -0.9517, -0.9416, -0.9572]], device='cuda:0'), reward is -0.99\n",
      "Episode 769/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 32642, 'eps': 0.0, 'buffer_size': 32642, 'q_loss': 1.1328295469284058, 'mean_q_value': -0.17106465995311737, 'max_q_value': 0.35637664794921875, 'min_q_value': -0.9242434501647949, 'mean_td_error': 0.04333297, 'max_td_error': 0.20094094, 'mean_weight': 0.3692607879638672}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2074, -0.2515, -0.2588, -0.6738]], device='cuda:0'), reward is -0.99\n",
      "Episode 770/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 32664, 'eps': 0.0, 'buffer_size': 32664, 'q_loss': 1.6325719356536865, 'mean_q_value': -0.13673706352710724, 'max_q_value': 0.37591660022735596, 'min_q_value': -0.8453953862190247, 'mean_td_error': 0.05696889, 'max_td_error': 0.22434318, 'mean_weight': 0.5118275880813599}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6008, -0.6550, -0.6007, -0.5961]], device='cuda:0'), reward is -0.99\n",
      "Episode 771/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 32703, 'eps': 0.0, 'buffer_size': 32703, 'q_loss': 1.433356523513794, 'mean_q_value': -0.0913684293627739, 'max_q_value': 0.37196946144104004, 'min_q_value': -0.8995822072029114, 'mean_td_error': 0.05646177, 'max_td_error': 0.29907158, 'mean_weight': 0.4484737515449524}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3123, -0.4178, -0.3595, -0.3613]], device='cuda:0'), reward is -0.99\n",
      "Episode 772/1000000: {'total_return': -0.10999999999999943, 'steps': 89, 'total_steps': 32792, 'eps': 0.0, 'buffer_size': 32792, 'q_loss': 1.1316360235214233, 'mean_q_value': -0.11956046521663666, 'max_q_value': 0.35211181640625, 'min_q_value': -0.967781126499176, 'mean_td_error': 0.04464353, 'max_td_error': 0.16526315, 'mean_weight': 0.35520055890083313}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8799, -0.8830, -0.8794, -0.9041]], device='cuda:0'), reward is -0.99\n",
      "Episode 773/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 32858, 'eps': 0.0, 'buffer_size': 32858, 'q_loss': 1.712540626525879, 'mean_q_value': -0.1331721395254135, 'max_q_value': 0.3641971945762634, 'min_q_value': -0.886296272277832, 'mean_td_error': 0.036407, 'max_td_error': 0.12613389, 'mean_weight': 0.5566545128822327}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9798, -0.9793, -0.9813, -0.9822]], device='cuda:0'), reward is -0.99\n",
      "Episode 774/1000000: {'total_return': -0.0699999999999994, 'steps': 93, 'total_steps': 32951, 'eps': 0.0, 'buffer_size': 32951, 'q_loss': 1.3875370025634766, 'mean_q_value': -0.21345876157283783, 'max_q_value': 0.3596755266189575, 'min_q_value': -0.9606474041938782, 'mean_td_error': 0.049700312, 'max_td_error': 0.29219362, 'mean_weight': 0.48489847779273987}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5710, -0.5901, -0.5582, -0.5366]], device='cuda:0'), reward is -0.99\n",
      "Episode 775/1000000: {'total_return': -0.10999999999999943, 'steps': 89, 'total_steps': 33040, 'eps': 0.0, 'buffer_size': 33040, 'q_loss': 1.7415536642074585, 'mean_q_value': -0.2000322937965393, 'max_q_value': 0.3772258162498474, 'min_q_value': -0.9284372329711914, 'mean_td_error': 0.08652231, 'max_td_error': 0.40100121, 'mean_weight': 0.5720957517623901}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7517, -0.7033, -0.7101, -0.7496]], device='cuda:0'), reward is -0.99\n",
      "Episode 776/1000000: {'total_return': -0.6399999999999999, 'steps': 36, 'total_steps': 33076, 'eps': 0.0, 'buffer_size': 33076, 'q_loss': 1.69893217086792, 'mean_q_value': -0.14326584339141846, 'max_q_value': 0.3533502221107483, 'min_q_value': -0.9089208841323853, 'mean_td_error': 0.057910185, 'max_td_error': 0.3406281, 'mean_weight': 0.5472390651702881}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7077, -0.5808, -0.5456, -0.6478]], device='cuda:0'), reward is -0.99\n",
      "Episode 777/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 33097, 'eps': 0.0, 'buffer_size': 33097, 'q_loss': 1.5821540355682373, 'mean_q_value': -0.09320850670337677, 'max_q_value': 0.3454328179359436, 'min_q_value': -0.8566128611564636, 'mean_td_error': 0.041217305, 'max_td_error': 0.2459788, 'mean_weight': 0.5094625949859619}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1131, -0.1389, -0.1161, -0.1198]], device='cuda:0'), reward is -0.99\n",
      "Episode 778/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 33126, 'eps': 0.0, 'buffer_size': 33126, 'q_loss': 1.2402396202087402, 'mean_q_value': -0.24773775041103363, 'max_q_value': 0.3497079610824585, 'min_q_value': -0.9581741094589233, 'mean_td_error': 0.04291702, 'max_td_error': 0.1595555, 'mean_weight': 0.42584341764450073}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0501, -0.0539, -0.0512, -0.0522]], device='cuda:0'), reward is -0.99\n",
      "Episode 779/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 33155, 'eps': 0.0, 'buffer_size': 33155, 'q_loss': 1.5916051864624023, 'mean_q_value': -0.2404956817626953, 'max_q_value': 0.3821401000022888, 'min_q_value': -0.900100588798523, 'mean_td_error': 0.0649417, 'max_td_error': 0.2571048, 'mean_weight': 0.5509777069091797}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6298, -0.7101, -0.6383, -0.6696]], device='cuda:0'), reward is -0.99\n",
      "Episode 780/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 33198, 'eps': 0.0, 'buffer_size': 33198, 'q_loss': 1.8175671100616455, 'mean_q_value': -0.12004698812961578, 'max_q_value': 0.359415739774704, 'min_q_value': -0.8742819428443909, 'mean_td_error': 0.08025779, 'max_td_error': 0.6835943, 'mean_weight': 0.5772967338562012}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5259, -0.4746, -0.4661, -0.5120]], device='cuda:0'), reward is -0.99\n",
      "Episode 781/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 33250, 'eps': 0.0, 'buffer_size': 33250, 'q_loss': 1.8778862953186035, 'mean_q_value': -0.139929860830307, 'max_q_value': 0.3433821499347687, 'min_q_value': -0.9557055830955505, 'mean_td_error': 0.046558425, 'max_td_error': 0.15479027, 'mean_weight': 0.6130107641220093}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9812, -0.9643, -0.9541, -0.9681]], device='cuda:0'), reward is -0.99\n",
      "Episode 782/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 33324, 'eps': 0.0, 'buffer_size': 33324, 'q_loss': 1.5209927558898926, 'mean_q_value': -0.13446739315986633, 'max_q_value': 0.37720242142677307, 'min_q_value': -0.940574049949646, 'mean_td_error': 0.0403305, 'max_td_error': 0.2028366, 'mean_weight': 0.5061501264572144}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9088, -0.8749, -0.8794, -0.8766]], device='cuda:0'), reward is -0.99\n",
      "Episode 783/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 33355, 'eps': 0.0, 'buffer_size': 33355, 'q_loss': 1.4270960092544556, 'mean_q_value': -0.1029050350189209, 'max_q_value': 0.3676396608352661, 'min_q_value': -0.9864712357521057, 'mean_td_error': 0.06529714, 'max_td_error': 0.7239423, 'mean_weight': 0.4672469198703766}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9381, -0.9283, -0.9185, -0.9276]], device='cuda:0'), reward is -0.99\n",
      "Episode 784/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 33390, 'eps': 0.0, 'buffer_size': 33390, 'q_loss': 1.3944458961486816, 'mean_q_value': -0.1719578504562378, 'max_q_value': 0.3659612536430359, 'min_q_value': -0.9685646295547485, 'mean_td_error': 0.03468006, 'max_td_error': 0.107421935, 'mean_weight': 0.4586222171783447}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0228,  0.0200,  0.0668, -0.0595]], device='cuda:0'), reward is -0.99\n",
      "Episode 785/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 33457, 'eps': 0.0, 'buffer_size': 33457, 'q_loss': 1.5996754169464111, 'mean_q_value': -0.26914316415786743, 'max_q_value': 0.38093119859695435, 'min_q_value': -0.9525886178016663, 'mean_td_error': 0.055222705, 'max_td_error': 0.4769131, 'mean_weight': 0.5793696641921997}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6615, -0.6440, -0.6046, -0.6208]], device='cuda:0'), reward is -0.99\n",
      "Episode 786/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 33525, 'eps': 0.0, 'buffer_size': 33525, 'q_loss': 1.3760437965393066, 'mean_q_value': -0.16759298741817474, 'max_q_value': 0.3602163791656494, 'min_q_value': -0.8999022841453552, 'mean_td_error': 0.069746494, 'max_td_error': 0.53500056, 'mean_weight': 0.45479342341423035}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0638, -0.0229, -0.0193, -0.0105]], device='cuda:0'), reward is -0.99\n",
      "Episode 787/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 33557, 'eps': 0.0, 'buffer_size': 33557, 'q_loss': 1.329815149307251, 'mean_q_value': -0.12477514147758484, 'max_q_value': 0.37095579504966736, 'min_q_value': -0.9455532431602478, 'mean_td_error': 0.045981377, 'max_td_error': 0.16507763, 'mean_weight': 0.43676960468292236}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5109, -0.4743, -0.4714, -0.4881]], device='cuda:0'), reward is -0.99\n",
      "Episode 788/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 33609, 'eps': 0.0, 'buffer_size': 33609, 'q_loss': 1.808516263961792, 'mean_q_value': -0.157012939453125, 'max_q_value': 0.3579377830028534, 'min_q_value': -0.9135764837265015, 'mean_td_error': 0.03803462, 'max_td_error': 0.14446715, 'mean_weight': 0.61795973777771}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9338, -0.9344, -0.9207, -0.9283]], device='cuda:0'), reward is -0.99\n",
      "Episode 789/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 33687, 'eps': 0.0, 'buffer_size': 33687, 'q_loss': 1.51864492893219, 'mean_q_value': -0.08890483528375626, 'max_q_value': 0.40327924489974976, 'min_q_value': -0.9533225297927856, 'mean_td_error': 0.041601826, 'max_td_error': 0.18519911, 'mean_weight': 0.4834287762641907}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0258, -0.1150,  0.0164,  0.0184]], device='cuda:0'), reward is -0.99\n",
      "Episode 790/1000000: {'total_return': -0.7599999999999999, 'steps': 24, 'total_steps': 33711, 'eps': 0.0, 'buffer_size': 33711, 'q_loss': 1.468705654144287, 'mean_q_value': -0.21236863732337952, 'max_q_value': 0.3795308470726013, 'min_q_value': -0.9243993759155273, 'mean_td_error': 0.072346784, 'max_td_error': 0.8150725, 'mean_weight': 0.5148958563804626}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9664, -0.9471, -0.9356, -0.9583]], device='cuda:0'), reward is -0.99\n",
      "Episode 791/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 33773, 'eps': 0.0, 'buffer_size': 33773, 'q_loss': 1.3644993305206299, 'mean_q_value': -0.1865839958190918, 'max_q_value': 0.38605213165283203, 'min_q_value': -0.9446916580200195, 'mean_td_error': 0.054427885, 'max_td_error': 0.22823882, 'mean_weight': 0.4871162176132202}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0186,  0.0202,  0.0195, -0.1025]], device='cuda:0'), reward is -0.99\n",
      "Episode 792/1000000: {'total_return': -0.87, 'steps': 13, 'total_steps': 33786, 'eps': 0.0, 'buffer_size': 33786, 'q_loss': 1.7948014736175537, 'mean_q_value': -0.1329440474510193, 'max_q_value': 0.3750060200691223, 'min_q_value': -0.8913055658340454, 'mean_td_error': 0.043014124, 'max_td_error': 0.2410399, 'mean_weight': 0.568415641784668}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9338, -0.9189, -0.8733, -0.8820]], device='cuda:0'), reward is -0.99\n",
      "Episode 793/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 33849, 'eps': 0.0, 'buffer_size': 33849, 'q_loss': 1.3407979011535645, 'mean_q_value': -0.2671550512313843, 'max_q_value': 0.3514719605445862, 'min_q_value': -0.9374987483024597, 'mean_td_error': 0.046291605, 'max_td_error': 0.21288848, 'mean_weight': 0.47995874285697937}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1828, -0.1793, -0.2187, -0.3370]], device='cuda:0'), reward is -0.99\n",
      "Episode 794/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 33910, 'eps': 0.0, 'buffer_size': 33910, 'q_loss': 1.7547450065612793, 'mean_q_value': -0.14683181047439575, 'max_q_value': 0.34447720646858215, 'min_q_value': -0.9509528875350952, 'mean_td_error': 0.03614748, 'max_td_error': 0.144651, 'mean_weight': 0.576974630355835}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8410, -0.8228, -0.7876, -0.8000]], device='cuda:0'), reward is -0.99\n",
      "Episode 795/1000000: {'total_return': -0.2899999999999996, 'steps': 71, 'total_steps': 33981, 'eps': 0.0, 'buffer_size': 33981, 'q_loss': 2.075942277908325, 'mean_q_value': -0.124256931245327, 'max_q_value': 0.3741104006767273, 'min_q_value': -0.8761739134788513, 'mean_td_error': 0.055998687, 'max_td_error': 0.19934276, 'mean_weight': 0.693338930606842}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4313, -0.4262, -0.4264, -0.4375]], device='cuda:0'), reward is -0.99\n",
      "Episode 796/1000000: {'total_return': 0.06000000000000072, 'steps': 106, 'total_steps': 34087, 'eps': 0.0, 'buffer_size': 34087, 'q_loss': 1.2108039855957031, 'mean_q_value': -0.15472294390201569, 'max_q_value': 0.3531996011734009, 'min_q_value': -0.93830406665802, 'mean_td_error': 0.033019323, 'max_td_error': 0.13967478, 'mean_weight': 0.400937557220459}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4755, -0.4145, -0.4221, -0.4753]], device='cuda:0'), reward is -0.99\n",
      "Episode 797/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 34162, 'eps': 0.0, 'buffer_size': 34162, 'q_loss': 1.0153557062149048, 'mean_q_value': -0.2747318148612976, 'max_q_value': 0.3243962526321411, 'min_q_value': -1.011527180671692, 'mean_td_error': 0.041377548, 'max_td_error': 0.1404072, 'mean_weight': 0.3728606700897217}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6667, -0.6617, -0.6589, -0.6729]], device='cuda:0'), reward is -0.99\n",
      "Episode 798/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 34224, 'eps': 0.0, 'buffer_size': 34224, 'q_loss': 1.259943962097168, 'mean_q_value': -0.09754911810159683, 'max_q_value': 0.36074864864349365, 'min_q_value': -0.9690308570861816, 'mean_td_error': 0.03983719, 'max_td_error': 0.11536613, 'mean_weight': 0.39669105410575867}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6723, -0.6724, -0.6705, -0.6740]], device='cuda:0'), reward is -0.99\n",
      "Episode 799/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 34291, 'eps': 0.0, 'buffer_size': 34291, 'q_loss': 1.5777117013931274, 'mean_q_value': -0.1899648755788803, 'max_q_value': 0.3537050783634186, 'min_q_value': -0.9081510305404663, 'mean_td_error': 0.042140525, 'max_td_error': 0.120247036, 'mean_weight': 0.4973846673965454}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7322, -0.6474, -0.6137, -0.6496]], device='cuda:0'), reward is -0.99\n",
      "Episode 800/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 34336, 'eps': 0.0, 'buffer_size': 34336, 'q_loss': 1.63575279712677, 'mean_q_value': -0.21394576132297516, 'max_q_value': 0.3832435607910156, 'min_q_value': -0.9450152516365051, 'mean_td_error': 0.050189745, 'max_td_error': 0.23589844, 'mean_weight': 0.5377099514007568}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6408, -0.6279, -0.6309, -0.6765]], device='cuda:0'), reward is -0.99\n",
      "Episode 801/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 34379, 'eps': 0.0, 'buffer_size': 34379, 'q_loss': 1.4737677574157715, 'mean_q_value': -0.08484578132629395, 'max_q_value': 0.37873345613479614, 'min_q_value': -0.8030950427055359, 'mean_td_error': 0.04810297, 'max_td_error': 0.2625581, 'mean_weight': 0.4613789916038513}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3609, -0.3204, -0.3455, -0.3120]], device='cuda:0'), reward is -0.99\n",
      "Episode 802/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 34436, 'eps': 0.0, 'buffer_size': 34436, 'q_loss': 1.3291029930114746, 'mean_q_value': -0.21086305379867554, 'max_q_value': 0.39694756269454956, 'min_q_value': -0.9501461386680603, 'mean_td_error': 0.036395736, 'max_td_error': 0.1397698, 'mean_weight': 0.47744664549827576}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4734, -0.4753, -0.4728, -0.4750]], device='cuda:0'), reward is -0.99\n",
      "Episode 803/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 34471, 'eps': 0.0, 'buffer_size': 34471, 'q_loss': 1.420661211013794, 'mean_q_value': -0.2636386752128601, 'max_q_value': 0.33965134620666504, 'min_q_value': -0.9062725305557251, 'mean_td_error': 0.057417206, 'max_td_error': 0.24600226, 'mean_weight': 0.500838041305542}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9139, -0.9155, -0.8902, -0.9156]], device='cuda:0'), reward is -0.99\n",
      "Episode 804/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 34524, 'eps': 0.0, 'buffer_size': 34524, 'q_loss': 1.855347752571106, 'mean_q_value': -0.16454529762268066, 'max_q_value': 0.37342768907546997, 'min_q_value': -0.9211136698722839, 'mean_td_error': 0.053898804, 'max_td_error': 0.2318666, 'mean_weight': 0.6253336668014526}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4912, -0.5250, -0.5158, -0.4913]], device='cuda:0'), reward is -0.99\n",
      "Episode 805/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 34571, 'eps': 0.0, 'buffer_size': 34571, 'q_loss': 1.5214766263961792, 'mean_q_value': -0.21373631060123444, 'max_q_value': 0.355469286441803, 'min_q_value': -0.9554651975631714, 'mean_td_error': 0.053208493, 'max_td_error': 0.3771169, 'mean_weight': 0.5382609963417053}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7752, -0.7428, -0.8219, -0.7803]], device='cuda:0'), reward is -0.99\n",
      "Episode 806/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 34644, 'eps': 0.0, 'buffer_size': 34644, 'q_loss': 1.2464876174926758, 'mean_q_value': -0.19800755381584167, 'max_q_value': 0.38026073575019836, 'min_q_value': -0.8937467336654663, 'mean_td_error': 0.05498305, 'max_td_error': 0.24409574, 'mean_weight': 0.4078940153121948}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7274, -0.7217, -0.7188, -0.7403]], device='cuda:0'), reward is -0.99\n",
      "Episode 807/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 34703, 'eps': 0.0, 'buffer_size': 34703, 'q_loss': 1.3903257846832275, 'mean_q_value': -0.2712748050689697, 'max_q_value': 0.3887251615524292, 'min_q_value': -0.9069147109985352, 'mean_td_error': 0.08750087, 'max_td_error': 0.25644234, 'mean_weight': 0.5227756500244141}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3120, -0.2333, -0.2373, -0.2755]], device='cuda:0'), reward is -0.99\n",
      "Episode 808/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 34746, 'eps': 0.0, 'buffer_size': 34746, 'q_loss': 1.5797412395477295, 'mean_q_value': -0.2459505945444107, 'max_q_value': 0.3421471416950226, 'min_q_value': -0.967170000076294, 'mean_td_error': 0.06709956, 'max_td_error': 0.35090697, 'mean_weight': 0.564266562461853}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1362, -0.1316, -0.1248, -0.1607]], device='cuda:0'), reward is -0.99\n",
      "Episode 809/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 34768, 'eps': 0.0, 'buffer_size': 34768, 'q_loss': 1.4558517932891846, 'mean_q_value': -0.0931970551609993, 'max_q_value': 0.3753511309623718, 'min_q_value': -0.9204168319702148, 'mean_td_error': 0.043084923, 'max_td_error': 0.18070602, 'mean_weight': 0.45992565155029297}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7947, -0.7637, -0.7666, -0.7927]], device='cuda:0'), reward is -0.99\n",
      "Episode 810/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 34831, 'eps': 0.0, 'buffer_size': 34831, 'q_loss': 1.860020637512207, 'mean_q_value': -0.11999617516994476, 'max_q_value': 0.362248957157135, 'min_q_value': -0.8245038986206055, 'mean_td_error': 0.04647689, 'max_td_error': 0.22773018, 'mean_weight': 0.6043077111244202}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4356, -0.4610, -0.4351, -0.4755]], device='cuda:0'), reward is -0.99\n",
      "Episode 811/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 34866, 'eps': 0.0, 'buffer_size': 34866, 'q_loss': 1.8257207870483398, 'mean_q_value': -0.18693792819976807, 'max_q_value': 0.3683534264564514, 'min_q_value': -0.9509515762329102, 'mean_td_error': 0.05475617, 'max_td_error': 0.24262023, 'mean_weight': 0.6177940964698792}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6938, -0.6931, -0.6903, -0.7049]], device='cuda:0'), reward is -0.99\n",
      "Episode 812/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 34931, 'eps': 0.0, 'buffer_size': 34931, 'q_loss': 0.877440333366394, 'mean_q_value': -0.2608582377433777, 'max_q_value': 0.3709689974784851, 'min_q_value': -0.8780065178871155, 'mean_td_error': 0.04502125, 'max_td_error': 0.19891334, 'mean_weight': 0.3094061017036438}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4237, -0.4156, -0.4094, -0.4359]], device='cuda:0'), reward is -0.99\n",
      "Episode 813/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 34960, 'eps': 0.0, 'buffer_size': 34960, 'q_loss': 1.1082513332366943, 'mean_q_value': -0.21031665802001953, 'max_q_value': 0.34686753153800964, 'min_q_value': -0.9784762263298035, 'mean_td_error': 0.047898397, 'max_td_error': 0.27146623, 'mean_weight': 0.3747047781944275}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9638, -0.9334, -0.9318, -0.9553]], device='cuda:0'), reward is -0.99\n",
      "Episode 814/1000000: {'total_return': -0.09999999999999942, 'steps': 90, 'total_steps': 35050, 'eps': 0.0, 'buffer_size': 35050, 'q_loss': 1.4342801570892334, 'mean_q_value': -0.15947377681732178, 'max_q_value': 0.38255375623703003, 'min_q_value': -0.9732523560523987, 'mean_td_error': 0.043953836, 'max_td_error': 0.13978648, 'mean_weight': 0.47533512115478516}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5149, -0.5564, -0.4426, -0.4142]], device='cuda:0'), reward is -0.99\n",
      "Episode 815/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 35090, 'eps': 0.0, 'buffer_size': 35090, 'q_loss': 1.5483729839324951, 'mean_q_value': -0.1829964816570282, 'max_q_value': 0.35807493329048157, 'min_q_value': -0.9601327776908875, 'mean_td_error': 0.04761021, 'max_td_error': 0.20794237, 'mean_weight': 0.5228957533836365}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4881, -0.4900, -0.4779, -0.4844]], device='cuda:0'), reward is -0.99\n",
      "Episode 816/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 35149, 'eps': 0.0, 'buffer_size': 35149, 'q_loss': 1.6859577894210815, 'mean_q_value': -0.09513270854949951, 'max_q_value': 0.3794865310192108, 'min_q_value': -0.9007047414779663, 'mean_td_error': 0.032157302, 'max_td_error': 0.11125624, 'mean_weight': 0.5221171379089355}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7659, -0.7603, -0.7184, -0.7303]], device='cuda:0'), reward is -0.99\n",
      "Episode 817/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 35225, 'eps': 0.0, 'buffer_size': 35225, 'q_loss': 1.7290774583816528, 'mean_q_value': -0.1406317502260208, 'max_q_value': 0.39572739601135254, 'min_q_value': -0.9332829117774963, 'mean_td_error': 0.043579318, 'max_td_error': 0.2227807, 'mean_weight': 0.5698645114898682}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8927, -0.8576, -0.8321, -0.8664]], device='cuda:0'), reward is -0.99\n",
      "Episode 818/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 35289, 'eps': 0.0, 'buffer_size': 35289, 'q_loss': 2.0452466011047363, 'mean_q_value': -0.08330664038658142, 'max_q_value': 0.3383420407772064, 'min_q_value': -0.9834129214286804, 'mean_td_error': 0.028285258, 'max_td_error': 0.13806772, 'mean_weight': 0.6673464179039001}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3115, -0.2903, -0.2703, -0.2659]], device='cuda:0'), reward is -0.99\n",
      "Episode 819/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 35326, 'eps': 0.0, 'buffer_size': 35326, 'q_loss': 1.8864045143127441, 'mean_q_value': -0.08474457263946533, 'max_q_value': 0.38390472531318665, 'min_q_value': -0.8757331967353821, 'mean_td_error': 0.06045086, 'max_td_error': 0.40867996, 'mean_weight': 0.5921415090560913}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0083,  0.0282,  0.0579,  0.0536]], device='cuda:0'), reward is -0.99\n",
      "Episode 820/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 35370, 'eps': 0.0, 'buffer_size': 35370, 'q_loss': 1.6571693420410156, 'mean_q_value': -0.24142980575561523, 'max_q_value': 0.35862061381340027, 'min_q_value': -0.9784626960754395, 'mean_td_error': 0.06605473, 'max_td_error': 0.21767811, 'mean_weight': 0.6017147302627563}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0241,  0.0132,  0.0200, -0.1093]], device='cuda:0'), reward is -0.99\n",
      "Episode 821/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 35390, 'eps': 0.0, 'buffer_size': 35390, 'q_loss': 1.7498648166656494, 'mean_q_value': -0.09895689785480499, 'max_q_value': 0.38439851999282837, 'min_q_value': -0.8579170107841492, 'mean_td_error': 0.041919697, 'max_td_error': 0.17811278, 'mean_weight': 0.5642368793487549}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8768, -0.8397, -0.8348, -0.8491]], device='cuda:0'), reward is -0.99\n",
      "Episode 822/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 35460, 'eps': 0.0, 'buffer_size': 35460, 'q_loss': 1.4911673069000244, 'mean_q_value': -0.17831939458847046, 'max_q_value': 0.3633562922477722, 'min_q_value': -0.8878210186958313, 'mean_td_error': 0.03942795, 'max_td_error': 0.15262699, 'mean_weight': 0.49250203371047974}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5840, -0.4833, -0.4687, -0.5047]], device='cuda:0'), reward is -0.99\n",
      "Episode 823/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 35504, 'eps': 0.0, 'buffer_size': 35504, 'q_loss': 1.7272025346755981, 'mean_q_value': -0.18891304731369019, 'max_q_value': 0.3865705728530884, 'min_q_value': -0.9845468401908875, 'mean_td_error': 0.085494526, 'max_td_error': 1.0696435, 'mean_weight': 0.6131384372711182}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8808, -0.8642, -0.8537, -0.8574]], device='cuda:0'), reward is -0.99\n",
      "Episode 824/1000000: {'total_return': -0.10999999999999943, 'steps': 89, 'total_steps': 35593, 'eps': 0.0, 'buffer_size': 35593, 'q_loss': 1.4154714345932007, 'mean_q_value': -0.16416551172733307, 'max_q_value': 0.34716689586639404, 'min_q_value': -0.9281486868858337, 'mean_td_error': 0.04049688, 'max_td_error': 0.16952223, 'mean_weight': 0.4708678126335144}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7720, -0.7411, -0.7567, -0.7554]], device='cuda:0'), reward is -0.99\n",
      "Episode 825/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 35660, 'eps': 0.0, 'buffer_size': 35660, 'q_loss': 1.734156608581543, 'mean_q_value': -0.22386077046394348, 'max_q_value': 0.38242650032043457, 'min_q_value': -1.0077840089797974, 'mean_td_error': 0.04069397, 'max_td_error': 0.13953513, 'mean_weight': 0.5830299854278564}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0366, 0.0763, 0.0722, 0.0209]], device='cuda:0'), reward is -0.99\n",
      "Episode 826/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 35708, 'eps': 0.0, 'buffer_size': 35708, 'q_loss': 1.6650419235229492, 'mean_q_value': -0.23678578436374664, 'max_q_value': 0.35297685861587524, 'min_q_value': -0.966599702835083, 'mean_td_error': 0.045352265, 'max_td_error': 0.1646674, 'mean_weight': 0.5772252082824707}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7062, -0.7077, -0.7047, -0.7074]], device='cuda:0'), reward is -0.99\n",
      "Episode 827/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 35761, 'eps': 0.0, 'buffer_size': 35761, 'q_loss': 0.9024990797042847, 'mean_q_value': -0.0799083411693573, 'max_q_value': 0.34769922494888306, 'min_q_value': -0.9085842370986938, 'mean_td_error': 0.043040924, 'max_td_error': 0.20458305, 'mean_weight': 0.28155502676963806}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5181, -0.4194, -0.4276, -0.4520]], device='cuda:0'), reward is -0.99\n",
      "Episode 828/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 35813, 'eps': 0.0, 'buffer_size': 35813, 'q_loss': 0.992850661277771, 'mean_q_value': -0.2400904893875122, 'max_q_value': 0.3194952607154846, 'min_q_value': -0.8983452916145325, 'mean_td_error': 0.060382992, 'max_td_error': 0.2161414, 'mean_weight': 0.37150031328201294}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8901, -0.8909, -0.8900, -0.8915]], device='cuda:0'), reward is -0.99\n",
      "Episode 829/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 35877, 'eps': 0.0, 'buffer_size': 35877, 'q_loss': 1.5108731985092163, 'mean_q_value': -0.19995218515396118, 'max_q_value': 0.4030234217643738, 'min_q_value': -0.91791170835495, 'mean_td_error': 0.06829888, 'max_td_error': 0.49881247, 'mean_weight': 0.5199224948883057}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0703, -0.0922, -0.0826, -0.0974]], device='cuda:0'), reward is -0.99\n",
      "Episode 830/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 35929, 'eps': 0.0, 'buffer_size': 35929, 'q_loss': 1.868039846420288, 'mean_q_value': -0.16800029575824738, 'max_q_value': 0.38434046506881714, 'min_q_value': -0.9173725843429565, 'mean_td_error': 0.059633873, 'max_td_error': 0.69538677, 'mean_weight': 0.650080680847168}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5826, -0.5536, -0.5409, -0.5725]], device='cuda:0'), reward is -0.99\n",
      "Episode 831/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 35999, 'eps': 0.0, 'buffer_size': 35999, 'q_loss': 1.7103042602539062, 'mean_q_value': -0.21009375154972076, 'max_q_value': 0.37976616621017456, 'min_q_value': -0.9526263475418091, 'mean_td_error': 0.047358986, 'max_td_error': 0.19499613, 'mean_weight': 0.6150246858596802}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0529, 0.0505, 0.0555, 0.0531]], device='cuda:0'), reward is -0.99\n",
      "Episode 832/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 36039, 'eps': 0.0, 'buffer_size': 36039, 'q_loss': 1.6822543144226074, 'mean_q_value': -0.15488538146018982, 'max_q_value': 0.3763285279273987, 'min_q_value': -0.9283909201622009, 'mean_td_error': 0.05754001, 'max_td_error': 0.2149651, 'mean_weight': 0.5747982263565063}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4042, -0.3643, -0.3488, -0.3930]], device='cuda:0'), reward is -0.99\n",
      "Episode 833/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 36080, 'eps': 0.0, 'buffer_size': 36080, 'q_loss': 1.4595615863800049, 'mean_q_value': -0.13616327941417694, 'max_q_value': 0.35946181416511536, 'min_q_value': -0.9264295697212219, 'mean_td_error': 0.049139015, 'max_td_error': 0.19577539, 'mean_weight': 0.46970388293266296}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7342, -0.7343, -0.8159, -0.7674]], device='cuda:0'), reward is -0.99\n",
      "Episode 834/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 36141, 'eps': 0.0, 'buffer_size': 36141, 'q_loss': 1.310849666595459, 'mean_q_value': -0.2740498483181, 'max_q_value': 0.4083547592163086, 'min_q_value': -0.916493833065033, 'mean_td_error': 0.065329686, 'max_td_error': 0.36479986, 'mean_weight': 0.4716317653656006}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6503, -0.6357, -0.6327, -0.6461]], device='cuda:0'), reward is -0.99\n",
      "Episode 835/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 36189, 'eps': 0.0, 'buffer_size': 36189, 'q_loss': 1.5565532445907593, 'mean_q_value': -0.17339038848876953, 'max_q_value': 0.38460615277290344, 'min_q_value': -0.8532782793045044, 'mean_td_error': 0.050389897, 'max_td_error': 0.22183254, 'mean_weight': 0.5284270644187927}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0126,  0.0065, -0.0074, -0.0235]], device='cuda:0'), reward is -0.99\n",
      "Episode 836/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 36207, 'eps': 0.0, 'buffer_size': 36207, 'q_loss': 1.8574409484863281, 'mean_q_value': -0.22002872824668884, 'max_q_value': 0.3753555417060852, 'min_q_value': -0.9384149312973022, 'mean_td_error': 0.04118815, 'max_td_error': 0.12373704, 'mean_weight': 0.6894224882125854}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5892, -0.5884, -0.5910, -0.6037]], device='cuda:0'), reward is -0.99\n",
      "Episode 837/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 36257, 'eps': 0.0, 'buffer_size': 36257, 'q_loss': 1.644266963005066, 'mean_q_value': -0.13327370584011078, 'max_q_value': 0.3353375196456909, 'min_q_value': -0.9220563769340515, 'mean_td_error': 0.06280637, 'max_td_error': 0.26199752, 'mean_weight': 0.5275120735168457}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5499, -0.4258, -0.3821, -0.4659]], device='cuda:0'), reward is -0.99\n",
      "Episode 838/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 36312, 'eps': 0.0, 'buffer_size': 36312, 'q_loss': 1.2556993961334229, 'mean_q_value': -0.16090592741966248, 'max_q_value': 0.37097877264022827, 'min_q_value': -0.8983784317970276, 'mean_td_error': 0.04377529, 'max_td_error': 0.22646195, 'mean_weight': 0.41897183656692505}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0663, 0.0797, 0.0798, 0.0782]], device='cuda:0'), reward is -0.99\n",
      "Episode 839/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 36352, 'eps': 0.0, 'buffer_size': 36352, 'q_loss': 0.8964534997940063, 'mean_q_value': -0.2088075429201126, 'max_q_value': 0.3457261323928833, 'min_q_value': -0.9025982022285461, 'mean_td_error': 0.046125013, 'max_td_error': 0.3198772, 'mean_weight': 0.3086439371109009}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4498, -0.4489, -0.4455, -0.4639]], device='cuda:0'), reward is -0.99\n",
      "Episode 840/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 36410, 'eps': 0.0, 'buffer_size': 36410, 'q_loss': 1.5359143018722534, 'mean_q_value': -0.20303788781166077, 'max_q_value': 0.4316917955875397, 'min_q_value': -0.9279323816299438, 'mean_td_error': 0.04956659, 'max_td_error': 0.24321872, 'mean_weight': 0.521510660648346}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8734, -0.8601, -0.8533, -0.8544]], device='cuda:0'), reward is -0.99\n",
      "Episode 841/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 36473, 'eps': 0.0, 'buffer_size': 36473, 'q_loss': 1.5948450565338135, 'mean_q_value': -0.2552805244922638, 'max_q_value': 0.3940192461013794, 'min_q_value': -0.9082038402557373, 'mean_td_error': 0.043115184, 'max_td_error': 0.24798557, 'mean_weight': 0.5707913637161255}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2873, -0.2122, -0.1979, -0.2418]], device='cuda:0'), reward is -0.99\n",
      "Episode 842/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 36515, 'eps': 0.0, 'buffer_size': 36515, 'q_loss': 1.6315126419067383, 'mean_q_value': -0.18229401111602783, 'max_q_value': 0.3774917721748352, 'min_q_value': -0.9100949764251709, 'mean_td_error': 0.045383055, 'max_td_error': 0.17012084, 'mean_weight': 0.564939022064209}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9807, -0.9625, -0.9668, -0.9603]], device='cuda:0'), reward is -0.99\n",
      "Episode 843/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 36566, 'eps': 0.0, 'buffer_size': 36566, 'q_loss': 1.1296350955963135, 'mean_q_value': -0.1749916672706604, 'max_q_value': 0.3845279812812805, 'min_q_value': -0.9671145081520081, 'mean_td_error': 0.049915608, 'max_td_error': 0.18232742, 'mean_weight': 0.378542423248291}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8425, -0.8424, -0.8414, -0.8502]], device='cuda:0'), reward is -0.99\n",
      "Episode 844/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 36616, 'eps': 0.0, 'buffer_size': 36616, 'q_loss': 1.7477257251739502, 'mean_q_value': -0.19429902732372284, 'max_q_value': 0.3787745237350464, 'min_q_value': -0.9826900362968445, 'mean_td_error': 0.058052614, 'max_td_error': 0.45077318, 'mean_weight': 0.6052951216697693}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6419, -0.6261, -0.6225, -0.6839]], device='cuda:0'), reward is -0.99\n",
      "Episode 845/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 36670, 'eps': 0.0, 'buffer_size': 36670, 'q_loss': 1.5379412174224854, 'mean_q_value': -0.2529487609863281, 'max_q_value': 0.3849294185638428, 'min_q_value': -0.9271733164787292, 'mean_td_error': 0.055780686, 'max_td_error': 0.15773761, 'mean_weight': 0.5530315041542053}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5921, -0.4984, -0.4978, -0.5021]], device='cuda:0'), reward is -0.99\n",
      "Episode 846/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 36713, 'eps': 0.0, 'buffer_size': 36713, 'q_loss': 1.3582956790924072, 'mean_q_value': -0.2270156443119049, 'max_q_value': 0.37393683195114136, 'min_q_value': -0.8898290991783142, 'mean_td_error': 0.040204108, 'max_td_error': 0.21826455, 'mean_weight': 0.49006980657577515}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8137, -0.7854, -0.7863, -0.8032]], device='cuda:0'), reward is -0.99\n",
      "Episode 847/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 36772, 'eps': 0.0, 'buffer_size': 36772, 'q_loss': 1.659462332725525, 'mean_q_value': -0.31642842292785645, 'max_q_value': 0.3933565616607666, 'min_q_value': -0.9289418458938599, 'mean_td_error': 0.0397616, 'max_td_error': 0.13277614, 'mean_weight': 0.6266289949417114}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4533, -0.2537, -0.2894, -0.2776]], device='cuda:0'), reward is -0.99\n",
      "Episode 848/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 36832, 'eps': 0.0, 'buffer_size': 36832, 'q_loss': 1.4985175132751465, 'mean_q_value': -0.1894376277923584, 'max_q_value': 0.3568647503852844, 'min_q_value': -0.8682188987731934, 'mean_td_error': 0.044016108, 'max_td_error': 0.17146474, 'mean_weight': 0.5239640474319458}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9432, -0.9424, -0.9414, -0.9492]], device='cuda:0'), reward is -0.99\n",
      "Episode 849/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 36877, 'eps': 0.0, 'buffer_size': 36877, 'q_loss': 1.5926034450531006, 'mean_q_value': -0.22827500104904175, 'max_q_value': 0.3796136975288391, 'min_q_value': -0.9575123190879822, 'mean_td_error': 0.04583256, 'max_td_error': 0.18322769, 'mean_weight': 0.5623160600662231}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6944, -0.6881, -0.6868, -0.6999]], device='cuda:0'), reward is -0.99\n",
      "Episode 850/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 36931, 'eps': 0.0, 'buffer_size': 36931, 'q_loss': 1.329543113708496, 'mean_q_value': -0.019100192934274673, 'max_q_value': 0.3698732554912567, 'min_q_value': -0.9249803423881531, 'mean_td_error': 0.042292062, 'max_td_error': 0.17264917, 'mean_weight': 0.4117962419986725}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5129, -0.4997, -0.4986, -0.5188]], device='cuda:0'), reward is -0.99\n",
      "Episode 851/1000000: {'total_return': -0.16999999999999948, 'steps': 83, 'total_steps': 37014, 'eps': 0.0, 'buffer_size': 37014, 'q_loss': 1.5763565301895142, 'mean_q_value': -0.17198669910430908, 'max_q_value': 0.37584108114242554, 'min_q_value': -0.8920515775680542, 'mean_td_error': 0.05871901, 'max_td_error': 0.39737904, 'mean_weight': 0.550082802772522}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8492, -0.8244, -0.8306, -0.8522]], device='cuda:0'), reward is -0.99\n",
      "Episode 852/1000000: {'total_return': -0.09999999999999942, 'steps': 90, 'total_steps': 37104, 'eps': 0.0, 'buffer_size': 37104, 'q_loss': 1.3663749694824219, 'mean_q_value': -0.17999276518821716, 'max_q_value': 0.3851117491722107, 'min_q_value': -0.9046144485473633, 'mean_td_error': 0.040270492, 'max_td_error': 0.107860595, 'mean_weight': 0.4566859006881714}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8555, -0.8560, -0.8557, -0.8569]], device='cuda:0'), reward is -0.99\n",
      "Episode 853/1000000: {'total_return': -0.1799999999999995, 'steps': 82, 'total_steps': 37186, 'eps': 0.0, 'buffer_size': 37186, 'q_loss': 0.9090928435325623, 'mean_q_value': -0.1486874371767044, 'max_q_value': 0.3656691014766693, 'min_q_value': -0.9224612712860107, 'mean_td_error': 0.057442285, 'max_td_error': 0.30510718, 'mean_weight': 0.29825636744499207}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7858, -0.7824, -0.7873, -0.7837]], device='cuda:0'), reward is -0.99\n",
      "Episode 854/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 37250, 'eps': 0.0, 'buffer_size': 37250, 'q_loss': 1.6649069786071777, 'mean_q_value': -0.17655476927757263, 'max_q_value': 0.4057382643222809, 'min_q_value': -0.930324137210846, 'mean_td_error': 0.06013463, 'max_td_error': 0.37747374, 'mean_weight': 0.5636489391326904}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3952, -0.3969, -0.3946, -0.3971]], device='cuda:0'), reward is -0.99\n",
      "Episode 855/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 37301, 'eps': 0.0, 'buffer_size': 37301, 'q_loss': 1.7287182807922363, 'mean_q_value': -0.2274790108203888, 'max_q_value': 0.3779771029949188, 'min_q_value': -0.9084507822990417, 'mean_td_error': 0.0638814, 'max_td_error': 0.20075582, 'mean_weight': 0.6106985807418823}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.0760, -0.0222,  0.0987,  0.1006]], device='cuda:0'), reward is -0.99\n",
      "Episode 856/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 37342, 'eps': 0.0, 'buffer_size': 37342, 'q_loss': 1.4591474533081055, 'mean_q_value': -0.09323377907276154, 'max_q_value': 0.3576967418193817, 'min_q_value': -0.8345335721969604, 'mean_td_error': 0.04311107, 'max_td_error': 0.12969488, 'mean_weight': 0.4652286767959595}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1399, 0.1385, 0.1413, 0.1390]], device='cuda:0'), reward is -0.99\n",
      "Episode 857/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 37396, 'eps': 0.0, 'buffer_size': 37396, 'q_loss': 1.4677022695541382, 'mean_q_value': -0.18388141691684723, 'max_q_value': 0.38779979944229126, 'min_q_value': -0.9542512893676758, 'mean_td_error': 0.05704023, 'max_td_error': 0.17109618, 'mean_weight': 0.5003823041915894}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8287, -0.8035, -0.7951, -0.7974]], device='cuda:0'), reward is -0.99\n",
      "Episode 858/1000000: {'total_return': -0.1899999999999995, 'steps': 81, 'total_steps': 37477, 'eps': 0.0, 'buffer_size': 37477, 'q_loss': 1.1592390537261963, 'mean_q_value': -0.2757836580276489, 'max_q_value': 0.36380672454833984, 'min_q_value': -0.9330821633338928, 'mean_td_error': 0.06443707, 'max_td_error': 0.2710917, 'mean_weight': 0.41837048530578613}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9624, -0.9590, -0.9458, -0.9468]], device='cuda:0'), reward is -0.99\n",
      "Episode 859/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 37525, 'eps': 0.0, 'buffer_size': 37525, 'q_loss': 1.2627085447311401, 'mean_q_value': -0.17005985975265503, 'max_q_value': 0.4032791554927826, 'min_q_value': -0.8693399429321289, 'mean_td_error': 0.04551875, 'max_td_error': 0.27405703, 'mean_weight': 0.41153770685195923}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0236,  0.0006,  0.0095,  0.0114]], device='cuda:0'), reward is -0.99\n",
      "Episode 860/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 37572, 'eps': 0.0, 'buffer_size': 37572, 'q_loss': 1.2458529472351074, 'mean_q_value': -0.0887986570596695, 'max_q_value': 0.40443748235702515, 'min_q_value': -0.9370891451835632, 'mean_td_error': 0.052123033, 'max_td_error': 0.32592303, 'mean_weight': 0.40215322375297546}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6845, -0.6855, -0.6840, -0.6863]], device='cuda:0'), reward is -0.99\n",
      "Episode 861/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 37639, 'eps': 0.0, 'buffer_size': 37639, 'q_loss': 1.4010868072509766, 'mean_q_value': -0.07779723405838013, 'max_q_value': 0.405550092458725, 'min_q_value': -0.9705823659896851, 'mean_td_error': 0.042103603, 'max_td_error': 0.19064006, 'mean_weight': 0.4554358720779419}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9388, -0.9300, -0.9388, -0.9476]], device='cuda:0'), reward is -0.99\n",
      "Episode 862/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 37713, 'eps': 0.0, 'buffer_size': 37713, 'q_loss': 1.6568868160247803, 'mean_q_value': -0.2042275071144104, 'max_q_value': 0.40849000215530396, 'min_q_value': -0.9156025052070618, 'mean_td_error': 0.043959275, 'max_td_error': 0.25505984, 'mean_weight': 0.5769716501235962}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2625, -0.2965, -0.1868, -0.1844]], device='cuda:0'), reward is -0.99\n",
      "Episode 863/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 37739, 'eps': 0.0, 'buffer_size': 37739, 'q_loss': 1.6109282970428467, 'mean_q_value': -0.1398421972990036, 'max_q_value': 0.38661229610443115, 'min_q_value': -0.9943240880966187, 'mean_td_error': 0.044109896, 'max_td_error': 0.20722339, 'mean_weight': 0.5326349139213562}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7169, -0.7305, -0.7157, -0.7206]], device='cuda:0'), reward is -0.99\n",
      "Episode 864/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 37799, 'eps': 0.0, 'buffer_size': 37799, 'q_loss': 1.571192741394043, 'mean_q_value': -0.17339080572128296, 'max_q_value': 0.4253959059715271, 'min_q_value': -0.9675032496452332, 'mean_td_error': 0.0391837, 'max_td_error': 0.11152181, 'mean_weight': 0.5366484522819519}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0460, -0.0211, -0.0690, -0.1058]], device='cuda:0'), reward is -0.99\n",
      "Episode 865/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 37844, 'eps': 0.0, 'buffer_size': 37844, 'q_loss': 1.480262279510498, 'mean_q_value': -0.15458491444587708, 'max_q_value': 0.4091992974281311, 'min_q_value': -0.967125415802002, 'mean_td_error': 0.044594426, 'max_td_error': 0.13893342, 'mean_weight': 0.48727959394454956}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7152, -0.7319, -0.6780, -0.6811]], device='cuda:0'), reward is -0.99\n",
      "Episode 866/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 37903, 'eps': 0.0, 'buffer_size': 37903, 'q_loss': 1.3968743085861206, 'mean_q_value': -0.23518070578575134, 'max_q_value': 0.3749236464500427, 'min_q_value': -0.9663105010986328, 'mean_td_error': 0.05243003, 'max_td_error': 0.16099131, 'mean_weight': 0.4780135154724121}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5472, -0.5308, -0.5197, -0.5793]], device='cuda:0'), reward is -0.99\n",
      "Episode 867/1000000: {'total_return': 0.020000000000000684, 'steps': 102, 'total_steps': 38005, 'eps': 0.0, 'buffer_size': 38005, 'q_loss': 1.1817817687988281, 'mean_q_value': -0.192554771900177, 'max_q_value': 0.3899672031402588, 'min_q_value': -0.979205310344696, 'mean_td_error': 0.059398424, 'max_td_error': 0.55519706, 'mean_weight': 0.39916643500328064}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8401, -0.8394, -0.8439, -0.8224]], device='cuda:0'), reward is -0.99\n",
      "Episode 868/1000000: {'total_return': 0.370000000000001, 'steps': 137, 'total_steps': 38142, 'eps': 0.0, 'buffer_size': 38142, 'q_loss': 1.1582872867584229, 'mean_q_value': -0.3058652877807617, 'max_q_value': 0.3770933151245117, 'min_q_value': -1.0061366558074951, 'mean_td_error': 0.058055792, 'max_td_error': 0.2592067, 'mean_weight': 0.44167107343673706}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2080, -0.3687, -0.2260, -0.2600]], device='cuda:0'), reward is -0.99\n",
      "Episode 869/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 38194, 'eps': 0.0, 'buffer_size': 38194, 'q_loss': 1.5178024768829346, 'mean_q_value': -0.19513949751853943, 'max_q_value': 0.36133816838264465, 'min_q_value': -0.8487869501113892, 'mean_td_error': 0.052062463, 'max_td_error': 0.20688778, 'mean_weight': 0.5148137807846069}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6847, -0.6863, -0.6846, -0.6875]], device='cuda:0'), reward is -0.99\n",
      "Episode 870/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 38244, 'eps': 0.0, 'buffer_size': 38244, 'q_loss': 2.2774229049682617, 'mean_q_value': -0.17814017832279205, 'max_q_value': 0.34818243980407715, 'min_q_value': -0.9465265274047852, 'mean_td_error': 0.036471568, 'max_td_error': 0.12495045, 'mean_weight': 0.7624073028564453}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6688, -0.6598, -0.6674, -0.6923]], device='cuda:0'), reward is -0.99\n",
      "Episode 871/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 38298, 'eps': 0.0, 'buffer_size': 38298, 'q_loss': 1.7853622436523438, 'mean_q_value': -0.101932093501091, 'max_q_value': 0.3394254148006439, 'min_q_value': -0.8782718181610107, 'mean_td_error': 0.03711483, 'max_td_error': 0.16616547, 'mean_weight': 0.5821013450622559}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5543, -0.2339, -0.2333, -0.3198]], device='cuda:0'), reward is -0.99\n",
      "Episode 872/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 38350, 'eps': 0.0, 'buffer_size': 38350, 'q_loss': 1.6850873231887817, 'mean_q_value': -0.13251863420009613, 'max_q_value': 0.38629573583602905, 'min_q_value': -0.9536173939704895, 'mean_td_error': 0.036237728, 'max_td_error': 0.14461926, 'mean_weight': 0.5706164240837097}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6407, -0.6264, -0.6537, -0.6719]], device='cuda:0'), reward is -0.99\n",
      "Episode 873/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 38406, 'eps': 0.0, 'buffer_size': 38406, 'q_loss': 1.6324968338012695, 'mean_q_value': -0.09499120712280273, 'max_q_value': 0.3858070969581604, 'min_q_value': -0.9702034592628479, 'mean_td_error': 0.048830606, 'max_td_error': 0.21651217, 'mean_weight': 0.5267543196678162}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8162, -0.8002, -0.7848, -0.7892]], device='cuda:0'), reward is -0.99\n",
      "Episode 874/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 38474, 'eps': 0.0, 'buffer_size': 38474, 'q_loss': 1.5650794506072998, 'mean_q_value': -0.19571062922477722, 'max_q_value': 0.32942861318588257, 'min_q_value': -0.94524747133255, 'mean_td_error': 0.055392597, 'max_td_error': 0.33647925, 'mean_weight': 0.5435264110565186}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8784, -0.7995, -0.8241, -0.8308]], device='cuda:0'), reward is -0.99\n",
      "Episode 875/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 38526, 'eps': 0.0, 'buffer_size': 38526, 'q_loss': 1.6910643577575684, 'mean_q_value': -0.17777124047279358, 'max_q_value': 0.38320356607437134, 'min_q_value': -0.8163001537322998, 'mean_td_error': 0.044570714, 'max_td_error': 0.1586147, 'mean_weight': 0.5704351663589478}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0832, -0.0573, -0.0488, -0.0660]], device='cuda:0'), reward is -0.99\n",
      "Episode 876/1000000: {'total_return': -0.20999999999999952, 'steps': 79, 'total_steps': 38605, 'eps': 0.0, 'buffer_size': 38605, 'q_loss': 1.7784881591796875, 'mean_q_value': -0.1814926713705063, 'max_q_value': 0.34175050258636475, 'min_q_value': -0.9467010498046875, 'mean_td_error': 0.06774688, 'max_td_error': 0.336687, 'mean_weight': 0.6115656495094299}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4235, -0.4531, -0.4234, -0.4300]], device='cuda:0'), reward is -0.99\n",
      "Episode 877/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 38657, 'eps': 0.0, 'buffer_size': 38657, 'q_loss': 1.5967570543289185, 'mean_q_value': -0.15578968822956085, 'max_q_value': 0.38408875465393066, 'min_q_value': -0.8474767804145813, 'mean_td_error': 0.048206486, 'max_td_error': 0.2807082, 'mean_weight': 0.5393691658973694}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9144, -0.8934, -0.8940, -0.9069]], device='cuda:0'), reward is -0.99\n",
      "Episode 878/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 38719, 'eps': 0.0, 'buffer_size': 38719, 'q_loss': 1.3217519521713257, 'mean_q_value': -0.15943017601966858, 'max_q_value': 0.4292692542076111, 'min_q_value': -0.919694721698761, 'mean_td_error': 0.030582216, 'max_td_error': 0.14453973, 'mean_weight': 0.43514418601989746}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9258, -0.9260, -0.9155, -0.9197]], device='cuda:0'), reward is -0.99\n",
      "Episode 879/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 38772, 'eps': 0.0, 'buffer_size': 38772, 'q_loss': 1.4759840965270996, 'mean_q_value': -0.18620318174362183, 'max_q_value': 0.39862120151519775, 'min_q_value': -0.9591015577316284, 'mean_td_error': 0.04513989, 'max_td_error': 0.22752815, 'mean_weight': 0.5186415314674377}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5021, -0.4489, -0.4264, -0.4492]], device='cuda:0'), reward is -0.99\n",
      "Episode 880/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 38798, 'eps': 0.0, 'buffer_size': 38798, 'q_loss': 1.7655930519104004, 'mean_q_value': -0.2748068869113922, 'max_q_value': 0.3981071710586548, 'min_q_value': -0.9823398590087891, 'mean_td_error': 0.05761318, 'max_td_error': 0.20543712, 'mean_weight': 0.6186342239379883}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9400, -0.9146, -0.9046, -0.9384]], device='cuda:0'), reward is -0.99\n",
      "Episode 881/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 38854, 'eps': 0.0, 'buffer_size': 38854, 'q_loss': 1.3833431005477905, 'mean_q_value': -0.1505376696586609, 'max_q_value': 0.391061007976532, 'min_q_value': -0.752839982509613, 'mean_td_error': 0.05791239, 'max_td_error': 0.2361367, 'mean_weight': 0.4551515579223633}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5431, -0.4907, -0.4644, -0.4685]], device='cuda:0'), reward is -0.99\n",
      "Episode 882/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 38905, 'eps': 0.0, 'buffer_size': 38905, 'q_loss': 1.61604642868042, 'mean_q_value': -0.18802356719970703, 'max_q_value': 0.3688693940639496, 'min_q_value': -0.8852083086967468, 'mean_td_error': 0.040144324, 'max_td_error': 0.1536533, 'mean_weight': 0.5639888048171997}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1958, -0.1988, -0.2123, -0.2273]], device='cuda:0'), reward is -0.99\n",
      "Episode 883/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 38928, 'eps': 0.0, 'buffer_size': 38928, 'q_loss': 1.517815113067627, 'mean_q_value': -0.20157097280025482, 'max_q_value': 0.403114378452301, 'min_q_value': -0.9456422328948975, 'mean_td_error': 0.05169291, 'max_td_error': 0.13729602, 'mean_weight': 0.5194558501243591}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4838, -0.5470, -0.4826, -0.4967]], device='cuda:0'), reward is -0.99\n",
      "Episode 884/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 38974, 'eps': 0.0, 'buffer_size': 38974, 'q_loss': 1.6374166011810303, 'mean_q_value': -0.16151081025600433, 'max_q_value': 0.4085150957107544, 'min_q_value': -0.9461191892623901, 'mean_td_error': 0.063213386, 'max_td_error': 0.35586563, 'mean_weight': 0.5590015053749084}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5188, -0.5051, -0.5045, -0.5107]], device='cuda:0'), reward is -0.99\n",
      "Episode 885/1000000: {'total_return': -0.45999999999999974, 'steps': 54, 'total_steps': 39028, 'eps': 0.0, 'buffer_size': 39028, 'q_loss': 1.233069896697998, 'mean_q_value': -0.09861936420202255, 'max_q_value': 0.4022141098976135, 'min_q_value': -0.8956964015960693, 'mean_td_error': 0.048893996, 'max_td_error': 0.25322944, 'mean_weight': 0.4069383144378662}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3226, -0.3196, -0.3168, -0.3349]], device='cuda:0'), reward is -0.99\n",
      "Episode 886/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 39103, 'eps': 0.0, 'buffer_size': 39103, 'q_loss': 1.4920754432678223, 'mean_q_value': -0.1774754375219345, 'max_q_value': 0.369098424911499, 'min_q_value': -0.9604925513267517, 'mean_td_error': 0.02756069, 'max_td_error': 0.14888275, 'mean_weight': 0.5369963645935059}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7527, -0.7439, -0.7044, -0.7404]], device='cuda:0'), reward is -0.99\n",
      "Episode 887/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 39171, 'eps': 0.0, 'buffer_size': 39171, 'q_loss': 1.5707545280456543, 'mean_q_value': -0.12378531694412231, 'max_q_value': 0.37156370282173157, 'min_q_value': -0.9440137147903442, 'mean_td_error': 0.041477073, 'max_td_error': 0.18085706, 'mean_weight': 0.5265332460403442}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4275, -0.3936, -0.4037, -0.4085]], device='cuda:0'), reward is -0.99\n",
      "Episode 888/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 39193, 'eps': 0.0, 'buffer_size': 39193, 'q_loss': 1.4179966449737549, 'mean_q_value': -0.14464181661605835, 'max_q_value': 0.38925668597221375, 'min_q_value': -0.974294126033783, 'mean_td_error': 0.040106416, 'max_td_error': 0.21069223, 'mean_weight': 0.47849583625793457}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8623, -0.8152, -0.7944, -0.8367]], device='cuda:0'), reward is -0.99\n",
      "Episode 889/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 39255, 'eps': 0.0, 'buffer_size': 39255, 'q_loss': 1.3240203857421875, 'mean_q_value': -0.20389588177204132, 'max_q_value': 0.3728894889354706, 'min_q_value': -0.8687708377838135, 'mean_td_error': 0.05475171, 'max_td_error': 0.24133289, 'mean_weight': 0.4482506513595581}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8263, -0.8596, -0.8199, -0.8674]], device='cuda:0'), reward is -0.99\n",
      "Episode 890/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 39300, 'eps': 0.0, 'buffer_size': 39300, 'q_loss': 1.9212630987167358, 'mean_q_value': -0.1447153389453888, 'max_q_value': 0.3817817270755768, 'min_q_value': -0.8833631873130798, 'mean_td_error': 0.07146718, 'max_td_error': 0.56260794, 'mean_weight': 0.6443353891372681}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7131, -0.7093, -0.7281, -0.7309]], device='cuda:0'), reward is -0.99\n",
      "Episode 891/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 39360, 'eps': 0.0, 'buffer_size': 39360, 'q_loss': 1.4092392921447754, 'mean_q_value': -0.20198071002960205, 'max_q_value': 0.3760017156600952, 'min_q_value': -0.9328940510749817, 'mean_td_error': 0.0505615, 'max_td_error': 0.20940945, 'mean_weight': 0.475375235080719}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1846, -0.1615, -0.1827, -0.2140]], device='cuda:0'), reward is -0.99\n",
      "Episode 892/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 39409, 'eps': 0.0, 'buffer_size': 39409, 'q_loss': 1.5822279453277588, 'mean_q_value': -0.22641834616661072, 'max_q_value': 0.43143200874328613, 'min_q_value': -0.9095349907875061, 'mean_td_error': 0.06861712, 'max_td_error': 0.5700389, 'mean_weight': 0.5580294728279114}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8774, -0.8487, -0.8508, -0.8691]], device='cuda:0'), reward is -0.99\n",
      "Episode 893/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 39481, 'eps': 0.0, 'buffer_size': 39481, 'q_loss': 1.5236282348632812, 'mean_q_value': -0.13808542490005493, 'max_q_value': 0.39076435565948486, 'min_q_value': -0.9174904823303223, 'mean_td_error': 0.055433743, 'max_td_error': 0.20179164, 'mean_weight': 0.4891531467437744}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9434, -0.9224, -0.9193, -0.9557]], device='cuda:0'), reward is -0.99\n",
      "Episode 894/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 39540, 'eps': 0.0, 'buffer_size': 39540, 'q_loss': 1.8764764070510864, 'mean_q_value': -0.21023797988891602, 'max_q_value': 0.37603840231895447, 'min_q_value': -0.9277928471565247, 'mean_td_error': 0.054396763, 'max_td_error': 0.22843355, 'mean_weight': 0.670865535736084}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8548, -0.8042, -0.8124, -0.8551]], device='cuda:0'), reward is -0.99\n",
      "Episode 895/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 39599, 'eps': 0.0, 'buffer_size': 39599, 'q_loss': 1.7279314994812012, 'mean_q_value': -0.21175606548786163, 'max_q_value': 0.33934783935546875, 'min_q_value': -0.9753907322883606, 'mean_td_error': 0.0557435, 'max_td_error': 0.20774335, 'mean_weight': 0.6306058168411255}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8387, -0.8163, -0.7967, -0.8186]], device='cuda:0'), reward is -0.99\n",
      "Episode 896/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 39673, 'eps': 0.0, 'buffer_size': 39673, 'q_loss': 1.2303094863891602, 'mean_q_value': -0.09688861668109894, 'max_q_value': 0.38426709175109863, 'min_q_value': -0.9891929626464844, 'mean_td_error': 0.04277861, 'max_td_error': 0.21385258, 'mean_weight': 0.4017249643802643}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7642, -0.6865, -0.6890, -0.7381]], device='cuda:0'), reward is -0.99\n",
      "Episode 897/1000000: {'total_return': -0.01999999999999935, 'steps': 98, 'total_steps': 39771, 'eps': 0.0, 'buffer_size': 39771, 'q_loss': 1.6115436553955078, 'mean_q_value': -0.11550000309944153, 'max_q_value': 0.39214274287223816, 'min_q_value': -0.8846096992492676, 'mean_td_error': 0.028666256, 'max_td_error': 0.1341742, 'mean_weight': 0.5179597735404968}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8650, -0.8361, -0.8379, -0.8629]], device='cuda:0'), reward is -0.99\n",
      "Episode 898/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 39843, 'eps': 0.0, 'buffer_size': 39843, 'q_loss': 1.8273581266403198, 'mean_q_value': -0.13277633488178253, 'max_q_value': 0.38716983795166016, 'min_q_value': -0.9320585131645203, 'mean_td_error': 0.035405073, 'max_td_error': 0.13843718, 'mean_weight': 0.593791127204895}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8116, -0.7933, -0.7928, -0.8027]], device='cuda:0'), reward is -0.99\n",
      "Episode 899/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 39909, 'eps': 0.0, 'buffer_size': 39909, 'q_loss': 1.5133323669433594, 'mean_q_value': -0.17362350225448608, 'max_q_value': 0.3966057598590851, 'min_q_value': -0.9563718438148499, 'mean_td_error': 0.028581377, 'max_td_error': 0.09846902, 'mean_weight': 0.4998818635940552}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5473, -0.4131, -0.4169, -0.4628]], device='cuda:0'), reward is -0.99\n",
      "Episode 900/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 39965, 'eps': 0.0, 'buffer_size': 39965, 'q_loss': 1.237121820449829, 'mean_q_value': -0.19509127736091614, 'max_q_value': 0.36102837324142456, 'min_q_value': -0.9732682704925537, 'mean_td_error': 0.039387487, 'max_td_error': 0.11607081, 'mean_weight': 0.42614445090293884}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2934, -0.2569, -0.3213, -0.3067]], device='cuda:0'), reward is -0.99\n",
      "Episode 901/1000000: {'total_return': -0.87, 'steps': 13, 'total_steps': 39978, 'eps': 0.0, 'buffer_size': 39978, 'q_loss': 1.4725544452667236, 'mean_q_value': -0.2982974946498871, 'max_q_value': 0.3901348114013672, 'min_q_value': -0.9635429978370667, 'mean_td_error': 0.05609691, 'max_td_error': 0.2608388, 'mean_weight': 0.5443058013916016}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0099, 0.0091, 0.0124, 0.0092]], device='cuda:0'), reward is -0.99\n",
      "Episode 902/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 40017, 'eps': 0.0, 'buffer_size': 40017, 'q_loss': 1.1756949424743652, 'mean_q_value': -0.1703033745288849, 'max_q_value': 0.4018833637237549, 'min_q_value': -0.9055346846580505, 'mean_td_error': 0.058233406, 'max_td_error': 0.4854343, 'mean_weight': 0.3983074426651001}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6496, -0.8270, -0.6328, -0.6065]], device='cuda:0'), reward is -0.99\n",
      "Episode 903/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 40051, 'eps': 0.0, 'buffer_size': 40051, 'q_loss': 0.7863285541534424, 'mean_q_value': -0.12718147039413452, 'max_q_value': 0.41212600469589233, 'min_q_value': -0.9197131395339966, 'mean_td_error': 0.049114786, 'max_td_error': 0.21208873, 'mean_weight': 0.24787753820419312}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0291, 0.0284, 0.0308, 0.0282]], device='cuda:0'), reward is -0.99\n",
      "Episode 904/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 40071, 'eps': 0.0, 'buffer_size': 40071, 'q_loss': 1.438227891921997, 'mean_q_value': -0.20877957344055176, 'max_q_value': 0.31521326303482056, 'min_q_value': -0.9568728804588318, 'mean_td_error': 0.074120715, 'max_td_error': 0.45340136, 'mean_weight': 0.5102980732917786}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7252, -0.7041, -0.7001, -0.7662]], device='cuda:0'), reward is -0.99\n",
      "Episode 905/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 40130, 'eps': 0.0, 'buffer_size': 40130, 'q_loss': 0.8077934980392456, 'mean_q_value': -0.2595003843307495, 'max_q_value': 0.3484904170036316, 'min_q_value': -0.9559593796730042, 'mean_td_error': 0.066676676, 'max_td_error': 0.35189354, 'mean_weight': 0.28066349029541016}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6197, -0.6062, -0.6084, -0.6060]], device='cuda:0'), reward is -0.99\n",
      "Episode 906/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 40198, 'eps': 0.0, 'buffer_size': 40198, 'q_loss': 1.4881205558776855, 'mean_q_value': -0.19509615004062653, 'max_q_value': 0.40139055252075195, 'min_q_value': -0.8626323938369751, 'mean_td_error': 0.062120877, 'max_td_error': 0.3896147, 'mean_weight': 0.5146306753158569}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5325, -0.5340, -0.5318, -0.5356]], device='cuda:0'), reward is -0.99\n",
      "Episode 907/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 40239, 'eps': 0.0, 'buffer_size': 40239, 'q_loss': 0.8559083938598633, 'mean_q_value': -0.20027261972427368, 'max_q_value': 0.3850804269313812, 'min_q_value': -0.906667172908783, 'mean_td_error': 0.03716432, 'max_td_error': 0.15141097, 'mean_weight': 0.2903164327144623}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8204, -0.8534, -0.8252, -0.8241]], device='cuda:0'), reward is -0.99\n",
      "Episode 908/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 40280, 'eps': 0.0, 'buffer_size': 40280, 'q_loss': 1.6764379739761353, 'mean_q_value': -0.060465749353170395, 'max_q_value': 0.40180790424346924, 'min_q_value': -0.9109501242637634, 'mean_td_error': 0.052602757, 'max_td_error': 0.16599065, 'mean_weight': 0.524845540523529}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3991, -0.4095, -0.3797, -0.3680]], device='cuda:0'), reward is -0.99\n",
      "Episode 909/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 40324, 'eps': 0.0, 'buffer_size': 40324, 'q_loss': 1.3623714447021484, 'mean_q_value': -0.16497397422790527, 'max_q_value': 0.38973039388656616, 'min_q_value': -0.9887427687644958, 'mean_td_error': 0.05120403, 'max_td_error': 0.46762323, 'mean_weight': 0.45921099185943604}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8869, -0.8881, -0.8834, -0.8863]], device='cuda:0'), reward is -0.99\n",
      "Episode 910/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 40383, 'eps': 0.0, 'buffer_size': 40383, 'q_loss': 1.3445355892181396, 'mean_q_value': -0.19447195529937744, 'max_q_value': 0.39966896176338196, 'min_q_value': -0.9131925702095032, 'mean_td_error': 0.041885156, 'max_td_error': 0.1981743, 'mean_weight': 0.4547518491744995}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4774, -0.4278, -0.4299, -0.4439]], device='cuda:0'), reward is -0.99\n",
      "Episode 911/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 40445, 'eps': 0.0, 'buffer_size': 40445, 'q_loss': 1.4430341720581055, 'mean_q_value': -0.18897078931331635, 'max_q_value': 0.38667646050453186, 'min_q_value': -0.9130364656448364, 'mean_td_error': 0.06417902, 'max_td_error': 0.55914533, 'mean_weight': 0.49905335903167725}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1250, -0.0660, -0.0500, -0.0785]], device='cuda:0'), reward is -0.99\n",
      "Episode 912/1000000: {'total_return': -0.1999999999999995, 'steps': 80, 'total_steps': 40525, 'eps': 0.0, 'buffer_size': 40525, 'q_loss': 1.5471559762954712, 'mean_q_value': -0.14489474892616272, 'max_q_value': 0.38034719228744507, 'min_q_value': -0.8932927250862122, 'mean_td_error': 0.057269238, 'max_td_error': 0.16611898, 'mean_weight': 0.5154212713241577}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7966, -0.7899, -0.7891, -0.7953]], device='cuda:0'), reward is -0.99\n",
      "Episode 913/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 40580, 'eps': 0.0, 'buffer_size': 40580, 'q_loss': 1.4348809719085693, 'mean_q_value': -0.21201744675636292, 'max_q_value': 0.41564682126045227, 'min_q_value': -0.9689689874649048, 'mean_td_error': 0.04084543, 'max_td_error': 0.2428303, 'mean_weight': 0.5132306218147278}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8765, -0.8742, -0.8775, -0.8752]], device='cuda:0'), reward is -0.99\n",
      "Episode 914/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 40646, 'eps': 0.0, 'buffer_size': 40646, 'q_loss': 1.7367222309112549, 'mean_q_value': -0.2845892608165741, 'max_q_value': 0.33199313282966614, 'min_q_value': -0.917061448097229, 'mean_td_error': 0.047496065, 'max_td_error': 0.1758312, 'mean_weight': 0.6392467021942139}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3949, -0.2850, -0.2594, -0.3093]], device='cuda:0'), reward is -0.99\n",
      "Episode 915/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 40688, 'eps': 0.0, 'buffer_size': 40688, 'q_loss': 1.5512521266937256, 'mean_q_value': -0.15452824532985687, 'max_q_value': 0.3924962282180786, 'min_q_value': -0.8596673607826233, 'mean_td_error': 0.031905368, 'max_td_error': 0.10990459, 'mean_weight': 0.5507553219795227}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7520, -0.7440, -0.7431, -0.7744]], device='cuda:0'), reward is -0.99\n",
      "Episode 916/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 40738, 'eps': 0.0, 'buffer_size': 40738, 'q_loss': 1.5918605327606201, 'mean_q_value': -0.09738368541002274, 'max_q_value': 0.37854617834091187, 'min_q_value': -0.8734638690948486, 'mean_td_error': 0.06971879, 'max_td_error': 0.48864126, 'mean_weight': 0.5345150232315063}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5052, -0.5070, -0.4661, -0.4521]], device='cuda:0'), reward is -0.99\n",
      "Episode 917/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 40764, 'eps': 0.0, 'buffer_size': 40764, 'q_loss': 1.2194581031799316, 'mean_q_value': -0.25245288014411926, 'max_q_value': 0.4112282693386078, 'min_q_value': -0.8423036932945251, 'mean_td_error': 0.051932126, 'max_td_error': 0.33028683, 'mean_weight': 0.4393728971481323}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0457, -0.0546, -0.0429, -0.0914]], device='cuda:0'), reward is -0.99\n",
      "Episode 918/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 40802, 'eps': 0.0, 'buffer_size': 40802, 'q_loss': 1.5949857234954834, 'mean_q_value': -0.17625978589057922, 'max_q_value': 0.3905244469642639, 'min_q_value': -0.8711536526679993, 'mean_td_error': 0.05540752, 'max_td_error': 0.27842236, 'mean_weight': 0.5348647832870483}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5808, -0.5826, -0.5798, -0.5833]], device='cuda:0'), reward is -0.99\n",
      "Episode 919/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 40837, 'eps': 0.0, 'buffer_size': 40837, 'q_loss': 1.3120481967926025, 'mean_q_value': -0.2170281708240509, 'max_q_value': 0.3575032949447632, 'min_q_value': -0.9201716184616089, 'mean_td_error': 0.043342777, 'max_td_error': 0.19648331, 'mean_weight': 0.45376819372177124}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8315, -0.8337, -0.8195, -0.8256]], device='cuda:0'), reward is -0.99\n",
      "Episode 920/1000000: {'total_return': -0.2699999999999996, 'steps': 73, 'total_steps': 40910, 'eps': 0.0, 'buffer_size': 40910, 'q_loss': 1.410017728805542, 'mean_q_value': -0.3307894468307495, 'max_q_value': 0.34803617000579834, 'min_q_value': -0.9190160632133484, 'mean_td_error': 0.07992241, 'max_td_error': 0.32640123, 'mean_weight': 0.5285122394561768}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1343, -0.1065, -0.1019, -0.1138]], device='cuda:0'), reward is -0.99\n",
      "Episode 921/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 40951, 'eps': 0.0, 'buffer_size': 40951, 'q_loss': 1.4429235458374023, 'mean_q_value': -0.25814345479011536, 'max_q_value': 0.33565235137939453, 'min_q_value': -0.9734840989112854, 'mean_td_error': 0.06628032, 'max_td_error': 0.70470226, 'mean_weight': 0.5312042236328125}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3011, -0.3124, -0.3076, -0.3054]], device='cuda:0'), reward is -0.99\n",
      "Episode 922/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 40983, 'eps': 0.0, 'buffer_size': 40983, 'q_loss': 1.8202619552612305, 'mean_q_value': -0.11491262912750244, 'max_q_value': 0.43783771991729736, 'min_q_value': -0.9618450403213501, 'mean_td_error': 0.042854108, 'max_td_error': 0.2758649, 'mean_weight': 0.6198623180389404}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5915, -0.5973, -0.5731, -0.5748]], device='cuda:0'), reward is -0.99\n",
      "Episode 923/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 41029, 'eps': 0.0, 'buffer_size': 41029, 'q_loss': 1.7040820121765137, 'mean_q_value': -0.2034156322479248, 'max_q_value': 0.3698607385158539, 'min_q_value': -0.9160474538803101, 'mean_td_error': 0.05608644, 'max_td_error': 0.29631057, 'mean_weight': 0.5896667242050171}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7945, -0.7862, -0.7862, -0.7893]], device='cuda:0'), reward is -0.99\n",
      "Episode 924/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 41063, 'eps': 0.0, 'buffer_size': 41063, 'q_loss': 1.324993371963501, 'mean_q_value': -0.20605839788913727, 'max_q_value': 0.38998907804489136, 'min_q_value': -0.904394268989563, 'mean_td_error': 0.11332777, 'max_td_error': 0.9619762, 'mean_weight': 0.48537635803222656}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5959, -0.6160, -0.5426, -0.5206]], device='cuda:0'), reward is -0.99\n",
      "Episode 925/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 41110, 'eps': 0.0, 'buffer_size': 41110, 'q_loss': 1.4640823602676392, 'mean_q_value': -0.16958633065223694, 'max_q_value': 0.39872050285339355, 'min_q_value': -0.9760596752166748, 'mean_td_error': 0.053904068, 'max_td_error': 0.34049273, 'mean_weight': 0.5173661708831787}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4684, -0.4673, -0.4629, -0.4661]], device='cuda:0'), reward is -0.99\n",
      "Episode 926/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 41136, 'eps': 0.0, 'buffer_size': 41136, 'q_loss': 1.1895190477371216, 'mean_q_value': -0.2622740864753723, 'max_q_value': 0.387382835149765, 'min_q_value': -0.9777783155441284, 'mean_td_error': 0.043043323, 'max_td_error': 0.2863958, 'mean_weight': 0.4464682638645172}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1343, -0.1682, -0.1614, -0.1458]], device='cuda:0'), reward is -0.99\n",
      "Episode 927/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 41174, 'eps': 0.0, 'buffer_size': 41174, 'q_loss': 1.103461503982544, 'mean_q_value': -0.10892385244369507, 'max_q_value': 0.40439048409461975, 'min_q_value': -0.9617665410041809, 'mean_td_error': 0.045153797, 'max_td_error': 0.15162948, 'mean_weight': 0.3717208504676819}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6423, -0.5794, -0.5554, -0.5663]], device='cuda:0'), reward is -0.99\n",
      "Episode 928/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 41235, 'eps': 0.0, 'buffer_size': 41235, 'q_loss': 1.5344209671020508, 'mean_q_value': -0.13134647905826569, 'max_q_value': 0.39392346143722534, 'min_q_value': -0.8801982402801514, 'mean_td_error': 0.06354677, 'max_td_error': 0.25545928, 'mean_weight': 0.504875659942627}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7901, -0.6749, -0.6753, -0.7418]], device='cuda:0'), reward is -0.99\n",
      "Episode 929/1000000: {'total_return': -0.0799999999999994, 'steps': 92, 'total_steps': 41327, 'eps': 0.0, 'buffer_size': 41327, 'q_loss': 0.930359959602356, 'mean_q_value': -0.2753068506717682, 'max_q_value': 0.3968682587146759, 'min_q_value': -0.9186924695968628, 'mean_td_error': 0.0730771, 'max_td_error': 0.26310992, 'mean_weight': 0.33434784412384033}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.2027, 0.2114, 0.2152, 0.2134]], device='cuda:0'), reward is -0.99\n",
      "Episode 930/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 41350, 'eps': 0.0, 'buffer_size': 41350, 'q_loss': 1.7148635387420654, 'mean_q_value': -0.13753436505794525, 'max_q_value': 0.3749834895133972, 'min_q_value': -0.9641624093055725, 'mean_td_error': 0.044842083, 'max_td_error': 0.22463343, 'mean_weight': 0.5841631889343262}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7981, -0.8020, -0.7929, -0.7989]], device='cuda:0'), reward is -0.99\n",
      "Episode 931/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 41417, 'eps': 0.0, 'buffer_size': 41417, 'q_loss': 1.5241025686264038, 'mean_q_value': -0.22274717688560486, 'max_q_value': 0.4217514097690582, 'min_q_value': -0.9805842638015747, 'mean_td_error': 0.05948048, 'max_td_error': 0.22448522, 'mean_weight': 0.5638625621795654}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4727, -0.3715, -0.3931, -0.3429]], device='cuda:0'), reward is -0.99\n",
      "Episode 932/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 41455, 'eps': 0.0, 'buffer_size': 41455, 'q_loss': 1.4447399377822876, 'mean_q_value': -0.21804048120975494, 'max_q_value': 0.42588359117507935, 'min_q_value': -0.9290482401847839, 'mean_td_error': 0.048652567, 'max_td_error': 0.35096115, 'mean_weight': 0.5025085210800171}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1947, -0.1972, -0.1948, -0.1950]], device='cuda:0'), reward is -0.99\n",
      "Episode 933/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 41483, 'eps': 0.0, 'buffer_size': 41483, 'q_loss': 1.5460530519485474, 'mean_q_value': -0.13607999682426453, 'max_q_value': 0.41688090562820435, 'min_q_value': -0.9243951439857483, 'mean_td_error': 0.049039196, 'max_td_error': 0.35541117, 'mean_weight': 0.532615065574646}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8335, -0.8248, -0.8264, -0.8300]], device='cuda:0'), reward is -0.99\n",
      "Episode 934/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 41541, 'eps': 0.0, 'buffer_size': 41541, 'q_loss': 1.2815070152282715, 'mean_q_value': -0.2959696054458618, 'max_q_value': 0.39400848746299744, 'min_q_value': -0.9623012542724609, 'mean_td_error': 0.06369599, 'max_td_error': 0.39045694, 'mean_weight': 0.48820409178733826}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.1516, 0.1308, 0.1604, 0.1396]], device='cuda:0'), reward is -0.99\n",
      "Episode 935/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 41567, 'eps': 0.0, 'buffer_size': 41567, 'q_loss': 1.1576542854309082, 'mean_q_value': -0.2938653528690338, 'max_q_value': 0.39508163928985596, 'min_q_value': -0.9407498240470886, 'mean_td_error': 0.06885025, 'max_td_error': 0.3493263, 'mean_weight': 0.42805343866348267}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9105, -0.9017, -0.8921, -0.8965]], device='cuda:0'), reward is -0.99\n",
      "Episode 936/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 41636, 'eps': 0.0, 'buffer_size': 41636, 'q_loss': 1.6070573329925537, 'mean_q_value': -0.23937752842903137, 'max_q_value': 0.34620368480682373, 'min_q_value': -0.8965535759925842, 'mean_td_error': 0.05371436, 'max_td_error': 0.22423932, 'mean_weight': 0.5565309524536133}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6166, -0.6168, -0.6149, -0.6168]], device='cuda:0'), reward is -0.99\n",
      "Episode 937/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 41686, 'eps': 0.0, 'buffer_size': 41686, 'q_loss': 1.6568536758422852, 'mean_q_value': -0.1818787306547165, 'max_q_value': 0.38347333669662476, 'min_q_value': -0.9133656024932861, 'mean_td_error': 0.049214974, 'max_td_error': 0.21004552, 'mean_weight': 0.5855557322502136}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7243, -0.5966, -0.6639, -0.7067]], device='cuda:0'), reward is -0.99\n",
      "Episode 938/1000000: {'total_return': -0.5899999999999999, 'steps': 41, 'total_steps': 41727, 'eps': 0.0, 'buffer_size': 41727, 'q_loss': 0.9268645644187927, 'mean_q_value': -0.23511207103729248, 'max_q_value': 0.3323709964752197, 'min_q_value': -0.9663206934928894, 'mean_td_error': 0.06337211, 'max_td_error': 0.38084704, 'mean_weight': 0.3390524983406067}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0962, 0.0928, 0.1032, 0.0141]], device='cuda:0'), reward is -0.99\n",
      "Episode 939/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 41748, 'eps': 0.0, 'buffer_size': 41748, 'q_loss': 0.935900092124939, 'mean_q_value': -0.1892796903848648, 'max_q_value': 0.39160284399986267, 'min_q_value': -0.876313328742981, 'mean_td_error': 0.04142343, 'max_td_error': 0.19661471, 'mean_weight': 0.3240647315979004}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7695, -0.6716, -0.6939, -0.6967]], device='cuda:0'), reward is -0.99\n",
      "Episode 940/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 41803, 'eps': 0.0, 'buffer_size': 41803, 'q_loss': 1.5571355819702148, 'mean_q_value': -0.1631239503622055, 'max_q_value': 0.41681867837905884, 'min_q_value': -0.97996586561203, 'mean_td_error': 0.041744016, 'max_td_error': 0.18123299, 'mean_weight': 0.5419224500656128}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7002, -0.6984, -0.6969, -0.7015]], device='cuda:0'), reward is -0.99\n",
      "Episode 941/1000000: {'total_return': -0.69, 'steps': 31, 'total_steps': 41834, 'eps': 0.0, 'buffer_size': 41834, 'q_loss': 1.5004732608795166, 'mean_q_value': -0.1553972214460373, 'max_q_value': 0.4078655242919922, 'min_q_value': -0.9602200388908386, 'mean_td_error': 0.05819328, 'max_td_error': 0.38564962, 'mean_weight': 0.5177796483039856}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9356, -0.8764, -0.9022, -0.9366]], device='cuda:0'), reward is -0.99\n",
      "Episode 942/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 41901, 'eps': 0.0, 'buffer_size': 41901, 'q_loss': 1.333191156387329, 'mean_q_value': -0.20003144443035126, 'max_q_value': 0.3953744173049927, 'min_q_value': -0.9485139846801758, 'mean_td_error': 0.041802146, 'max_td_error': 0.12909779, 'mean_weight': 0.4773661196231842}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0898, -0.0898, -0.0866, -0.0922]], device='cuda:0'), reward is -0.99\n",
      "Episode 943/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 41939, 'eps': 0.0, 'buffer_size': 41939, 'q_loss': 1.3543097972869873, 'mean_q_value': -0.1088949516415596, 'max_q_value': 0.29326683282852173, 'min_q_value': -0.7983292937278748, 'mean_td_error': 0.053630903, 'max_td_error': 0.2853976, 'mean_weight': 0.4275099039077759}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6909, -0.6855, -0.6788, -0.6841]], device='cuda:0'), reward is -0.99\n",
      "Episode 944/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 41986, 'eps': 0.0, 'buffer_size': 41986, 'q_loss': 1.5685546398162842, 'mean_q_value': -0.08577649295330048, 'max_q_value': 0.4018290638923645, 'min_q_value': -0.8774049878120422, 'mean_td_error': 0.04493881, 'max_td_error': 0.18738943, 'mean_weight': 0.5215322971343994}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6380, -0.6304, -0.6229, -0.6230]], device='cuda:0'), reward is -0.99\n",
      "Episode 945/1000000: {'total_return': -0.73, 'steps': 27, 'total_steps': 42013, 'eps': 0.0, 'buffer_size': 42013, 'q_loss': 1.6394541263580322, 'mean_q_value': -0.060224663466215134, 'max_q_value': 0.37222471833229065, 'min_q_value': -0.9402514696121216, 'mean_td_error': 0.048047725, 'max_td_error': 0.14906126, 'mean_weight': 0.510879635810852}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0717, 0.0785, 0.1148, 0.1180]], device='cuda:0'), reward is -0.99\n",
      "Episode 946/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 42076, 'eps': 0.0, 'buffer_size': 42076, 'q_loss': 1.238948941230774, 'mean_q_value': -0.26780736446380615, 'max_q_value': 0.3889792561531067, 'min_q_value': -0.9569530487060547, 'mean_td_error': 0.042613372, 'max_td_error': 0.15175596, 'mean_weight': 0.4794989228248596}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2122, -0.2143, -0.2125, -0.2139]], device='cuda:0'), reward is -0.99\n",
      "Episode 947/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 42152, 'eps': 0.0, 'buffer_size': 42152, 'q_loss': 1.5581670999526978, 'mean_q_value': -0.2220602035522461, 'max_q_value': 0.4447566270828247, 'min_q_value': -0.9306932687759399, 'mean_td_error': 0.041821513, 'max_td_error': 0.16779003, 'mean_weight': 0.5317389965057373}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7661, -0.8390, -0.7739, -0.7672]], device='cuda:0'), reward is -0.99\n",
      "Episode 948/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 42186, 'eps': 0.0, 'buffer_size': 42186, 'q_loss': 1.5503087043762207, 'mean_q_value': -0.08159377425909042, 'max_q_value': 0.5740929841995239, 'min_q_value': -0.9044800400733948, 'mean_td_error': 0.045024857, 'max_td_error': 0.34106588, 'mean_weight': 0.5293493866920471}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7885, -0.8063, -0.7594, -0.7583]], device='cuda:0'), reward is -0.99\n",
      "Episode 949/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 42221, 'eps': 0.0, 'buffer_size': 42221, 'q_loss': 1.194326400756836, 'mean_q_value': -0.0624602846801281, 'max_q_value': 0.44050905108451843, 'min_q_value': -0.8724929690361023, 'mean_td_error': 0.04765137, 'max_td_error': 0.2593906, 'mean_weight': 0.38421666622161865}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2538, -0.2481, -0.2644, -0.2833]], device='cuda:0'), reward is -0.99\n",
      "Episode 950/1000000: {'total_return': -0.84, 'steps': 16, 'total_steps': 42237, 'eps': 0.0, 'buffer_size': 42237, 'q_loss': 1.145183801651001, 'mean_q_value': -0.14949022233486176, 'max_q_value': 0.37257903814315796, 'min_q_value': -0.9077314734458923, 'mean_td_error': 0.05087816, 'max_td_error': 0.22027725, 'mean_weight': 0.3719545900821686}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9139, -0.9247, -0.9191, -0.9078]], device='cuda:0'), reward is -0.99\n",
      "Episode 951/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 42314, 'eps': 0.0, 'buffer_size': 42314, 'q_loss': 0.9790946841239929, 'mean_q_value': -0.21229101717472076, 'max_q_value': 0.35265377163887024, 'min_q_value': -1.0059664249420166, 'mean_td_error': 0.036367513, 'max_td_error': 0.2876752, 'mean_weight': 0.36436986923217773}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2324, -0.1972, -0.2263, -0.2152]], device='cuda:0'), reward is -0.99\n",
      "Episode 952/1000000: {'total_return': -0.5199999999999998, 'steps': 48, 'total_steps': 42362, 'eps': 0.0, 'buffer_size': 42362, 'q_loss': 1.64736008644104, 'mean_q_value': -0.10397069156169891, 'max_q_value': 0.41956430673599243, 'min_q_value': -0.8924035429954529, 'mean_td_error': 0.0383386, 'max_td_error': 0.16706449, 'mean_weight': 0.5322182774543762}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6820, -0.6827, -0.6822, -0.6836]], device='cuda:0'), reward is -0.99\n",
      "Episode 953/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 42421, 'eps': 0.0, 'buffer_size': 42421, 'q_loss': 1.4972317218780518, 'mean_q_value': -0.16040697693824768, 'max_q_value': 0.3914467394351959, 'min_q_value': -0.9222577214241028, 'mean_td_error': 0.05332433, 'max_td_error': 0.21131688, 'mean_weight': 0.5249446630477905}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5486, -0.5013, -0.4598, -0.4465]], device='cuda:0'), reward is -0.99\n",
      "Episode 954/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 42464, 'eps': 0.0, 'buffer_size': 42464, 'q_loss': 1.3388673067092896, 'mean_q_value': -0.1789993941783905, 'max_q_value': 0.38387876749038696, 'min_q_value': -0.9894141554832458, 'mean_td_error': 0.06905827, 'max_td_error': 0.5498737, 'mean_weight': 0.4622151851654053}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2383, -0.2082, -0.2171, -0.2016]], device='cuda:0'), reward is -0.99\n",
      "Episode 955/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 42513, 'eps': 0.0, 'buffer_size': 42513, 'q_loss': 1.4799492359161377, 'mean_q_value': -0.1749333143234253, 'max_q_value': 0.38422465324401855, 'min_q_value': -0.9560559391975403, 'mean_td_error': 0.051051646, 'max_td_error': 0.27315181, 'mean_weight': 0.5025932192802429}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0864, 0.0857, 0.0873, 0.0874]], device='cuda:0'), reward is -0.99\n",
      "Episode 956/1000000: {'total_return': -0.7999999999999999, 'steps': 20, 'total_steps': 42533, 'eps': 0.0, 'buffer_size': 42533, 'q_loss': 1.4860665798187256, 'mean_q_value': -0.23065444827079773, 'max_q_value': 0.4208758473396301, 'min_q_value': -0.8530461192131042, 'mean_td_error': 0.062929034, 'max_td_error': 0.20507383, 'mean_weight': 0.5585724115371704}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0379, -0.0383, -0.0371, -0.0366]], device='cuda:0'), reward is -0.99\n",
      "Episode 957/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 42579, 'eps': 0.0, 'buffer_size': 42579, 'q_loss': 1.4206688404083252, 'mean_q_value': -0.060874152928590775, 'max_q_value': 0.4732017517089844, 'min_q_value': -0.8237248659133911, 'mean_td_error': 0.06895159, 'max_td_error': 0.60849655, 'mean_weight': 0.4632571339607239}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6567, -0.6096, -0.5993, -0.6062]], device='cuda:0'), reward is -0.99\n",
      "Episode 958/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 42646, 'eps': 0.0, 'buffer_size': 42646, 'q_loss': 1.0745929479599, 'mean_q_value': -0.13418836891651154, 'max_q_value': 0.40757936239242554, 'min_q_value': -0.9162149429321289, 'mean_td_error': 0.049517103, 'max_td_error': 0.26466942, 'mean_weight': 0.3716529309749603}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6637, -0.6019, -0.5970, -0.6465]], device='cuda:0'), reward is -0.99\n",
      "Episode 959/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 42704, 'eps': 0.0, 'buffer_size': 42704, 'q_loss': 1.7285147905349731, 'mean_q_value': -0.1952420473098755, 'max_q_value': 0.4179233908653259, 'min_q_value': -0.9375507831573486, 'mean_td_error': 0.06596405, 'max_td_error': 0.51111734, 'mean_weight': 0.6125578880310059}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3245, -0.3249, -0.3246, -0.3235]], device='cuda:0'), reward is -0.99\n",
      "Episode 960/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 42741, 'eps': 0.0, 'buffer_size': 42741, 'q_loss': 1.7621721029281616, 'mean_q_value': -0.15740889310836792, 'max_q_value': 0.3821120858192444, 'min_q_value': -1.0153188705444336, 'mean_td_error': 0.041446753, 'max_td_error': 0.17478988, 'mean_weight': 0.6128537654876709}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8934, -0.9074, -0.8971, -0.8988]], device='cuda:0'), reward is -0.99\n",
      "Episode 961/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 42779, 'eps': 0.0, 'buffer_size': 42779, 'q_loss': 1.6890219449996948, 'mean_q_value': -0.1819971650838852, 'max_q_value': 0.39505353569984436, 'min_q_value': -0.9500352144241333, 'mean_td_error': 0.048432164, 'max_td_error': 0.15773416, 'mean_weight': 0.5923475623130798}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4343, -0.4536, -0.4236, -0.5042]], device='cuda:0'), reward is -0.99\n",
      "Episode 962/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 42847, 'eps': 0.0, 'buffer_size': 42847, 'q_loss': 1.2915371656417847, 'mean_q_value': -0.14906710386276245, 'max_q_value': 0.38663798570632935, 'min_q_value': -0.8572246432304382, 'mean_td_error': 0.045184527, 'max_td_error': 0.2011948, 'mean_weight': 0.42635950446128845}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6107, -0.5151, -0.5362, -0.5604]], device='cuda:0'), reward is -0.99\n",
      "Episode 963/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 42892, 'eps': 0.0, 'buffer_size': 42892, 'q_loss': 1.4557454586029053, 'mean_q_value': -0.1559496521949768, 'max_q_value': 0.40067028999328613, 'min_q_value': -0.9334792494773865, 'mean_td_error': 0.044775985, 'max_td_error': 0.25665298, 'mean_weight': 0.4970937669277191}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3808, -0.3805, -0.3809, -0.3796]], device='cuda:0'), reward is -0.99\n",
      "Episode 964/1000000: {'total_return': -0.6299999999999999, 'steps': 37, 'total_steps': 42929, 'eps': 0.0, 'buffer_size': 42929, 'q_loss': 1.9787623882293701, 'mean_q_value': -0.018942631781101227, 'max_q_value': 0.4105485677719116, 'min_q_value': -0.9099550843238831, 'mean_td_error': 0.039307196, 'max_td_error': 0.1378156, 'mean_weight': 0.6196328401565552}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8042, -0.9007, -0.7738, -0.7895]], device='cuda:0'), reward is -0.99\n",
      "Episode 965/1000000: {'total_return': -0.6499999999999999, 'steps': 35, 'total_steps': 42964, 'eps': 0.0, 'buffer_size': 42964, 'q_loss': 1.393754243850708, 'mean_q_value': -0.11369091272354126, 'max_q_value': 0.36801379919052124, 'min_q_value': -0.9065200090408325, 'mean_td_error': 0.03779734, 'max_td_error': 0.13078141, 'mean_weight': 0.46297258138656616}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0988, 0.0990, 0.0983, 0.1008]], device='cuda:0'), reward is -0.99\n",
      "Episode 966/1000000: {'total_return': -0.83, 'steps': 17, 'total_steps': 42981, 'eps': 0.0, 'buffer_size': 42981, 'q_loss': 1.664416790008545, 'mean_q_value': -0.205250084400177, 'max_q_value': 0.40423691272735596, 'min_q_value': -0.9275004863739014, 'mean_td_error': 0.046326075, 'max_td_error': 0.22704032, 'mean_weight': 0.5930361747741699}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7197, -0.7148, -0.7128, -0.7128]], device='cuda:0'), reward is -0.99\n",
      "Episode 967/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 43044, 'eps': 0.0, 'buffer_size': 43044, 'q_loss': 1.8425687551498413, 'mean_q_value': -0.04927242174744606, 'max_q_value': 0.4066697955131531, 'min_q_value': -0.9493030905723572, 'mean_td_error': 0.056857497, 'max_td_error': 0.62688375, 'mean_weight': 0.5785655975341797}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7788, -0.6949, -0.7006, -0.7637]], device='cuda:0'), reward is -0.99\n",
      "Episode 968/1000000: {'total_return': -0.3999999999999997, 'steps': 60, 'total_steps': 43104, 'eps': 0.0, 'buffer_size': 43104, 'q_loss': 1.3779017925262451, 'mean_q_value': -0.08315770328044891, 'max_q_value': 0.4069509506225586, 'min_q_value': -0.8649144172668457, 'mean_td_error': 0.027935171, 'max_td_error': 0.118992925, 'mean_weight': 0.44957235455513}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3729, -0.3963, -0.4025, -0.3953]], device='cuda:0'), reward is -0.99\n",
      "Episode 969/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 43176, 'eps': 0.0, 'buffer_size': 43176, 'q_loss': 2.1004257202148438, 'mean_q_value': -0.1206917017698288, 'max_q_value': 0.4232933521270752, 'min_q_value': -0.8250712156295776, 'mean_td_error': 0.047035433, 'max_td_error': 0.21591362, 'mean_weight': 0.6846176385879517}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8718, -0.8483, -0.8461, -0.8580]], device='cuda:0'), reward is -0.99\n",
      "Episode 970/1000000: {'total_return': -0.5399999999999998, 'steps': 46, 'total_steps': 43222, 'eps': 0.0, 'buffer_size': 43222, 'q_loss': 1.7580711841583252, 'mean_q_value': -0.1593295931816101, 'max_q_value': 0.40339094400405884, 'min_q_value': -0.9609521627426147, 'mean_td_error': 0.034308292, 'max_td_error': 0.2372244, 'mean_weight': 0.5827814340591431}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4763, -0.4756, -0.4762, -0.4755]], device='cuda:0'), reward is -0.99\n",
      "Episode 971/1000000: {'total_return': -0.71, 'steps': 29, 'total_steps': 43251, 'eps': 0.0, 'buffer_size': 43251, 'q_loss': 1.2892522811889648, 'mean_q_value': -0.2428932934999466, 'max_q_value': 0.3772764503955841, 'min_q_value': -0.8825792670249939, 'mean_td_error': 0.049006127, 'max_td_error': 0.21324185, 'mean_weight': 0.4550119936466217}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8249, -0.7742, -0.7734, -0.7959]], device='cuda:0'), reward is -0.99\n",
      "Episode 972/1000000: {'total_return': -0.5599999999999998, 'steps': 44, 'total_steps': 43295, 'eps': 0.0, 'buffer_size': 43295, 'q_loss': 1.3840489387512207, 'mean_q_value': -0.11538736522197723, 'max_q_value': 0.40949004888534546, 'min_q_value': -0.9292208552360535, 'mean_td_error': 0.052937508, 'max_td_error': 0.29029185, 'mean_weight': 0.4714888334274292}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6077, -0.2492, -0.2557, -0.2890]], device='cuda:0'), reward is -0.99\n",
      "Episode 973/1000000: {'total_return': -0.21999999999999953, 'steps': 78, 'total_steps': 43373, 'eps': 0.0, 'buffer_size': 43373, 'q_loss': 1.724421501159668, 'mean_q_value': -0.16501323878765106, 'max_q_value': 0.4310315251350403, 'min_q_value': -0.9500479102134705, 'mean_td_error': 0.044490054, 'max_td_error': 0.31204364, 'mean_weight': 0.6087123155593872}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2798, -0.2654, -0.2677, -0.2684]], device='cuda:0'), reward is -0.99\n",
      "Episode 974/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 43425, 'eps': 0.0, 'buffer_size': 43425, 'q_loss': 1.2683711051940918, 'mean_q_value': -0.1766996830701828, 'max_q_value': 0.3281041979789734, 'min_q_value': -0.9493476748466492, 'mean_td_error': 0.04772061, 'max_td_error': 0.2209427, 'mean_weight': 0.4337892234325409}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9188, -0.9271, -0.9032, -0.9214]], device='cuda:0'), reward is -0.99\n",
      "Episode 975/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 43493, 'eps': 0.0, 'buffer_size': 43493, 'q_loss': 1.5965840816497803, 'mean_q_value': -0.15134890377521515, 'max_q_value': 0.33454614877700806, 'min_q_value': -0.9852743744850159, 'mean_td_error': 0.05258102, 'max_td_error': 0.18359816, 'mean_weight': 0.5459917783737183}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6910, -0.6479, -0.6520, -0.6765]], device='cuda:0'), reward is -0.99\n",
      "Episode 976/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 43521, 'eps': 0.0, 'buffer_size': 43521, 'q_loss': 0.9436883926391602, 'mean_q_value': -0.13877838850021362, 'max_q_value': 0.3494073748588562, 'min_q_value': -0.8546172976493835, 'mean_td_error': 0.042878926, 'max_td_error': 0.14352655, 'mean_weight': 0.3226991593837738}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5058, -0.5284, -0.5003, -0.5271]], device='cuda:0'), reward is -0.99\n",
      "Episode 977/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 43578, 'eps': 0.0, 'buffer_size': 43578, 'q_loss': 1.0192749500274658, 'mean_q_value': -0.16692137718200684, 'max_q_value': 0.4047761559486389, 'min_q_value': -0.8889703154563904, 'mean_td_error': 0.07826599, 'max_td_error': 0.78607035, 'mean_weight': 0.36811670660972595}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5017, -0.5058, -0.4895, -0.5132]], device='cuda:0'), reward is -0.99\n",
      "Episode 978/1000000: {'total_return': -0.6599999999999999, 'steps': 34, 'total_steps': 43612, 'eps': 0.0, 'buffer_size': 43612, 'q_loss': 1.4463489055633545, 'mean_q_value': -0.19934514164924622, 'max_q_value': 0.4275345206260681, 'min_q_value': -0.9120281934738159, 'mean_td_error': 0.04846085, 'max_td_error': 0.34548938, 'mean_weight': 0.5134517550468445}\n",
      "Hit done, on final action Predicted Q-values: tensor([[ 0.1183, -0.1343, -0.0140,  0.1261]], device='cuda:0'), reward is -0.99\n",
      "Episode 979/1000000: {'total_return': 0.05000000000000071, 'steps': 105, 'total_steps': 43717, 'eps': 0.0, 'buffer_size': 43717, 'q_loss': 0.8032195568084717, 'mean_q_value': -0.13708531856536865, 'max_q_value': 0.4141775965690613, 'min_q_value': -0.9400061368942261, 'mean_td_error': 0.04211988, 'max_td_error': 0.13016176, 'mean_weight': 0.28345441818237305}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5602, -0.5635, -0.5684, -0.5868]], device='cuda:0'), reward is -0.99\n",
      "Episode 980/1000000: {'total_return': -0.3099999999999996, 'steps': 69, 'total_steps': 43786, 'eps': 0.0, 'buffer_size': 43786, 'q_loss': 1.72782301902771, 'mean_q_value': -0.15129108726978302, 'max_q_value': 0.39284318685531616, 'min_q_value': -0.8480796217918396, 'mean_td_error': 0.054508053, 'max_td_error': 0.2469593, 'mean_weight': 0.560732901096344}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5461, -0.5495, -0.6286, -0.5390]], device='cuda:0'), reward is -0.99\n",
      "Episode 981/1000000: {'total_return': 0.020000000000000684, 'steps': 102, 'total_steps': 43888, 'eps': 0.0, 'buffer_size': 43888, 'q_loss': 1.9219087362289429, 'mean_q_value': -0.08441673219203949, 'max_q_value': 0.3845382630825043, 'min_q_value': -0.9136476516723633, 'mean_td_error': 0.03925719, 'max_td_error': 0.13203824, 'mean_weight': 0.61871337890625}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6558, -0.6716, -0.6169, -0.5900]], device='cuda:0'), reward is -0.99\n",
      "Episode 982/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 43928, 'eps': 0.0, 'buffer_size': 43928, 'q_loss': 0.7847440242767334, 'mean_q_value': -0.16658271849155426, 'max_q_value': 0.4086012840270996, 'min_q_value': -0.7955425381660461, 'mean_td_error': 0.04217737, 'max_td_error': 0.17566192, 'mean_weight': 0.27098149061203003}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6200, -0.5125, -0.5409, -0.5647]], device='cuda:0'), reward is -0.99\n",
      "Episode 983/1000000: {'total_return': -0.5099999999999998, 'steps': 49, 'total_steps': 43977, 'eps': 0.0, 'buffer_size': 43977, 'q_loss': 1.708698034286499, 'mean_q_value': -0.0614350400865078, 'max_q_value': 0.41636282205581665, 'min_q_value': -0.8026654720306396, 'mean_td_error': 0.044468477, 'max_td_error': 0.26861107, 'mean_weight': 0.5441245436668396}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2168, -0.2047, -0.1819, -0.3283]], device='cuda:0'), reward is -0.99\n",
      "Episode 984/1000000: {'total_return': -0.33999999999999964, 'steps': 66, 'total_steps': 44043, 'eps': 0.0, 'buffer_size': 44043, 'q_loss': 2.1122334003448486, 'mean_q_value': -0.14915461838245392, 'max_q_value': 0.44256269931793213, 'min_q_value': -0.9600591063499451, 'mean_td_error': 0.026060667, 'max_td_error': 0.076553434, 'mean_weight': 0.7179850339889526}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6153, -0.6308, -0.6354, -0.6140]], device='cuda:0'), reward is -0.99\n",
      "Episode 985/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 44065, 'eps': 0.0, 'buffer_size': 44065, 'q_loss': 1.4959644079208374, 'mean_q_value': -0.11272544413805008, 'max_q_value': 0.3855777084827423, 'min_q_value': -0.9106769561767578, 'mean_td_error': 0.03339699, 'max_td_error': 0.13522664, 'mean_weight': 0.49241796135902405}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9055, -0.9125, -0.9055, -0.9190]], device='cuda:0'), reward is -0.99\n",
      "Episode 986/1000000: {'total_return': -0.2899999999999996, 'steps': 71, 'total_steps': 44136, 'eps': 0.0, 'buffer_size': 44136, 'q_loss': 1.2831387519836426, 'mean_q_value': -0.18277299404144287, 'max_q_value': 0.432567298412323, 'min_q_value': -0.8962467312812805, 'mean_td_error': 0.03830665, 'max_td_error': 0.15119413, 'mean_weight': 0.45318543910980225}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5913, -0.5918, -0.5909, -0.5925]], device='cuda:0'), reward is -0.99\n",
      "Episode 987/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 44174, 'eps': 0.0, 'buffer_size': 44174, 'q_loss': 1.449457049369812, 'mean_q_value': -0.13443997502326965, 'max_q_value': 0.4107467532157898, 'min_q_value': -0.892055869102478, 'mean_td_error': 0.04872188, 'max_td_error': 0.2173607, 'mean_weight': 0.48175203800201416}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3956, -0.3972, -0.3957, -0.3976]], device='cuda:0'), reward is -0.99\n",
      "Episode 988/1000000: {'total_return': 0.08000000000000074, 'steps': 108, 'total_steps': 44282, 'eps': 0.0, 'buffer_size': 44282, 'q_loss': 1.5696690082550049, 'mean_q_value': -0.1830701231956482, 'max_q_value': 0.37692511081695557, 'min_q_value': -0.8574913740158081, 'mean_td_error': 0.047363136, 'max_td_error': 0.29982024, 'mean_weight': 0.5572015047073364}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6923, -0.7538, -0.6953, -0.7061]], device='cuda:0'), reward is -0.99\n",
      "Episode 989/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 44308, 'eps': 0.0, 'buffer_size': 44308, 'q_loss': 1.7001897096633911, 'mean_q_value': -0.13505780696868896, 'max_q_value': 0.3964187502861023, 'min_q_value': -0.9068326354026794, 'mean_td_error': 0.052440666, 'max_td_error': 0.28683633, 'mean_weight': 0.5717833638191223}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8262, -0.8079, -0.8088, -0.8270]], device='cuda:0'), reward is -0.99\n",
      "Episode 990/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 44361, 'eps': 0.0, 'buffer_size': 44361, 'q_loss': 1.5341237783432007, 'mean_q_value': -0.2125747948884964, 'max_q_value': 0.34750375151634216, 'min_q_value': -0.9483146667480469, 'mean_td_error': 0.048529103, 'max_td_error': 0.25532138, 'mean_weight': 0.5682401061058044}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5704, -0.5459, -0.6244, -0.5421]], device='cuda:0'), reward is -0.99\n",
      "Episode 991/1000000: {'total_return': -0.02999999999999936, 'steps': 97, 'total_steps': 44458, 'eps': 0.0, 'buffer_size': 44458, 'q_loss': 1.4505168199539185, 'mean_q_value': -0.2126552164554596, 'max_q_value': 0.3914499282836914, 'min_q_value': -0.9725672602653503, 'mean_td_error': 0.042985756, 'max_td_error': 0.1645298, 'mean_weight': 0.5254571437835693}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4213, -0.4263, -0.4383, -0.4476]], device='cuda:0'), reward is -0.99\n",
      "Episode 992/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 44481, 'eps': 0.0, 'buffer_size': 44481, 'q_loss': 1.1445728540420532, 'mean_q_value': -0.2273206114768982, 'max_q_value': 0.3958320617675781, 'min_q_value': -0.9318119883537292, 'mean_td_error': 0.039335787, 'max_td_error': 0.11505604, 'mean_weight': 0.41252022981643677}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3120, -0.3408, -0.3236, -0.3139]], device='cuda:0'), reward is -0.99\n",
      "Episode 993/1000000: {'total_return': -0.7899999999999999, 'steps': 21, 'total_steps': 44502, 'eps': 0.0, 'buffer_size': 44502, 'q_loss': 1.5025224685668945, 'mean_q_value': -0.30712494254112244, 'max_q_value': 0.3688339591026306, 'min_q_value': -0.9699155688285828, 'mean_td_error': 0.03470307, 'max_td_error': 0.092075646, 'mean_weight': 0.5791097283363342}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8640, -0.8664, -0.8522, -0.9001]], device='cuda:0'), reward is -0.99\n",
      "Episode 994/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 44564, 'eps': 0.0, 'buffer_size': 44564, 'q_loss': 1.305087685585022, 'mean_q_value': -0.12091610580682755, 'max_q_value': 0.3515302836894989, 'min_q_value': -0.981611430644989, 'mean_td_error': 0.03633357, 'max_td_error': 0.10301024, 'mean_weight': 0.4351915419101715}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7680, -0.6557, -0.6515, -0.7267]], device='cuda:0'), reward is -0.99\n",
      "Episode 995/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 44627, 'eps': 0.0, 'buffer_size': 44627, 'q_loss': 1.2845089435577393, 'mean_q_value': -0.16605284810066223, 'max_q_value': 0.384657621383667, 'min_q_value': -0.9256957769393921, 'mean_td_error': 0.029854123, 'max_td_error': 0.07604313, 'mean_weight': 0.4405095875263214}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7372, -0.7366, -0.7372, -0.7384]], device='cuda:0'), reward is -0.99\n",
      "Episode 996/1000000: {'total_return': -0.35999999999999965, 'steps': 64, 'total_steps': 44691, 'eps': 0.0, 'buffer_size': 44691, 'q_loss': 1.7822551727294922, 'mean_q_value': -0.1762465238571167, 'max_q_value': 0.4365473985671997, 'min_q_value': -0.9639939665794373, 'mean_td_error': 0.03369523, 'max_td_error': 0.090863585, 'mean_weight': 0.6191971302032471}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6428, -0.6786, -0.6369, -0.6219]], device='cuda:0'), reward is -0.99\n",
      "Episode 997/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 44719, 'eps': 0.0, 'buffer_size': 44719, 'q_loss': 1.5365443229675293, 'mean_q_value': -0.2871461808681488, 'max_q_value': 0.3852076232433319, 'min_q_value': -0.996325671672821, 'mean_td_error': 0.034869656, 'max_td_error': 0.18025479, 'mean_weight': 0.601359486579895}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8961, -0.8813, -0.9070, -0.8990]], device='cuda:0'), reward is -0.99\n",
      "Episode 998/1000000: {'total_return': 0.09000000000000075, 'steps': 109, 'total_steps': 44828, 'eps': 0.0, 'buffer_size': 44828, 'q_loss': 1.5140495300292969, 'mean_q_value': -0.14408236742019653, 'max_q_value': 0.4076188802719116, 'min_q_value': -0.9269171357154846, 'mean_td_error': 0.06253367, 'max_td_error': 0.38956633, 'mean_weight': 0.5173196792602539}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9054, -0.9036, -0.8512, -0.8569]], device='cuda:0'), reward is -0.99\n",
      "Episode 999/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 44879, 'eps': 0.0, 'buffer_size': 44879, 'q_loss': 1.3790888786315918, 'mean_q_value': -0.18282727897167206, 'max_q_value': 0.36522558331489563, 'min_q_value': -0.98540860414505, 'mean_td_error': 0.051801614, 'max_td_error': 0.37016052, 'mean_weight': 0.46359488368034363}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8466, -0.8556, -0.8499, -0.8503]], device='cuda:0'), reward is -0.99\n",
      "Episode 1000/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 44935, 'eps': 0.0, 'buffer_size': 44935, 'q_loss': 1.8811553716659546, 'mean_q_value': -0.17202027142047882, 'max_q_value': 0.41463685035705566, 'min_q_value': -0.9548683166503906, 'mean_td_error': 0.057272512, 'max_td_error': 0.37000972, 'mean_weight': 0.6688504219055176}\n",
      "Saved checkpoint: experiments/Surround_rainbow_dqn_20250224_172432/checkpoints/training_state_episode_1000_20250224_172916.pt\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8820, -0.8685, -0.8610, -0.9037]], device='cuda:0'), reward is -0.99\n",
      "Episode 1001/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 45007, 'eps': 0.0, 'buffer_size': 45007, 'q_loss': 1.0408916473388672, 'mean_q_value': -0.08558738976716995, 'max_q_value': 0.4045102596282959, 'min_q_value': -0.9250658750534058, 'mean_td_error': 0.05414142, 'max_td_error': 0.28369802, 'mean_weight': 0.3359047770500183}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8983, -0.8955, -0.8972, -0.9333]], device='cuda:0'), reward is -0.99\n",
      "Episode 1002/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 45075, 'eps': 0.0, 'buffer_size': 45075, 'q_loss': 1.268582820892334, 'mean_q_value': -0.20824137330055237, 'max_q_value': 0.358890175819397, 'min_q_value': -0.9393684267997742, 'mean_td_error': 0.0536301, 'max_td_error': 0.2489575, 'mean_weight': 0.45229247212409973}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0749, 0.0852, 0.0905, 0.0816]], device='cuda:0'), reward is -0.99\n",
      "Episode 1003/1000000: {'total_return': -0.4099999999999997, 'steps': 59, 'total_steps': 45134, 'eps': 0.0, 'buffer_size': 45134, 'q_loss': 1.418015480041504, 'mean_q_value': -0.1511567085981369, 'max_q_value': 0.4058917164802551, 'min_q_value': -0.9638816118240356, 'mean_td_error': 0.045711417, 'max_td_error': 0.24511862, 'mean_weight': 0.47900575399398804}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5545, -0.4561, -0.4939, -0.5151]], device='cuda:0'), reward is -0.99\n",
      "Episode 1004/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 45187, 'eps': 0.0, 'buffer_size': 45187, 'q_loss': 1.6025714874267578, 'mean_q_value': -0.11791916191577911, 'max_q_value': 0.42162516713142395, 'min_q_value': -0.9619475603103638, 'mean_td_error': 0.03441131, 'max_td_error': 0.1614069, 'mean_weight': 0.5230903625488281}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8993, -0.8964, -0.8833, -0.8901]], device='cuda:0'), reward is -0.99\n",
      "Episode 1005/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 45238, 'eps': 0.0, 'buffer_size': 45238, 'q_loss': 1.6562929153442383, 'mean_q_value': -0.2883166968822479, 'max_q_value': 0.44263961911201477, 'min_q_value': -0.8686637878417969, 'mean_td_error': 0.03871677, 'max_td_error': 0.16269568, 'mean_weight': 0.629744291305542}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0191, -0.0056,  0.0004, -0.0102]], device='cuda:0'), reward is -0.99\n",
      "Episode 1006/1000000: {'total_return': -0.2799999999999996, 'steps': 72, 'total_steps': 45310, 'eps': 0.0, 'buffer_size': 45310, 'q_loss': 0.8929609656333923, 'mean_q_value': -0.2217540442943573, 'max_q_value': 0.4432482123374939, 'min_q_value': -0.9676132798194885, 'mean_td_error': 0.081220135, 'max_td_error': 1.0103364, 'mean_weight': 0.33543312549591064}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6737, -0.6642, -0.6682, -0.6647]], device='cuda:0'), reward is -0.99\n",
      "Episode 1007/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 45362, 'eps': 0.0, 'buffer_size': 45362, 'q_loss': 1.439479112625122, 'mean_q_value': -0.21151557564735413, 'max_q_value': 0.40211570262908936, 'min_q_value': -0.8739692568778992, 'mean_td_error': 0.078661665, 'max_td_error': 0.9764269, 'mean_weight': 0.5304273366928101}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5440, -0.5054, -0.5072, -0.4997]], device='cuda:0'), reward is -0.99\n",
      "Episode 1008/1000000: {'total_return': -0.6099999999999999, 'steps': 39, 'total_steps': 45401, 'eps': 0.0, 'buffer_size': 45401, 'q_loss': 1.420038104057312, 'mean_q_value': -0.19857557117938995, 'max_q_value': 0.4301220774650574, 'min_q_value': -0.9510311484336853, 'mean_td_error': 0.04784534, 'max_td_error': 0.18834734, 'mean_weight': 0.5128917098045349}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8244, -0.7582, -0.7381, -0.8234]], device='cuda:0'), reward is -0.99\n",
      "Episode 1009/1000000: {'total_return': -0.1999999999999995, 'steps': 80, 'total_steps': 45481, 'eps': 0.0, 'buffer_size': 45481, 'q_loss': 1.3574531078338623, 'mean_q_value': -0.2017846554517746, 'max_q_value': 0.4142645299434662, 'min_q_value': -0.9017796516418457, 'mean_td_error': 0.04435779, 'max_td_error': 0.16035452, 'mean_weight': 0.4861885905265808}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4288, -0.4943, -0.4693, -0.6415]], device='cuda:0'), reward is -0.99\n",
      "Episode 1010/1000000: {'total_return': -0.74, 'steps': 26, 'total_steps': 45507, 'eps': 0.0, 'buffer_size': 45507, 'q_loss': 1.7944505214691162, 'mean_q_value': -0.1890917420387268, 'max_q_value': 0.42186272144317627, 'min_q_value': -0.9942198395729065, 'mean_td_error': 0.03758728, 'max_td_error': 0.14243442, 'mean_weight': 0.6480139493942261}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9185, -0.8919, -0.9021, -0.9030]], device='cuda:0'), reward is -0.99\n",
      "Episode 1011/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 45560, 'eps': 0.0, 'buffer_size': 45560, 'q_loss': 1.186895728111267, 'mean_q_value': -0.18421152234077454, 'max_q_value': 0.4217310845851898, 'min_q_value': -0.9162272810935974, 'mean_td_error': 0.041432653, 'max_td_error': 0.17523912, 'mean_weight': 0.3904399871826172}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5265, -0.5205, -0.5219, -0.5254]], device='cuda:0'), reward is -0.99\n",
      "Episode 1012/1000000: {'total_return': -0.23999999999999955, 'steps': 76, 'total_steps': 45636, 'eps': 0.0, 'buffer_size': 45636, 'q_loss': 1.0752321481704712, 'mean_q_value': -0.20633214712142944, 'max_q_value': 0.3482855558395386, 'min_q_value': -0.8999763131141663, 'mean_td_error': 0.045983918, 'max_td_error': 0.15248463, 'mean_weight': 0.3938484787940979}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8275, -0.8195, -0.8210, -0.8311]], device='cuda:0'), reward is -0.99\n",
      "Episode 1013/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 45706, 'eps': 0.0, 'buffer_size': 45706, 'q_loss': 0.9434255361557007, 'mean_q_value': -0.2351713627576828, 'max_q_value': 0.3870135545730591, 'min_q_value': -0.9987627267837524, 'mean_td_error': 0.051778935, 'max_td_error': 0.21856189, 'mean_weight': 0.33461737632751465}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6032, -0.5721, -0.5702, -0.5798]], device='cuda:0'), reward is -0.99\n",
      "Episode 1014/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 45768, 'eps': 0.0, 'buffer_size': 45768, 'q_loss': 1.0750823020935059, 'mean_q_value': -0.12359406054019928, 'max_q_value': 0.4831906855106354, 'min_q_value': -0.8646165728569031, 'mean_td_error': 0.07449242, 'max_td_error': 0.4556794, 'mean_weight': 0.37568843364715576}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9028, -0.9027, -0.9031, -0.9043]], device='cuda:0'), reward is -0.99\n",
      "Episode 1015/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 45823, 'eps': 0.0, 'buffer_size': 45823, 'q_loss': 1.3942523002624512, 'mean_q_value': -0.22042876482009888, 'max_q_value': 0.37390679121017456, 'min_q_value': -0.8982241749763489, 'mean_td_error': 0.05408945, 'max_td_error': 0.30087852, 'mean_weight': 0.5163213014602661}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8957, -0.8643, -0.8822, -0.8791]], device='cuda:0'), reward is -0.99\n",
      "Episode 1016/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 45890, 'eps': 0.0, 'buffer_size': 45890, 'q_loss': 1.3050575256347656, 'mean_q_value': -0.23048481345176697, 'max_q_value': 0.3755441904067993, 'min_q_value': -0.9232815504074097, 'mean_td_error': 0.044470914, 'max_td_error': 0.1674901, 'mean_weight': 0.4876307249069214}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7804, -0.7658, -0.7766, -0.7625]], device='cuda:0'), reward is -0.99\n",
      "Episode 1017/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 45941, 'eps': 0.0, 'buffer_size': 45941, 'q_loss': 1.658217191696167, 'mean_q_value': 0.01927734538912773, 'max_q_value': 0.551517128944397, 'min_q_value': -0.9310011863708496, 'mean_td_error': 0.040067144, 'max_td_error': 0.22061071, 'mean_weight': 0.5178240537643433}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7814, -0.7812, -0.7815, -0.7830]], device='cuda:0'), reward is -0.99\n",
      "Episode 1018/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 46002, 'eps': 0.0, 'buffer_size': 46002, 'q_loss': 1.6109607219696045, 'mean_q_value': -0.200409933924675, 'max_q_value': 0.3988643288612366, 'min_q_value': -0.9130116701126099, 'mean_td_error': 0.06442045, 'max_td_error': 0.37426847, 'mean_weight': 0.5679545402526855}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8079, -0.8079, -0.8082, -0.8094]], device='cuda:0'), reward is -0.99\n",
      "Episode 1019/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 46034, 'eps': 0.0, 'buffer_size': 46034, 'q_loss': 1.3065767288208008, 'mean_q_value': -0.2164626121520996, 'max_q_value': 0.3803715705871582, 'min_q_value': -0.9077392816543579, 'mean_td_error': 0.045906536, 'max_td_error': 0.21703696, 'mean_weight': 0.4637678563594818}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9395, -0.9087, -0.9168, -0.9323]], device='cuda:0'), reward is -0.99\n",
      "Episode 1020/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 46109, 'eps': 0.0, 'buffer_size': 46109, 'q_loss': 1.0934785604476929, 'mean_q_value': -0.20420518517494202, 'max_q_value': 0.4568800926208496, 'min_q_value': -0.9475326538085938, 'mean_td_error': 0.061736427, 'max_td_error': 0.46046424, 'mean_weight': 0.400529146194458}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2044, -0.2051, -0.2030, -0.2063]], device='cuda:0'), reward is -0.99\n",
      "Episode 1021/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 46177, 'eps': 0.0, 'buffer_size': 46177, 'q_loss': 1.0624053478240967, 'mean_q_value': -0.11619647592306137, 'max_q_value': 0.3789088726043701, 'min_q_value': -0.9943233132362366, 'mean_td_error': 0.04624302, 'max_td_error': 0.24936193, 'mean_weight': 0.35411280393600464}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4738, -0.4528, -0.4530, -0.4819]], device='cuda:0'), reward is -0.99\n",
      "Episode 1022/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 46202, 'eps': 0.0, 'buffer_size': 46202, 'q_loss': 1.5432912111282349, 'mean_q_value': -0.23175901174545288, 'max_q_value': 0.41317737102508545, 'min_q_value': -0.9533450603485107, 'mean_td_error': 0.03544552, 'max_td_error': 0.14632154, 'mean_weight': 0.5711888670921326}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9038, -0.9225, -0.9057, -0.9025]], device='cuda:0'), reward is -0.99\n",
      "Episode 1023/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 46252, 'eps': 0.0, 'buffer_size': 46252, 'q_loss': 1.3179316520690918, 'mean_q_value': -0.22487199306488037, 'max_q_value': 0.4584682583808899, 'min_q_value': -0.9290539622306824, 'mean_td_error': 0.04845331, 'max_td_error': 0.21513808, 'mean_weight': 0.5013284087181091}\n",
      "Hit done, on final action Predicted Q-values: tensor([[0.0839, 0.0833, 0.0849, 0.0836]], device='cuda:0'), reward is -0.99\n",
      "Episode 1024/1000000: {'total_return': -0.37999999999999967, 'steps': 62, 'total_steps': 46314, 'eps': 0.0, 'buffer_size': 46314, 'q_loss': 1.302823781967163, 'mean_q_value': -0.17663002014160156, 'max_q_value': 0.37290579080581665, 'min_q_value': -0.9645937085151672, 'mean_td_error': 0.057763524, 'max_td_error': 0.4836203, 'mean_weight': 0.46641677618026733}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7951, -0.7530, -0.7558, -0.7809]], device='cuda:0'), reward is -0.99\n",
      "Episode 1025/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 46375, 'eps': 0.0, 'buffer_size': 46375, 'q_loss': 1.3628374338150024, 'mean_q_value': -0.21051472425460815, 'max_q_value': 0.4165361225605011, 'min_q_value': -0.9019191861152649, 'mean_td_error': 0.05734272, 'max_td_error': 0.3020876, 'mean_weight': 0.4829164445400238}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2591, -0.2603, -0.2596, -0.2623]], device='cuda:0'), reward is -0.99\n",
      "Episode 1026/1000000: {'total_return': -0.6699999999999999, 'steps': 33, 'total_steps': 46408, 'eps': 0.0, 'buffer_size': 46408, 'q_loss': 1.2223706245422363, 'mean_q_value': -0.14466546475887299, 'max_q_value': 0.41952982544898987, 'min_q_value': -0.919147789478302, 'mean_td_error': 0.04937352, 'max_td_error': 0.1765745, 'mean_weight': 0.4121505618095398}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7052, -0.7640, -0.7005, -0.7177]], device='cuda:0'), reward is -0.99\n",
      "Episode 1027/1000000: {'total_return': -0.44999999999999973, 'steps': 55, 'total_steps': 46463, 'eps': 0.0, 'buffer_size': 46463, 'q_loss': 1.4259979724884033, 'mean_q_value': -0.08110767602920532, 'max_q_value': 0.45586901903152466, 'min_q_value': -0.8674869537353516, 'mean_td_error': 0.05215262, 'max_td_error': 0.22449866, 'mean_weight': 0.46093687415122986}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5207, -0.5165, -0.5133, -0.5163]], device='cuda:0'), reward is -0.99\n",
      "Episode 1028/1000000: {'total_return': -0.24999999999999956, 'steps': 75, 'total_steps': 46538, 'eps': 0.0, 'buffer_size': 46538, 'q_loss': 1.4787073135375977, 'mean_q_value': -0.2557588517665863, 'max_q_value': 0.38368117809295654, 'min_q_value': -0.9197369813919067, 'mean_td_error': 0.04764583, 'max_td_error': 0.22097501, 'mean_weight': 0.5619405508041382}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7106, -0.6670, -0.6429, -0.6639]], device='cuda:0'), reward is -0.99\n",
      "Episode 1029/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 46591, 'eps': 0.0, 'buffer_size': 46591, 'q_loss': 1.3597426414489746, 'mean_q_value': -0.2659168243408203, 'max_q_value': 0.4303758144378662, 'min_q_value': -0.9604364633560181, 'mean_td_error': 0.062203363, 'max_td_error': 0.44852883, 'mean_weight': 0.5081322193145752}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8196, -0.8196, -0.8198, -0.8213]], device='cuda:0'), reward is -0.99\n",
      "Episode 1030/1000000: {'total_return': -0.3199999999999996, 'steps': 68, 'total_steps': 46659, 'eps': 0.0, 'buffer_size': 46659, 'q_loss': 1.2256174087524414, 'mean_q_value': -0.2235889434814453, 'max_q_value': 0.4104483127593994, 'min_q_value': -0.9647947549819946, 'mean_td_error': 0.06125543, 'max_td_error': 0.2774459, 'mean_weight': 0.44056975841522217}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5857, -0.5409, -0.5506, -0.6055]], device='cuda:0'), reward is -0.99\n",
      "Episode 1031/1000000: {'total_return': -0.5699999999999998, 'steps': 43, 'total_steps': 46702, 'eps': 0.0, 'buffer_size': 46702, 'q_loss': 1.5327069759368896, 'mean_q_value': -0.17487773299217224, 'max_q_value': 0.4161871671676636, 'min_q_value': -0.9741654992103577, 'mean_td_error': 0.04858564, 'max_td_error': 0.16868687, 'mean_weight': 0.562299907207489}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3014, -0.1052, -0.0887, -0.1764]], device='cuda:0'), reward is -0.99\n",
      "Episode 1032/1000000: {'total_return': -0.36999999999999966, 'steps': 63, 'total_steps': 46765, 'eps': 0.0, 'buffer_size': 46765, 'q_loss': 1.7141411304473877, 'mean_q_value': -0.2534664571285248, 'max_q_value': 0.404934287071228, 'min_q_value': -0.8659043312072754, 'mean_td_error': 0.049063332, 'max_td_error': 0.20353669, 'mean_weight': 0.6251416206359863}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2680, -0.2667, -0.2682, -0.2695]], device='cuda:0'), reward is -0.99\n",
      "Episode 1033/1000000: {'total_return': -0.82, 'steps': 18, 'total_steps': 46783, 'eps': 0.0, 'buffer_size': 46783, 'q_loss': 2.0111279487609863, 'mean_q_value': -0.10465647280216217, 'max_q_value': 0.3752290904521942, 'min_q_value': -0.8482397794723511, 'mean_td_error': 0.06625007, 'max_td_error': 0.31999296, 'mean_weight': 0.6754838228225708}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9030, -0.9139, -0.8964, -0.9284]], device='cuda:0'), reward is -0.99\n",
      "Episode 1034/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 46839, 'eps': 0.0, 'buffer_size': 46839, 'q_loss': 1.5663137435913086, 'mean_q_value': -0.19197340309619904, 'max_q_value': 0.457596093416214, 'min_q_value': -0.9566090106964111, 'mean_td_error': 0.049567085, 'max_td_error': 0.29411936, 'mean_weight': 0.5668158531188965}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5517, -0.5421, -0.5410, -0.5390]], device='cuda:0'), reward is -0.99\n",
      "Episode 1035/1000000: {'total_return': -0.47999999999999976, 'steps': 52, 'total_steps': 46891, 'eps': 0.0, 'buffer_size': 46891, 'q_loss': 0.9654470682144165, 'mean_q_value': -0.09969031810760498, 'max_q_value': 0.4193013906478882, 'min_q_value': -0.9450981616973877, 'mean_td_error': 0.042396717, 'max_td_error': 0.20801169, 'mean_weight': 0.32777243852615356}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5081, -0.4932, -0.4737, -0.4702]], device='cuda:0'), reward is -0.99\n",
      "Episode 1036/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 46929, 'eps': 0.0, 'buffer_size': 46929, 'q_loss': 1.4531348943710327, 'mean_q_value': -0.23239237070083618, 'max_q_value': 0.40184879302978516, 'min_q_value': -0.9151139259338379, 'mean_td_error': 0.043052897, 'max_td_error': 0.27866, 'mean_weight': 0.527755618095398}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7493, -0.7617, -0.7327, -0.7486]], device='cuda:0'), reward is -0.99\n",
      "Episode 1037/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 47003, 'eps': 0.0, 'buffer_size': 47003, 'q_loss': 1.148066759109497, 'mean_q_value': -0.21056288480758667, 'max_q_value': 0.4175303876399994, 'min_q_value': -0.820354163646698, 'mean_td_error': 0.065628156, 'max_td_error': 0.25748044, 'mean_weight': 0.42114198207855225}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5495, -0.2430, -0.1354, -0.1935]], device='cuda:0'), reward is -0.99\n",
      "Episode 1038/1000000: {'total_return': -0.72, 'steps': 28, 'total_steps': 47031, 'eps': 0.0, 'buffer_size': 47031, 'q_loss': 1.5254945755004883, 'mean_q_value': -0.2618100643157959, 'max_q_value': 0.4461648464202881, 'min_q_value': -0.92849200963974, 'mean_td_error': 0.057648607, 'max_td_error': 0.23340023, 'mean_weight': 0.556472659111023}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1648, -0.1708, -0.1655, -0.1687]], device='cuda:0'), reward is -0.99\n",
      "Episode 1039/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 47073, 'eps': 0.0, 'buffer_size': 47073, 'q_loss': 1.6825714111328125, 'mean_q_value': -0.15708273649215698, 'max_q_value': 0.410854697227478, 'min_q_value': -0.9171242117881775, 'mean_td_error': 0.04738272, 'max_td_error': 0.15571988, 'mean_weight': 0.5708470344543457}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4981, -0.5682, -0.4960, -0.5134]], device='cuda:0'), reward is -0.99\n",
      "Episode 1040/1000000: {'total_return': -0.22999999999999954, 'steps': 77, 'total_steps': 47150, 'eps': 0.0, 'buffer_size': 47150, 'q_loss': 1.7808812856674194, 'mean_q_value': -0.0989890918135643, 'max_q_value': 0.41099417209625244, 'min_q_value': -0.9118467569351196, 'mean_td_error': 0.06646433, 'max_td_error': 0.54410386, 'mean_weight': 0.5947046279907227}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8920, -0.8925, -0.8921, -0.8934]], device='cuda:0'), reward is -0.99\n",
      "Episode 1041/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 47190, 'eps': 0.0, 'buffer_size': 47190, 'q_loss': 1.0369547605514526, 'mean_q_value': -0.2504225969314575, 'max_q_value': 0.3608136475086212, 'min_q_value': -1.003319263458252, 'mean_td_error': 0.052494265, 'max_td_error': 0.277064, 'mean_weight': 0.39751213788986206}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4831, -0.4810, -0.4495, -0.4601]], device='cuda:0'), reward is -0.99\n",
      "Episode 1042/1000000: {'total_return': -0.7699999999999999, 'steps': 23, 'total_steps': 47213, 'eps': 0.0, 'buffer_size': 47213, 'q_loss': 1.5588490962982178, 'mean_q_value': -0.3765774965286255, 'max_q_value': 0.3185104727745056, 'min_q_value': -0.9401346445083618, 'mean_td_error': 0.05210233, 'max_td_error': 0.14984548, 'mean_weight': 0.6505514979362488}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1859, -0.1805, -0.1785, -0.1819]], device='cuda:0'), reward is -0.99\n",
      "Episode 1043/1000000: {'total_return': -0.7799999999999999, 'steps': 22, 'total_steps': 47235, 'eps': 0.0, 'buffer_size': 47235, 'q_loss': 1.6339547634124756, 'mean_q_value': -0.09327643364667892, 'max_q_value': 0.4460456371307373, 'min_q_value': -0.8901432156562805, 'mean_td_error': 0.033449847, 'max_td_error': 0.101257175, 'mean_weight': 0.5346816182136536}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7774, -0.7686, -0.6030, -0.7441]], device='cuda:0'), reward is -0.99\n",
      "Episode 1044/1000000: {'total_return': -0.13999999999999946, 'steps': 86, 'total_steps': 47321, 'eps': 0.0, 'buffer_size': 47321, 'q_loss': 2.197742462158203, 'mean_q_value': -0.08140704035758972, 'max_q_value': 0.4193177819252014, 'min_q_value': -0.8592325448989868, 'mean_td_error': 0.05564136, 'max_td_error': 0.24917212, 'mean_weight': 0.7016608715057373}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5562, -0.4755, -0.4678, -0.4827]], device='cuda:0'), reward is -0.99\n",
      "Episode 1045/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 47363, 'eps': 0.0, 'buffer_size': 47363, 'q_loss': 1.6126344203948975, 'mean_q_value': -0.1348147988319397, 'max_q_value': 0.42131733894348145, 'min_q_value': -0.92977374792099, 'mean_td_error': 0.045117, 'max_td_error': 0.1687805, 'mean_weight': 0.5570799112319946}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9558, -0.9364, -0.9284, -0.9370]], device='cuda:0'), reward is -0.99\n",
      "Episode 1046/1000000: {'total_return': 0.23000000000000087, 'steps': 123, 'total_steps': 47486, 'eps': 0.0, 'buffer_size': 47486, 'q_loss': 1.2681798934936523, 'mean_q_value': -0.2040564864873886, 'max_q_value': 0.422458678483963, 'min_q_value': -0.9843189716339111, 'mean_td_error': 0.042721886, 'max_td_error': 0.13864005, 'mean_weight': 0.4194491505622864}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8433, -0.8645, -0.8319, -0.8354]], device='cuda:0'), reward is -0.99\n",
      "Episode 1047/1000000: {'total_return': -0.2999999999999996, 'steps': 70, 'total_steps': 47556, 'eps': 0.0, 'buffer_size': 47556, 'q_loss': 1.0587317943572998, 'mean_q_value': -0.20232856273651123, 'max_q_value': 0.4090133011341095, 'min_q_value': -0.9897046685218811, 'mean_td_error': 0.05554096, 'max_td_error': 0.25097445, 'mean_weight': 0.37350916862487793}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7733, -0.7598, -0.7603, -0.7640]], device='cuda:0'), reward is -0.99\n",
      "Episode 1048/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 47613, 'eps': 0.0, 'buffer_size': 47613, 'q_loss': 1.314030647277832, 'mean_q_value': -0.22353024780750275, 'max_q_value': 0.4368201792240143, 'min_q_value': -0.9593569040298462, 'mean_td_error': 0.04709981, 'max_td_error': 0.16214466, 'mean_weight': 0.4874955415725708}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0118, -0.0124, -0.0124, -0.0142]], device='cuda:0'), reward is -0.99\n",
      "Episode 1049/1000000: {'total_return': -0.4199999999999997, 'steps': 58, 'total_steps': 47671, 'eps': 0.0, 'buffer_size': 47671, 'q_loss': 1.7822248935699463, 'mean_q_value': -0.17838363349437714, 'max_q_value': 0.4254729151725769, 'min_q_value': -0.9096181392669678, 'mean_td_error': 0.055913422, 'max_td_error': 0.22501415, 'mean_weight': 0.6086013317108154}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.2993, -0.2462, -0.3010, -0.2586]], device='cuda:0'), reward is -0.99\n",
      "Episode 1050/1000000: {'total_return': -0.6199999999999999, 'steps': 38, 'total_steps': 47709, 'eps': 0.0, 'buffer_size': 47709, 'q_loss': 1.2349536418914795, 'mean_q_value': -0.1261408030986786, 'max_q_value': 0.38739049434661865, 'min_q_value': -0.9598706960678101, 'mean_td_error': 0.04729601, 'max_td_error': 0.17262682, 'mean_weight': 0.4148350656032562}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0462,  0.0229,  0.0262, -0.0518]], device='cuda:0'), reward is -0.99\n",
      "Episode 1051/1000000: {'total_return': -0.5999999999999999, 'steps': 40, 'total_steps': 47749, 'eps': 0.0, 'buffer_size': 47749, 'q_loss': 1.4408466815948486, 'mean_q_value': -0.2607373595237732, 'max_q_value': 0.3708263039588928, 'min_q_value': -0.9805965423583984, 'mean_td_error': 0.04322917, 'max_td_error': 0.15245795, 'mean_weight': 0.5330342650413513}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6631, -0.6128, -0.6153, -0.6394]], device='cuda:0'), reward is -0.99\n",
      "Episode 1052/1000000: {'total_return': -0.6799999999999999, 'steps': 32, 'total_steps': 47781, 'eps': 0.0, 'buffer_size': 47781, 'q_loss': 1.5062499046325684, 'mean_q_value': -0.23497015237808228, 'max_q_value': 0.48198366165161133, 'min_q_value': -0.8196155428886414, 'mean_td_error': 0.04969927, 'max_td_error': 0.21055561, 'mean_weight': 0.5631659030914307}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8261, -0.8292, -0.8502, -0.8458]], device='cuda:0'), reward is -0.99\n",
      "Episode 1053/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 47832, 'eps': 0.0, 'buffer_size': 47832, 'q_loss': 1.646644115447998, 'mean_q_value': -0.19972318410873413, 'max_q_value': 0.5242955088615417, 'min_q_value': -0.9469009041786194, 'mean_td_error': 0.055986464, 'max_td_error': 0.41048908, 'mean_weight': 0.6011800169944763}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5318, -0.6075, -0.5350, -0.5508]], device='cuda:0'), reward is -0.99\n",
      "Episode 1054/1000000: {'total_return': -0.5299999999999998, 'steps': 47, 'total_steps': 47879, 'eps': 0.0, 'buffer_size': 47879, 'q_loss': 1.0413258075714111, 'mean_q_value': -0.1853204369544983, 'max_q_value': 0.41892704367637634, 'min_q_value': -0.8658148646354675, 'mean_td_error': 0.05614227, 'max_td_error': 0.31698582, 'mean_weight': 0.39309948682785034}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5267, -0.4885, -0.4749, -0.4834]], device='cuda:0'), reward is -0.99\n",
      "Episode 1055/1000000: {'total_return': -0.3299999999999996, 'steps': 67, 'total_steps': 47946, 'eps': 0.0, 'buffer_size': 47946, 'q_loss': 0.960155189037323, 'mean_q_value': -0.16976474225521088, 'max_q_value': 0.4689393639564514, 'min_q_value': -0.9617695808410645, 'mean_td_error': 0.070902824, 'max_td_error': 0.309829, 'mean_weight': 0.34558162093162537}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7456, -0.6824, -0.6760, -0.6888]], device='cuda:0'), reward is -0.99\n",
      "Episode 1056/1000000: {'total_return': -0.4399999999999997, 'steps': 56, 'total_steps': 48002, 'eps': 0.0, 'buffer_size': 48002, 'q_loss': 1.3828028440475464, 'mean_q_value': -0.12040096521377563, 'max_q_value': 0.39407747983932495, 'min_q_value': -0.8995658755302429, 'mean_td_error': 0.066097386, 'max_td_error': 0.34539926, 'mean_weight': 0.45710235834121704}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9207, -0.8896, -0.8950, -0.8875]], device='cuda:0'), reward is -0.99\n",
      "Episode 1057/1000000: {'total_return': -0.3899999999999997, 'steps': 61, 'total_steps': 48063, 'eps': 0.0, 'buffer_size': 48063, 'q_loss': 1.2879059314727783, 'mean_q_value': -0.16530592739582062, 'max_q_value': 0.41215628385543823, 'min_q_value': -0.9924183487892151, 'mean_td_error': 0.038168736, 'max_td_error': 0.145572, 'mean_weight': 0.45944684743881226}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.6173, -0.6356, -0.6033, -0.6025]], device='cuda:0'), reward is -0.99\n",
      "Episode 1058/1000000: {'total_return': -0.5499999999999998, 'steps': 45, 'total_steps': 48108, 'eps': 0.0, 'buffer_size': 48108, 'q_loss': 1.3161885738372803, 'mean_q_value': -0.19450020790100098, 'max_q_value': 0.47342294454574585, 'min_q_value': -0.8229209184646606, 'mean_td_error': 0.036441863, 'max_td_error': 0.18864089, 'mean_weight': 0.4571288228034973}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9381, -0.9346, -0.9349, -0.9586]], device='cuda:0'), reward is -0.99\n",
      "Episode 1059/1000000: {'total_return': -0.04999999999999938, 'steps': 95, 'total_steps': 48203, 'eps': 0.0, 'buffer_size': 48203, 'q_loss': 1.2693102359771729, 'mean_q_value': -0.23377110064029694, 'max_q_value': 0.4487788677215576, 'min_q_value': -0.9272879958152771, 'mean_td_error': 0.0533149, 'max_td_error': 0.2499677, 'mean_weight': 0.4617675244808197}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.7427, -0.7313, -0.7938, -0.6522]], device='cuda:0'), reward is -0.99\n",
      "Episode 1060/1000000: {'total_return': 0.09000000000000075, 'steps': 109, 'total_steps': 48312, 'eps': 0.0, 'buffer_size': 48312, 'q_loss': 1.0459486246109009, 'mean_q_value': -0.13148048520088196, 'max_q_value': 0.42832377552986145, 'min_q_value': -0.9297250509262085, 'mean_td_error': 0.066916466, 'max_td_error': 0.24395049, 'mean_weight': 0.3633121848106384}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0761, -0.0452, -0.0446, -0.1694]], device='cuda:0'), reward is -0.99\n",
      "Episode 1061/1000000: {'total_return': -0.4299999999999997, 'steps': 57, 'total_steps': 48369, 'eps': 0.0, 'buffer_size': 48369, 'q_loss': 1.7392536401748657, 'mean_q_value': -0.13888445496559143, 'max_q_value': 0.42674964666366577, 'min_q_value': -0.9568349123001099, 'mean_td_error': 0.036542293, 'max_td_error': 0.19682327, 'mean_weight': 0.6018500328063965}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.1812, -0.1377, -0.2065, -0.1476]], device='cuda:0'), reward is -0.99\n",
      "Episode 1062/1000000: {'total_return': -0.7499999999999999, 'steps': 25, 'total_steps': 48394, 'eps': 0.0, 'buffer_size': 48394, 'q_loss': 1.4879841804504395, 'mean_q_value': -0.25023889541625977, 'max_q_value': 0.39495351910591125, 'min_q_value': -0.9993546605110168, 'mean_td_error': 0.07002186, 'max_td_error': 0.35888976, 'mean_weight': 0.5599707961082458}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0513, -0.0401, -0.0372, -0.0433]], device='cuda:0'), reward is -0.99\n",
      "Episode 1063/1000000: {'total_return': -0.5799999999999998, 'steps': 42, 'total_steps': 48436, 'eps': 0.0, 'buffer_size': 48436, 'q_loss': 0.9474331140518188, 'mean_q_value': -0.14684158563613892, 'max_q_value': 0.4082415699958801, 'min_q_value': -0.9662880301475525, 'mean_td_error': 0.036276165, 'max_td_error': 0.10441387, 'mean_weight': 0.3140202760696411}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.8479, -0.8451, -0.8406, -0.8558]], device='cuda:0'), reward is -0.99\n",
      "Episode 1064/1000000: {'total_return': -0.48999999999999977, 'steps': 51, 'total_steps': 48487, 'eps': 0.0, 'buffer_size': 48487, 'q_loss': 1.1486833095550537, 'mean_q_value': -0.17524993419647217, 'max_q_value': 0.4556623101234436, 'min_q_value': -0.9354447722434998, 'mean_td_error': 0.059283048, 'max_td_error': 0.5409603, 'mean_weight': 0.42473527789115906}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.0673, -0.0583, -0.0807, -0.0362]], device='cuda:0'), reward is -0.99\n",
      "Episode 1065/1000000: {'total_return': -0.46999999999999975, 'steps': 53, 'total_steps': 48540, 'eps': 0.0, 'buffer_size': 48540, 'q_loss': 1.8602547645568848, 'mean_q_value': -0.13428489863872528, 'max_q_value': 0.438474178314209, 'min_q_value': -0.957654595375061, 'mean_td_error': 0.06433897, 'max_td_error': 0.48722905, 'mean_weight': 0.6115695238113403}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.9816, -0.9776, -0.9809, -0.9850]], device='cuda:0'), reward is -0.99\n",
      "Episode 1066/1000000: {'total_return': -0.25999999999999956, 'steps': 74, 'total_steps': 48614, 'eps': 0.0, 'buffer_size': 48614, 'q_loss': 1.4783165454864502, 'mean_q_value': -0.2450442612171173, 'max_q_value': 0.42060813307762146, 'min_q_value': -0.9525066018104553, 'mean_td_error': 0.03878004, 'max_td_error': 0.18065709, 'mean_weight': 0.5953087210655212}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.5303, -0.5765, -0.5804, -0.6446]], device='cuda:0'), reward is -0.99\n",
      "Episode 1067/1000000: {'total_return': -0.4999999999999997, 'steps': 50, 'total_steps': 48664, 'eps': 0.0, 'buffer_size': 48664, 'q_loss': 1.9806801080703735, 'mean_q_value': -0.105479896068573, 'max_q_value': 0.4273359775543213, 'min_q_value': -0.883277952671051, 'mean_td_error': 0.0498629, 'max_td_error': 0.2450999, 'mean_weight': 0.6578152179718018}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.4860, -0.4870, -0.4868, -0.4911]], device='cuda:0'), reward is -0.99\n",
      "Episode 1068/1000000: {'total_return': -0.34999999999999964, 'steps': 65, 'total_steps': 48729, 'eps': 0.0, 'buffer_size': 48729, 'q_loss': 1.336268424987793, 'mean_q_value': -0.13418671488761902, 'max_q_value': 0.4483998715877533, 'min_q_value': -0.8680095672607422, 'mean_td_error': 0.04190252, 'max_td_error': 0.19059649, 'mean_weight': 0.46801790595054626}\n",
      "Hit done, on final action Predicted Q-values: tensor([[-0.3507, -0.3515, -0.3509, -0.3557]], device='cuda:0'), reward is 1.01\n",
      "Episode 1069/1000000: {'total_return': 1.6800000000000004, 'steps': 68, 'total_steps': 48797, 'eps': 0.0, 'buffer_size': 48797, 'q_loss': 1.3935661315917969, 'mean_q_value': -0.2668495774269104, 'max_q_value': 0.4256879985332489, 'min_q_value': -0.959293007850647, 'mean_td_error': 0.045283273, 'max_td_error': 0.30984783, 'mean_weight': 0.5326904058456421}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent, history, env, exp_dir \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     39\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_episodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Run episode\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Print progress\u001b[39;00m\n",
      "File \u001b[0;32m~/ACM_AI/SlitheRL_Cleaned/agents/rainbow_dqn.py:312\u001b[0m, in \u001b[0;36mrun_episode\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# print(f\"DEBUG: No state change at step {steps}, repeated frame\")\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[1;32m    313\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_policy_step()\n\u001b[1;32m    314\u001b[0m     episode_metrics\u001b[38;5;241m.\u001b[39mupdate(metrics)\n",
      "File \u001b[0;32m~/ACM_AI/SlitheRL_Cleaned/agents/rainbow_dqn.py:190\u001b[0m, in \u001b[0;36m_update_policy_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# Get next-state distributions from target\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     next_q_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network(next_states)  \u001b[38;5;66;03m# [B, actions, n_atoms]\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdouble_dqn:\n\u001b[1;32m    191\u001b[0m         next_q_dist_online \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_network(next_states)  \u001b[38;5;66;03m# [B, actions, n_atoms]\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;66;03m# Sum over support for expected Q values and pick best action per batch element\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ACM_AI/SlitheRL_Cleaned/agents/rainbow_dqn.py:59\u001b[0m, in \u001b[0;36mC51DuelingQNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_min, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_max, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_atoms)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 59\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     62\u001b[0m value_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_network(features)\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_atoms)\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ACM_AI/SlitheRL_Cleaned/models/cnns.py:68\u001b[0m, in \u001b[0;36mCNNBackbone.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 68\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers:\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:172\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/slitherl/lib/python3.10/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent, history, env, exp_dir = main(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# close the environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slitherl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
